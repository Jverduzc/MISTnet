{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jverduzc/CNN_PBX_Model/blob/master/CNN_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Networks (CNN) for prediction of hotspots on PBX\n",
        "\n",
        "In this notebook we create a CNN model with a U-Net architecture for the prediction of temperature for a plastically bonded explosive molecular dynamics simulation."
      ],
      "metadata": {
        "id": "4QfRMy9VFrcW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries\n",
        "\n",
        "First, we need to set up libraries that are not part of the default environment in Google Colab. In our case, this is only the rendering library ```kaleido```.\n",
        "\n",
        "You will need to restart the runtime to update the kernel.\n",
        "- Menu Runtime -> Restart Runtime"
      ],
      "metadata": {
        "id": "C2UgThuCGG3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaleido"
      ],
      "metadata": {
        "id": "M79B0dH7ftZW",
        "outputId": "7b5ff8e0-bac3-4726-db46-202cdb09c1e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting kaleido\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 79.9 MB 119 kB/s \n",
            "\u001b[?25hInstalling collected packages: kaleido\n",
            "Successfully installed kaleido-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will then import the required libraries for our notebook to run. The following cells import:\n",
        "- Standard python libraries\n",
        "- Plotting libraries\n",
        "- Machine learning libraries (tensorflow / keras)"
      ],
      "metadata": {
        "id": "2ECMQghLGzUA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5Nd2jeT8r8uu"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import clear_output\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "qrgVqntVG6YP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "V08TFba6G_nw"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import initializers\n",
        "from keras.layers import Input, Dropout, BatchNormalization, Conv3DTranspose, concatenate, Dense, Conv3D, Flatten, MaxPooling3D\n",
        "from keras.models import Sequential\n",
        "import keras.backend as K\n",
        "tf.keras.utils.set_random_seed(0)\n",
        "\n",
        "from sklearn.cluster import AgglomerativeClustering"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to verify that we are running an enviroment with a GPU in Colab. The next cell shows if you have a GPU front-end execution host allocated to the notebook. \n",
        "\n",
        "<font color='red'><b>Warning:</b></font> If you don't have one, you'll need to re-run the previous cells after going to:\n",
        "- Menu Runtime -> Change runtime type -> Hardware accelerator"
      ],
      "metadata": {
        "id": "Wh5PkIn3H9dD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KnH0b5QqG_ny",
        "outputId": "25f7d43b-42e8-4495-ad79-ceedd9ac3579",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data\n",
        "\n",
        "After setting up the environment, we need the repository files to create the model and access the training/validation data. \n",
        "\n",
        "<font color='orange'><b>Attention:</b></font> This is not trivial in Colab, but to access a private repository on Github like this, you need to provide Colab with your Github Key. You can get that key here: https://github.com/settings/tokens\n",
        "\n",
        "After that, you need to execute a command with this syntax:\n",
        "```\n",
        "!git clone https://username:github_key@github.com/Jverduzc/CNN_PBX_Model.git\n",
        "```\n",
        "You can fill up the blanks in the following cell. We will also change the current working directory. You should see the a new directory in your directory tree (on your left) with the files on the repository.\n"
      ],
      "metadata": {
        "id": "hYseV3r9LkME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone XXX\n",
        "os.chdir(\"CNN_PBX_Model\")"
      ],
      "metadata": {
        "id": "Cr1dF6TJHU2J",
        "outputId": "14a57b53-fb9c-4cde-a709-1a981a66bfed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'CNN_PBX_Model' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and validation data\n",
        "\n",
        "This notebook was designed to read everything in the ```/train/``` folder as training data and everything in the ```/validation/``` folder as validation data. These directories contain individual labeled subdirectories that represent each of our simulation systems (data points).\n",
        "\n",
        "In each of the simulation systems subdirectories there are two files as numpy arrays: ```input.npy``` and ```output.npy```.\n",
        "\n",
        "\n",
        "```input.npy``` contains a (16 x 34 x 34 x 3) array with the input mappings from our simulations. The first three numbers represent the dimensions (in bins) of our system. The last number represents the number of mappings for our inputs. For each of our 3D structures, we generate the following:\n",
        "- Total density\n",
        "- HE density\n",
        "- GB interface parameter\n",
        "\n",
        "```output.npy``` contains a (16 x 32 x 32 x 1) array with the output mapping (temperature) from our simulations. The first three numbers represent the dimensions (in bins) of our system, but note that they are different from the inputs due to periodic boundary conditions. The last number represents the temperature mapping. \n",
        "- Temperature\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B2wbmJTjOpoe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please verify that after running the next cells you get the following results:\n",
        "\n",
        "<b>Training data:</b><br>\n",
        "\n",
        "(64, 16, 34, 34, 3) <br>\n",
        "(64, 16, 32, 32, 1) <br>\n",
        "\n",
        "<b>Validation data:</b><br>\n",
        "\n",
        "(28, 16, 34, 34, 3) <br>\n",
        "(28, 16, 32, 32, 1) <br>\n",
        "\n",
        "You can see that there is a new number in these arrays. It indicates the number of datapoints in each set. You can read this as having 64 points with (16 x 34 x 34 x 3) shape."
      ],
      "metadata": {
        "id": "ogxA0zxHRUIl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KZxqA1mmG_nz",
        "outputId": "2c6bfcda-3f74-4fe3-bf5b-7290b322677b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 16, 34, 34, 3)\n",
            "(64, 16, 32, 32, 1)\n"
          ]
        }
      ],
      "source": [
        "# TRAINING DATA\n",
        "\n",
        "paths = [x[0] for x in os.walk('train/')][1:]\n",
        "\n",
        "train_data = []\n",
        "train_labels = []\n",
        "\n",
        "for i in paths:\n",
        "  train_ex = np.load(i + \"/input.npy\")\n",
        "\n",
        "  if train_ex.shape != (16,34,34,3):\n",
        "\n",
        "    first_axis_pad = int(0.5 * (34 - train_ex.shape[1]))\n",
        "    second_axis_pad = int(0.5 * (34 - train_ex.shape[2]))\n",
        "\n",
        "    train_ex = np.pad(train_ex, ((0, 0), (first_axis_pad, first_axis_pad), (second_axis_pad, second_axis_pad), (0,0)), 'wrap')\n",
        "\n",
        "  train_lb = np.load(i + \"/output.npy\")\n",
        "  train_data.append(train_ex)\n",
        "  train_labels.append(train_lb)\n",
        "\n",
        "train_data = np.array(train_data)\n",
        "train_labels = np.array(train_labels) / 1000\n",
        "\n",
        "print(train_data.shape)\n",
        "print(train_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "02ORxH_vZNOC",
        "outputId": "f18c1dfa-4875-4da1-e9cc-0b4f5951a927",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(28, 16, 34, 34, 3)\n",
            "(28, 16, 32, 32, 1)\n"
          ]
        }
      ],
      "source": [
        "# VALIDATION DATA\n",
        "\n",
        "validation_paths = [x[0] for x in os.walk('validation/')][1:]\n",
        "\n",
        "validation_data = []\n",
        "validation_labels = []\n",
        "\n",
        "for i in validation_paths:\n",
        "  validation_ex= np.load(i + \"/input.npy\")\n",
        "\n",
        "  if validation_ex.shape != (16,34,34,1):\n",
        "\n",
        "    first_axis_pad = int(0.5 * (34 - validation_ex.shape[1]))\n",
        "    second_axis_pad = int(0.5 * (34 - validation_ex.shape[2]))\n",
        "\n",
        "    validation_ex = np.pad(validation_ex, ((0, 0), (first_axis_pad, first_axis_pad), (second_axis_pad, second_axis_pad), (0,0)), 'wrap')\n",
        "\n",
        "\n",
        "  validation_lb = np.load(i + \"/output.npy\")\n",
        "  validation_data.append(validation_ex)\n",
        "  validation_labels.append(validation_lb)\n",
        "\n",
        "validation_data = np.array(validation_data)\n",
        "validation_labels = np.array(validation_labels) / 1000\n",
        "\n",
        "print(validation_data.shape)\n",
        "print(validation_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model\n",
        "\n",
        "This notebook creates an architecture based on U-Net, a CNN algorithm for image segmentation. We will go a bit into the design of the architecture in the following cells.\n",
        "\n",
        "This first function addresses periodic padding for tensors in the model."
      ],
      "metadata": {
        "id": "xQrUeLx5R1mp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fWvLsqQXsWGy"
      },
      "outputs": [],
      "source": [
        "# Code taken from: https://stackoverflow.com/questions/39088489/tensorflow-periodic-padding\n",
        "\n",
        "def periodic_padding_flexible(tensor, axis, padding=1):\n",
        "\n",
        "    if isinstance(axis,int):\n",
        "        axis = (axis,)\n",
        "    if isinstance(padding,int):\n",
        "        padding = (padding,)\n",
        "\n",
        "    ndim = len(tensor.shape)\n",
        "\n",
        "    for ax,p in zip(axis,padding):\n",
        "        # create a slice object that selects everything from all axes,\n",
        "        # except only 0:p for the specified for right, and -p: for left\n",
        "\n",
        "        ind_right = [slice(-p,None) if i == ax else slice(None) for i in range(ndim)]\n",
        "        ind_left = [slice(0, p) if i == ax else slice(None) for i in range(ndim)]\n",
        "        right = tensor[ind_right]\n",
        "        left = tensor[ind_left]\n",
        "        middle = tensor\n",
        "        tensor = tf.concat([right,middle,left], axis=ax)\n",
        "\n",
        "    return tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since this architecture is going to be complicated, we will start by creating mini-blocks. This first function ```DownConvBlock``` executes the following operations sequentially:\n",
        "\n",
        "- (Optional) Periodic Padding\n",
        "- 3D Convolutional Layer\n",
        "- Periodic Padding\n",
        "- 3D Convolutional Layer\n",
        "- Batch normalization\n",
        "- (Optional) MaxPooling3D Layer"
      ],
      "metadata": {
        "id": "i2sWbazsagHg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rLhZ3NIocWJ9"
      },
      "outputs": [],
      "source": [
        "def DownConvBlock(inputs, n_filters=32, filter_size = 3, max_pooling=True, special_padding=False):\n",
        "\n",
        "  padding_size = int((filter_size-1)/2)\n",
        "  kernel_init =   tf.keras.initializers.GlorotUniform(seed=0)\n",
        "  bias_init = tf.keras.initializers.Zeros()\n",
        "\n",
        "\n",
        "  # PERIODIC PADDING\n",
        "\n",
        "  inputs = periodic_padding_flexible(inputs, axis=1,padding=padding_size)\n",
        "  if special_padding == False:\n",
        "    inputs = periodic_padding_flexible(inputs, axis=2,padding=padding_size)\n",
        "    inputs = periodic_padding_flexible(inputs, axis=3,padding=padding_size)\n",
        "  \n",
        "  conv = Conv3D(n_filters, filter_size, activation='relu', padding='valid', kernel_initializer=kernel_init, bias_initializer=bias_init)(inputs)\n",
        "  print(conv.shape)\n",
        "  conv = periodic_padding_flexible(conv, axis=(1,2,3),padding=(padding_size,padding_size,padding_size))\n",
        "  conv = Conv3D(n_filters, filter_size, activation='relu', padding='valid', kernel_initializer=kernel_init, bias_initializer=bias_init)(conv)\n",
        "  print(conv.shape)\n",
        "  conv = BatchNormalization()(conv, training=False)\n",
        "      \n",
        "  if max_pooling:\n",
        "    next_layer = tf.keras.layers.MaxPooling3D(pool_size = (2,2,2))(conv)\n",
        "  else:\n",
        "    next_layer = conv\n",
        "  \n",
        "  skip_connection = conv   \n",
        "\n",
        "  print(\"end_of_block\") \n",
        "  return next_layer, skip_connection"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This second function ```UpConvBlock``` executes the following operations sequentially:\n",
        "\n",
        "- Transpose 3D Convolutional Layer\n",
        "- Merge with <i>skip connection</i> from the corresponding ```DownConvBlock```\n",
        "- Periodic Padding\n",
        "- 3D Convolutional Layer\n",
        "- Periodic Padding\n",
        "- 3D Convolutional Layer"
      ],
      "metadata": {
        "id": "i8h2MOJHa_Aq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YvMNFlsHseOF"
      },
      "outputs": [],
      "source": [
        "def UpConvBlock(prev_layer_input, skip_layer_input, filter_size = 3, n_filters=32):\n",
        "\n",
        "    padding_size = int((filter_size-1)/2)\n",
        "    kernel_init = tf.keras.initializers.GlorotUniform(seed=0)\n",
        "    bias_init = tf.keras.initializers.Zeros()   \n",
        "\n",
        "    up = Conv3DTranspose(n_filters, (filter_size,filter_size,filter_size),\n",
        "                         strides=(filter_size-1,filter_size-1,filter_size-1),\n",
        "                         padding='same', kernel_initializer=kernel_init, bias_initializer=bias_init)(prev_layer_input)\n",
        "\n",
        "    merge = concatenate([up, skip_layer_input], axis=4)\n",
        "    merge = periodic_padding_flexible(merge, axis=(1,2,3),padding=(padding_size,padding_size,padding_size))\n",
        "    conv = Conv3D(n_filters, filter_size, activation='relu', padding='valid', kernel_initializer=kernel_init,  bias_initializer=bias_init)(merge)\n",
        "    print(conv.shape)\n",
        "    conv = periodic_padding_flexible(conv, axis=(1,2,3),padding=(padding_size,padding_size,padding_size))\n",
        "    conv = Conv3D(n_filters, filter_size, activation='relu',padding='valid', kernel_initializer=kernel_init,  bias_initializer=bias_init)(conv)\n",
        "    print(conv.shape)\n",
        "\n",
        "    print(\"end_of_block\")\n",
        "    return conv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The architecture will be composed of several ```DownConvBlock``` blocks followed by the same number of ```UpConvBlock``` blocks. "
      ],
      "metadata": {
        "id": "evWdWAkXbzfq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fe-fUh99sgKg"
      },
      "outputs": [],
      "source": [
        "\n",
        "def UNet3DModel(input_size=(16, 34, 34, 3), n_filters=32, filter_size=3, n_classes=1):\n",
        "  kernel_init =  tf.keras.initializers.GlorotUniform(seed=0)\n",
        "  bias_init = tf.keras.initializers.Zeros()  \n",
        "  \n",
        "  inputs = Input(input_size)\n",
        "  print(\"Inputs\", inputs.shape)\n",
        "\n",
        "  cblock0 = DownConvBlock(inputs,     n_filters = n_filters    , filter_size = filter_size, max_pooling=False, special_padding=True)\n",
        "  print(\"CB0\", cblock0[0].shape)\n",
        "\n",
        "  cblock1 = DownConvBlock(cblock0[0],     n_filters = n_filters    , filter_size = filter_size, max_pooling=True, special_padding=False)\n",
        "  print(\"CB1\", cblock1[0].shape)\n",
        "\n",
        "  cblock2 = DownConvBlock(cblock1[0], n_filters = n_filters*2  , filter_size = filter_size, max_pooling=True, special_padding=False)\n",
        "  print(\"CB2\", cblock2[0].shape)\n",
        "    \n",
        "  cblock3 = DownConvBlock(cblock2[0], n_filters = n_filters*4  , filter_size = filter_size, max_pooling=True, special_padding=False)\n",
        "  print(\"CB3\", cblock3[0].shape)\n",
        "  \n",
        "  cblock4 = DownConvBlock(cblock3[0], n_filters = n_filters*8  , filter_size = filter_size, max_pooling=False, special_padding=False)\n",
        "  print(\"CB4\", cblock4[0].shape)\n",
        "\n",
        "\n",
        "  print(\"------------------\")\n",
        "\n",
        "  ublock7 = UpConvBlock(cblock4[0]   , cblock3[1],  n_filters = n_filters * 4, filter_size = filter_size)\n",
        "  print(\"UB7\", ublock7.shape)\n",
        "  \n",
        "  ublock8 = UpConvBlock(ublock7   , cblock2[1],  n_filters = n_filters * 2, filter_size = filter_size)\n",
        "  print(\"UB8\", ublock8.shape)\n",
        "  \n",
        "  ublock9 = UpConvBlock(ublock8   , cblock1[1],  n_filters = n_filters, filter_size = filter_size)\n",
        "  print(\"UB9\", ublock9.shape)\n",
        "\n",
        "  ublock9 = periodic_padding_flexible(ublock9, axis=(1,2,3),padding=(1,1,1))\n",
        "  \n",
        "  conv9 = Conv3D(n_filters, 3, activation='relu', padding='valid', kernel_initializer=kernel_init,  bias_initializer=bias_init)(ublock9)\n",
        "  print(\"C9\", conv9.shape)\n",
        "  \n",
        "  conv10 = Conv3D(n_classes, 1, padding='same', kernel_initializer=kernel_init,  bias_initializer=bias_init)(conv9)\n",
        "  print(\"C10\", conv10.shape)\n",
        "\n",
        "  model = tf.keras.Model(inputs=inputs, outputs=conv10)  \n",
        "\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this application, we are concerned with the detection and accurate prediction of hotspots (areas with higher temperatures), which are significantly less common than the rest of the material at a lower temperature. To address this, we are using a custon loss function based on a weighted Mean Squared Error (MSE)."
      ],
      "metadata": {
        "id": "vUDnv4nLeTQH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "d2a5FVUYPHTB"
      },
      "outputs": [],
      "source": [
        "def custom_mse(y_true,y_pred):\n",
        "    w_hot = 5.0\n",
        "    w_cold = 1.0\n",
        "    cutoff = 1.8\n",
        "    weightmat = tf.cast(tf.where(tf.greater(y_true, cutoff), w_hot, w_cold),float)\n",
        "    loss = tf.cast(K.square(y_pred - y_true),float)\n",
        "    loss = loss*weightmat\n",
        "    loss = K.mean(loss)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, this last cell calls the function to generate the model, pair it with an optimizer and compile the model object."
      ],
      "metadata": {
        "id": "-uvZjSSeekHu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "R3SJtgKps6tc",
        "outputId": "0d4ee17f-e01d-4c69-98bf-1c2dc27a37f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs (None, 16, 34, 34, 3)\n",
            "(None, 16, 32, 32, 32)\n",
            "(None, 16, 32, 32, 32)\n",
            "end_of_block\n",
            "CB0 (None, 16, 32, 32, 32)\n",
            "(None, 16, 32, 32, 32)\n",
            "(None, 16, 32, 32, 32)\n",
            "end_of_block\n",
            "CB1 (None, 8, 16, 16, 32)\n",
            "(None, 8, 16, 16, 64)\n",
            "(None, 8, 16, 16, 64)\n",
            "end_of_block\n",
            "CB2 (None, 4, 8, 8, 64)\n",
            "(None, 4, 8, 8, 128)\n",
            "(None, 4, 8, 8, 128)\n",
            "end_of_block\n",
            "CB3 (None, 2, 4, 4, 128)\n",
            "(None, 2, 4, 4, 256)\n",
            "(None, 2, 4, 4, 256)\n",
            "end_of_block\n",
            "CB4 (None, 2, 4, 4, 256)\n",
            "------------------\n",
            "(None, 4, 8, 8, 128)\n",
            "(None, 4, 8, 8, 128)\n",
            "end_of_block\n",
            "UB7 (None, 4, 8, 8, 128)\n",
            "(None, 8, 16, 16, 64)\n",
            "(None, 8, 16, 16, 64)\n",
            "end_of_block\n",
            "UB8 (None, 8, 16, 16, 64)\n",
            "(None, 16, 32, 32, 32)\n",
            "(None, 16, 32, 32, 32)\n",
            "end_of_block\n",
            "UB9 (None, 16, 32, 32, 32)\n",
            "C9 (None, 16, 32, 32, 32)\n",
            "C10 (None, 16, 32, 32, 1)\n"
          ]
        }
      ],
      "source": [
        "model = UNet3DModel(input_size=(16, 34, 34, 3), n_filters=32, filter_size = 3, n_classes=1)\n",
        "optimizer = tf.optimizers.Adam(learning_rate = 0.0005)\n",
        "model.compile(loss=custom_mse, optimizer=optimizer, metrics=['mse'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the model\n",
        "\n",
        "This cell implements two techniques to prevent overfitting. The first one is a learning rate scheduler that decreases the learning rate after a fixed number of epochs. The second one is an early stopping criteria that monitors the validation loss to ensure the model continues to learn."
      ],
      "metadata": {
        "id": "BLFb04QIevl2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "baIEkfpntuOW",
        "outputId": "0db04ac3-88ee-4eb3-9f2d-6858034aff1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "2/2 [==============================] - 18s 3s/step - loss: 1.4051 - mse: 0.9419 - val_loss: 0.9628 - val_mse: 0.7017 - lr: 5.0000e-04\n",
            "Epoch 2/1000\n",
            "2/2 [==============================] - 2s 877ms/step - loss: 0.9582 - mse: 0.5789 - val_loss: 0.5171 - val_mse: 0.4807 - lr: 5.0000e-04\n",
            "Epoch 3/1000\n",
            "2/2 [==============================] - 2s 872ms/step - loss: 0.4949 - mse: 0.3313 - val_loss: 0.3276 - val_mse: 0.1677 - lr: 5.0000e-04\n",
            "Epoch 4/1000\n",
            "2/2 [==============================] - 2s 870ms/step - loss: 0.4529 - mse: 0.1915 - val_loss: 0.2154 - val_mse: 0.0925 - lr: 5.0000e-04\n",
            "Epoch 5/1000\n",
            "2/2 [==============================] - 1s 843ms/step - loss: 0.3324 - mse: 0.1479 - val_loss: 0.3195 - val_mse: 0.2573 - lr: 5.0000e-04\n",
            "Epoch 6/1000\n",
            "2/2 [==============================] - 2s 871ms/step - loss: 0.3768 - mse: 0.2518 - val_loss: 0.1942 - val_mse: 0.1054 - lr: 5.0000e-04\n",
            "Epoch 7/1000\n",
            "2/2 [==============================] - 2s 879ms/step - loss: 0.2940 - mse: 0.1251 - val_loss: 0.1833 - val_mse: 0.0776 - lr: 5.0000e-04\n",
            "Epoch 8/1000\n",
            "2/2 [==============================] - 2s 876ms/step - loss: 0.2681 - mse: 0.1038 - val_loss: 0.1828 - val_mse: 0.1304 - lr: 5.0000e-04\n",
            "Epoch 9/1000\n",
            "2/2 [==============================] - 2s 879ms/step - loss: 0.2381 - mse: 0.1419 - val_loss: 0.1290 - val_mse: 0.0555 - lr: 5.0000e-04\n",
            "Epoch 10/1000\n",
            "2/2 [==============================] - 2s 878ms/step - loss: 0.2010 - mse: 0.0788 - val_loss: 0.0964 - val_mse: 0.0470 - lr: 5.0000e-04\n",
            "Epoch 11/1000\n",
            "2/2 [==============================] - 2s 879ms/step - loss: 0.1601 - mse: 0.1019 - val_loss: 0.0786 - val_mse: 0.0422 - lr: 5.0000e-04\n",
            "Epoch 12/1000\n",
            "2/2 [==============================] - 1s 829ms/step - loss: 0.1270 - mse: 0.0636 - val_loss: 0.0840 - val_mse: 0.0465 - lr: 5.0000e-04\n",
            "Epoch 13/1000\n",
            "2/2 [==============================] - 2s 878ms/step - loss: 0.1175 - mse: 0.0757 - val_loss: 0.0705 - val_mse: 0.0500 - lr: 5.0000e-04\n",
            "Epoch 14/1000\n",
            "2/2 [==============================] - 2s 852ms/step - loss: 0.1122 - mse: 0.0751 - val_loss: 0.0944 - val_mse: 0.0629 - lr: 5.0000e-04\n",
            "Epoch 15/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.1107 - mse: 0.0747 - val_loss: 0.0694 - val_mse: 0.0516 - lr: 5.0000e-04\n",
            "Epoch 16/1000\n",
            "2/2 [==============================] - 2s 867ms/step - loss: 0.1023 - mse: 0.0733 - val_loss: 0.0778 - val_mse: 0.0504 - lr: 5.0000e-04\n",
            "Epoch 17/1000\n",
            "2/2 [==============================] - 2s 920ms/step - loss: 0.0951 - mse: 0.0600 - val_loss: 0.0591 - val_mse: 0.0417 - lr: 5.0000e-04\n",
            "Epoch 18/1000\n",
            "2/2 [==============================] - 2s 862ms/step - loss: 0.0906 - mse: 0.0641 - val_loss: 0.0608 - val_mse: 0.0360 - lr: 5.0000e-04\n",
            "Epoch 19/1000\n",
            "2/2 [==============================] - 2s 902ms/step - loss: 0.0891 - mse: 0.0503 - val_loss: 0.0570 - val_mse: 0.0350 - lr: 5.0000e-04\n",
            "Epoch 20/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0862 - mse: 0.0552 - val_loss: 0.0558 - val_mse: 0.0373 - lr: 5.0000e-04\n",
            "Epoch 21/1000\n",
            "2/2 [==============================] - 2s 994ms/step - loss: 0.0836 - mse: 0.0533 - val_loss: 0.0582 - val_mse: 0.0355 - lr: 5.0000e-04\n",
            "Epoch 22/1000\n",
            "2/2 [==============================] - 2s 911ms/step - loss: 0.0820 - mse: 0.0500 - val_loss: 0.0544 - val_mse: 0.0389 - lr: 5.0000e-04\n",
            "Epoch 23/1000\n",
            "2/2 [==============================] - 2s 866ms/step - loss: 0.0795 - mse: 0.0557 - val_loss: 0.0577 - val_mse: 0.0392 - lr: 5.0000e-04\n",
            "Epoch 24/1000\n",
            "2/2 [==============================] - 2s 898ms/step - loss: 0.0785 - mse: 0.0506 - val_loss: 0.0533 - val_mse: 0.0384 - lr: 5.0000e-04\n",
            "Epoch 25/1000\n",
            "2/2 [==============================] - 2s 896ms/step - loss: 0.0757 - mse: 0.0525 - val_loss: 0.0513 - val_mse: 0.0357 - lr: 5.0000e-04\n",
            "Epoch 26/1000\n",
            "2/2 [==============================] - 2s 896ms/step - loss: 0.0740 - mse: 0.0480 - val_loss: 0.0494 - val_mse: 0.0330 - lr: 5.0000e-04\n",
            "Epoch 27/1000\n",
            "2/2 [==============================] - 2s 919ms/step - loss: 0.0725 - mse: 0.0477 - val_loss: 0.0479 - val_mse: 0.0318 - lr: 5.0000e-04\n",
            "Epoch 28/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0716 - mse: 0.0450 - val_loss: 0.0474 - val_mse: 0.0310 - lr: 5.0000e-04\n",
            "Epoch 29/1000\n",
            "2/2 [==============================] - 2s 906ms/step - loss: 0.0699 - mse: 0.0446 - val_loss: 0.0463 - val_mse: 0.0326 - lr: 5.0000e-04\n",
            "Epoch 30/1000\n",
            "2/2 [==============================] - 2s 998ms/step - loss: 0.0690 - mse: 0.0458 - val_loss: 0.0475 - val_mse: 0.0321 - lr: 5.0000e-04\n",
            "Epoch 31/1000\n",
            "2/2 [==============================] - 2s 874ms/step - loss: 0.0691 - mse: 0.0462 - val_loss: 0.0465 - val_mse: 0.0316 - lr: 5.0000e-04\n",
            "Epoch 32/1000\n",
            "2/2 [==============================] - 2s 897ms/step - loss: 0.0667 - mse: 0.0430 - val_loss: 0.0451 - val_mse: 0.0309 - lr: 5.0000e-04\n",
            "Epoch 33/1000\n",
            "2/2 [==============================] - 2s 908ms/step - loss: 0.0661 - mse: 0.0427 - val_loss: 0.0445 - val_mse: 0.0315 - lr: 5.0000e-04\n",
            "Epoch 34/1000\n",
            "2/2 [==============================] - 2s 873ms/step - loss: 0.0654 - mse: 0.0446 - val_loss: 0.0477 - val_mse: 0.0302 - lr: 5.0000e-04\n",
            "Epoch 35/1000\n",
            "2/2 [==============================] - 2s 872ms/step - loss: 0.0654 - mse: 0.0400 - val_loss: 0.0445 - val_mse: 0.0333 - lr: 5.0000e-04\n",
            "Epoch 36/1000\n",
            "2/2 [==============================] - 2s 875ms/step - loss: 0.0646 - mse: 0.0444 - val_loss: 0.0481 - val_mse: 0.0305 - lr: 5.0000e-04\n",
            "Epoch 37/1000\n",
            "2/2 [==============================] - 2s 913ms/step - loss: 0.0641 - mse: 0.0399 - val_loss: 0.0437 - val_mse: 0.0327 - lr: 5.0000e-04\n",
            "Epoch 38/1000\n",
            "2/2 [==============================] - 2s 886ms/step - loss: 0.0648 - mse: 0.0441 - val_loss: 0.0447 - val_mse: 0.0291 - lr: 5.0000e-04\n",
            "Epoch 39/1000\n",
            "2/2 [==============================] - 2s 882ms/step - loss: 0.0606 - mse: 0.0387 - val_loss: 0.0442 - val_mse: 0.0339 - lr: 5.0000e-04\n",
            "Epoch 40/1000\n",
            "2/2 [==============================] - 2s 881ms/step - loss: 0.0637 - mse: 0.0432 - val_loss: 0.0472 - val_mse: 0.0297 - lr: 5.0000e-04\n",
            "Epoch 41/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0619 - mse: 0.0395 - val_loss: 0.0415 - val_mse: 0.0308 - lr: 5.0000e-04\n",
            "Epoch 42/1000\n",
            "2/2 [==============================] - 2s 886ms/step - loss: 0.0609 - mse: 0.0406 - val_loss: 0.0441 - val_mse: 0.0286 - lr: 5.0000e-04\n",
            "Epoch 43/1000\n",
            "2/2 [==============================] - 2s 914ms/step - loss: 0.0584 - mse: 0.0379 - val_loss: 0.0410 - val_mse: 0.0304 - lr: 5.0000e-04\n",
            "Epoch 44/1000\n",
            "2/2 [==============================] - 2s 892ms/step - loss: 0.0598 - mse: 0.0405 - val_loss: 0.0442 - val_mse: 0.0278 - lr: 5.0000e-04\n",
            "Epoch 45/1000\n",
            "2/2 [==============================] - 2s 911ms/step - loss: 0.0598 - mse: 0.0396 - val_loss: 0.0385 - val_mse: 0.0271 - lr: 5.0000e-04\n",
            "Epoch 46/1000\n",
            "2/2 [==============================] - 2s 884ms/step - loss: 0.0569 - mse: 0.0374 - val_loss: 0.0414 - val_mse: 0.0274 - lr: 5.0000e-04\n",
            "Epoch 47/1000\n",
            "2/2 [==============================] - 2s 884ms/step - loss: 0.0574 - mse: 0.0396 - val_loss: 0.0396 - val_mse: 0.0267 - lr: 5.0000e-04\n",
            "Epoch 48/1000\n",
            "2/2 [==============================] - 2s 911ms/step - loss: 0.0568 - mse: 0.0367 - val_loss: 0.0369 - val_mse: 0.0266 - lr: 5.0000e-04\n",
            "Epoch 49/1000\n",
            "2/2 [==============================] - 2s 885ms/step - loss: 0.0567 - mse: 0.0410 - val_loss: 0.0457 - val_mse: 0.0281 - lr: 5.0000e-04\n",
            "Epoch 50/1000\n",
            "2/2 [==============================] - 2s 883ms/step - loss: 0.0575 - mse: 0.0350 - val_loss: 0.0380 - val_mse: 0.0280 - lr: 5.0000e-04\n",
            "Epoch 51/1000\n",
            "2/2 [==============================] - 2s 877ms/step - loss: 0.0557 - mse: 0.0386 - val_loss: 0.0386 - val_mse: 0.0260 - lr: 5.0000e-04\n",
            "Epoch 52/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0527 - mse: 0.0361 - val_loss: 0.0366 - val_mse: 0.0251 - lr: 5.0000e-04\n",
            "Epoch 53/1000\n",
            "2/2 [==============================] - 2s 922ms/step - loss: 0.0513 - mse: 0.0339 - val_loss: 0.0362 - val_mse: 0.0241 - lr: 5.0000e-04\n",
            "Epoch 54/1000\n",
            "2/2 [==============================] - 2s 891ms/step - loss: 0.0507 - mse: 0.0351 - val_loss: 0.0378 - val_mse: 0.0243 - lr: 5.0000e-04\n",
            "Epoch 55/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0508 - mse: 0.0341 - val_loss: 0.0365 - val_mse: 0.0250 - lr: 5.0000e-04\n",
            "Epoch 56/1000\n",
            "2/2 [==============================] - 2s 882ms/step - loss: 0.0488 - mse: 0.0332 - val_loss: 0.0360 - val_mse: 0.0248 - lr: 5.0000e-04\n",
            "Epoch 57/1000\n",
            "2/2 [==============================] - 2s 878ms/step - loss: 0.0482 - mse: 0.0340 - val_loss: 0.0402 - val_mse: 0.0255 - lr: 5.0000e-04\n",
            "Epoch 58/1000\n",
            "2/2 [==============================] - 2s 917ms/step - loss: 0.0486 - mse: 0.0319 - val_loss: 0.0345 - val_mse: 0.0252 - lr: 5.0000e-04\n",
            "Epoch 59/1000\n",
            "2/2 [==============================] - 2s 879ms/step - loss: 0.0472 - mse: 0.0327 - val_loss: 0.0424 - val_mse: 0.0275 - lr: 5.0000e-04\n",
            "Epoch 60/1000\n",
            "2/2 [==============================] - 2s 872ms/step - loss: 0.0564 - mse: 0.0409 - val_loss: 0.0447 - val_mse: 0.0283 - lr: 5.0000e-04\n",
            "Epoch 61/1000\n",
            "2/2 [==============================] - 2s 873ms/step - loss: 0.0533 - mse: 0.0327 - val_loss: 0.0365 - val_mse: 0.0280 - lr: 5.0000e-04\n",
            "Epoch 62/1000\n",
            "2/2 [==============================] - 2s 872ms/step - loss: 0.0527 - mse: 0.0380 - val_loss: 0.0411 - val_mse: 0.0260 - lr: 5.0000e-04\n",
            "Epoch 63/1000\n",
            "2/2 [==============================] - 2s 878ms/step - loss: 0.0494 - mse: 0.0324 - val_loss: 0.0343 - val_mse: 0.0248 - lr: 5.0000e-04\n",
            "Epoch 64/1000\n",
            "2/2 [==============================] - 2s 866ms/step - loss: 0.0460 - mse: 0.0322 - val_loss: 0.0445 - val_mse: 0.0281 - lr: 5.0000e-04\n",
            "Epoch 65/1000\n",
            "2/2 [==============================] - 2s 907ms/step - loss: 0.0505 - mse: 0.0338 - val_loss: 0.0337 - val_mse: 0.0242 - lr: 5.0000e-04\n",
            "Epoch 66/1000\n",
            "2/2 [==============================] - 2s 878ms/step - loss: 0.0468 - mse: 0.0325 - val_loss: 0.0358 - val_mse: 0.0242 - lr: 5.0000e-04\n",
            "Epoch 67/1000\n",
            "2/2 [==============================] - 2s 878ms/step - loss: 0.0467 - mse: 0.0337 - val_loss: 0.0339 - val_mse: 0.0228 - lr: 5.0000e-04\n",
            "Epoch 68/1000\n",
            "2/2 [==============================] - 2s 865ms/step - loss: 0.0442 - mse: 0.0296 - val_loss: 0.0333 - val_mse: 0.0226 - lr: 5.0000e-04\n",
            "Epoch 69/1000\n",
            "2/2 [==============================] - 2s 867ms/step - loss: 0.0428 - mse: 0.0306 - val_loss: 0.0365 - val_mse: 0.0240 - lr: 5.0000e-04\n",
            "Epoch 70/1000\n",
            "2/2 [==============================] - 2s 867ms/step - loss: 0.0418 - mse: 0.0290 - val_loss: 0.0340 - val_mse: 0.0233 - lr: 5.0000e-04\n",
            "Epoch 71/1000\n",
            "2/2 [==============================] - 2s 875ms/step - loss: 0.0409 - mse: 0.0289 - val_loss: 0.0340 - val_mse: 0.0230 - lr: 5.0000e-04\n",
            "Epoch 72/1000\n",
            "2/2 [==============================] - 2s 871ms/step - loss: 0.0406 - mse: 0.0295 - val_loss: 0.0374 - val_mse: 0.0240 - lr: 5.0000e-04\n",
            "Epoch 73/1000\n",
            "2/2 [==============================] - 2s 872ms/step - loss: 0.0402 - mse: 0.0276 - val_loss: 0.0333 - val_mse: 0.0240 - lr: 5.0000e-04\n",
            "Epoch 74/1000\n",
            "2/2 [==============================] - 2s 894ms/step - loss: 0.0463 - mse: 0.0329 - val_loss: 0.0329 - val_mse: 0.0221 - lr: 5.0000e-04\n",
            "Epoch 75/1000\n",
            "2/2 [==============================] - 2s 876ms/step - loss: 0.0412 - mse: 0.0308 - val_loss: 0.0369 - val_mse: 0.0236 - lr: 5.0000e-04\n",
            "Epoch 76/1000\n",
            "2/2 [==============================] - 2s 870ms/step - loss: 0.0392 - mse: 0.0266 - val_loss: 0.0333 - val_mse: 0.0231 - lr: 5.0000e-04\n",
            "Epoch 77/1000\n",
            "2/2 [==============================] - 2s 875ms/step - loss: 0.0373 - mse: 0.0278 - val_loss: 0.0417 - val_mse: 0.0272 - lr: 5.0000e-04\n",
            "Epoch 78/1000\n",
            "2/2 [==============================] - 2s 876ms/step - loss: 0.0375 - mse: 0.0261 - val_loss: 0.0335 - val_mse: 0.0249 - lr: 5.0000e-04\n",
            "Epoch 79/1000\n",
            "2/2 [==============================] - 2s 874ms/step - loss: 0.0440 - mse: 0.0323 - val_loss: 0.0347 - val_mse: 0.0221 - lr: 5.0000e-04\n",
            "Epoch 80/1000\n",
            "2/2 [==============================] - 2s 863ms/step - loss: 0.0443 - mse: 0.0339 - val_loss: 0.0410 - val_mse: 0.0269 - lr: 5.0000e-04\n",
            "Epoch 81/1000\n",
            "2/2 [==============================] - 2s 868ms/step - loss: 0.0401 - mse: 0.0272 - val_loss: 0.0339 - val_mse: 0.0249 - lr: 5.0000e-04\n",
            "Epoch 82/1000\n",
            "2/2 [==============================] - 2s 877ms/step - loss: 0.0375 - mse: 0.0285 - val_loss: 0.0399 - val_mse: 0.0247 - lr: 5.0000e-04\n",
            "Epoch 83/1000\n",
            "2/2 [==============================] - 2s 873ms/step - loss: 0.0361 - mse: 0.0247 - val_loss: 0.0335 - val_mse: 0.0243 - lr: 5.0000e-04\n",
            "Epoch 84/1000\n",
            "2/2 [==============================] - 2s 869ms/step - loss: 0.0345 - mse: 0.0258 - val_loss: 0.0411 - val_mse: 0.0272 - lr: 5.0000e-04\n",
            "Epoch 85/1000\n",
            "2/2 [==============================] - 2s 874ms/step - loss: 0.0348 - mse: 0.0253 - val_loss: 0.0324 - val_mse: 0.0230 - lr: 5.0000e-04\n",
            "Epoch 86/1000\n",
            "2/2 [==============================] - 2s 868ms/step - loss: 0.0362 - mse: 0.0263 - val_loss: 0.0337 - val_mse: 0.0224 - lr: 5.0000e-04\n",
            "Epoch 87/1000\n",
            "2/2 [==============================] - 2s 873ms/step - loss: 0.0335 - mse: 0.0260 - val_loss: 0.0398 - val_mse: 0.0253 - lr: 5.0000e-04\n",
            "Epoch 88/1000\n",
            "2/2 [==============================] - 2s 872ms/step - loss: 0.0324 - mse: 0.0222 - val_loss: 0.0334 - val_mse: 0.0241 - lr: 5.0000e-04\n",
            "Epoch 89/1000\n",
            "2/2 [==============================] - 2s 873ms/step - loss: 0.0305 - mse: 0.0236 - val_loss: 0.0437 - val_mse: 0.0283 - lr: 5.0000e-04\n",
            "Epoch 90/1000\n",
            "2/2 [==============================] - 2s 869ms/step - loss: 0.0312 - mse: 0.0223 - val_loss: 0.0332 - val_mse: 0.0242 - lr: 5.0000e-04\n",
            "Epoch 91/1000\n",
            "2/2 [==============================] - 2s 875ms/step - loss: 0.0314 - mse: 0.0233 - val_loss: 0.0420 - val_mse: 0.0267 - lr: 5.0000e-04\n",
            "Epoch 92/1000\n",
            "2/2 [==============================] - 2s 873ms/step - loss: 0.0340 - mse: 0.0257 - val_loss: 0.0352 - val_mse: 0.0235 - lr: 5.0000e-04\n",
            "Epoch 93/1000\n",
            "2/2 [==============================] - 2s 877ms/step - loss: 0.0298 - mse: 0.0219 - val_loss: 0.0337 - val_mse: 0.0230 - lr: 5.0000e-04\n",
            "Epoch 94/1000\n",
            "2/2 [==============================] - 2s 874ms/step - loss: 0.0277 - mse: 0.0215 - val_loss: 0.0397 - val_mse: 0.0258 - lr: 5.0000e-04\n",
            "Epoch 95/1000\n",
            "2/2 [==============================] - 2s 876ms/step - loss: 0.0266 - mse: 0.0194 - val_loss: 0.0340 - val_mse: 0.0238 - lr: 5.0000e-04\n",
            "Epoch 96/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0262 - mse: 0.0201 - val_loss: 0.0373 - val_mse: 0.0246 - lr: 5.0000e-04\n",
            "Epoch 97/1000\n",
            "2/2 [==============================] - 2s 881ms/step - loss: 0.0253 - mse: 0.0193 - val_loss: 0.0388 - val_mse: 0.0260 - lr: 5.0000e-04\n",
            "Epoch 98/1000\n",
            "2/2 [==============================] - 2s 871ms/step - loss: 0.0240 - mse: 0.0181 - val_loss: 0.0346 - val_mse: 0.0238 - lr: 5.0000e-04\n",
            "Epoch 99/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0242 - mse: 0.0186 - val_loss: 0.0367 - val_mse: 0.0247 - lr: 5.0000e-04\n",
            "Epoch 100/1000\n",
            "2/2 [==============================] - 2s 884ms/step - loss: 0.0230 - mse: 0.0178 - val_loss: 0.0387 - val_mse: 0.0257 - lr: 5.0000e-04\n",
            "Epoch 101/1000\n",
            "2/2 [==============================] - 2s 877ms/step - loss: 0.0223 - mse: 0.0168 - val_loss: 0.0375 - val_mse: 0.0255 - lr: 5.0000e-04\n",
            "Epoch 102/1000\n",
            "2/2 [==============================] - 2s 884ms/step - loss: 0.0215 - mse: 0.0165 - val_loss: 0.0369 - val_mse: 0.0250 - lr: 5.0000e-04\n",
            "Epoch 103/1000\n",
            "2/2 [==============================] - 2s 877ms/step - loss: 0.0208 - mse: 0.0161 - val_loss: 0.0385 - val_mse: 0.0259 - lr: 5.0000e-04\n",
            "Epoch 104/1000\n",
            "2/2 [==============================] - 2s 875ms/step - loss: 0.0204 - mse: 0.0158 - val_loss: 0.0416 - val_mse: 0.0274 - lr: 5.0000e-04\n",
            "Epoch 105/1000\n",
            "2/2 [==============================] - 2s 876ms/step - loss: 0.0207 - mse: 0.0158 - val_loss: 0.0396 - val_mse: 0.0267 - lr: 5.0000e-04\n",
            "Epoch 106/1000\n",
            "2/2 [==============================] - 2s 871ms/step - loss: 0.0194 - mse: 0.0150 - val_loss: 0.0375 - val_mse: 0.0255 - lr: 5.0000e-04\n",
            "Epoch 107/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0192 - mse: 0.0146 - val_loss: 0.0381 - val_mse: 0.0261 - lr: 5.0000e-04\n",
            "Epoch 108/1000\n",
            "2/2 [==============================] - 2s 885ms/step - loss: 0.0181 - mse: 0.0144 - val_loss: 0.0410 - val_mse: 0.0271 - lr: 5.0000e-04\n",
            "Epoch 109/1000\n",
            "2/2 [==============================] - 2s 872ms/step - loss: 0.0179 - mse: 0.0139 - val_loss: 0.0402 - val_mse: 0.0272 - lr: 5.0000e-04\n",
            "Epoch 110/1000\n",
            "2/2 [==============================] - 2s 874ms/step - loss: 0.0173 - mse: 0.0135 - val_loss: 0.0405 - val_mse: 0.0270 - lr: 5.0000e-04\n",
            "Epoch 111/1000\n",
            "2/2 [==============================] - 2s 877ms/step - loss: 0.0168 - mse: 0.0132 - val_loss: 0.0394 - val_mse: 0.0265 - lr: 5.0000e-04\n",
            "Epoch 112/1000\n",
            "2/2 [==============================] - 2s 876ms/step - loss: 0.0173 - mse: 0.0133 - val_loss: 0.0360 - val_mse: 0.0255 - lr: 5.0000e-04\n",
            "Epoch 113/1000\n",
            "2/2 [==============================] - 2s 880ms/step - loss: 0.0242 - mse: 0.0189 - val_loss: 0.0348 - val_mse: 0.0244 - lr: 5.0000e-04\n",
            "Epoch 114/1000\n",
            "2/2 [==============================] - 2s 877ms/step - loss: 0.0227 - mse: 0.0180 - val_loss: 0.0457 - val_mse: 0.0310 - lr: 5.0000e-04\n",
            "Epoch 115/1000\n",
            "2/2 [==============================] - 2s 870ms/step - loss: 0.0215 - mse: 0.0167 - val_loss: 0.0428 - val_mse: 0.0281 - lr: 5.0000e-04\n",
            "Epoch 116/1000\n",
            "2/2 [==============================] - 2s 875ms/step - loss: 0.0200 - mse: 0.0147 - val_loss: 0.0353 - val_mse: 0.0235 - lr: 5.0000e-04\n",
            "Epoch 117/1000\n",
            "2/2 [==============================] - 2s 880ms/step - loss: 0.0191 - mse: 0.0144 - val_loss: 0.0402 - val_mse: 0.0272 - lr: 5.0000e-04\n",
            "Epoch 118/1000\n",
            "2/2 [==============================] - 2s 876ms/step - loss: 0.0178 - mse: 0.0138 - val_loss: 0.0401 - val_mse: 0.0264 - lr: 5.0000e-04\n",
            "Epoch 119/1000\n",
            "2/2 [==============================] - 2s 872ms/step - loss: 0.0172 - mse: 0.0132 - val_loss: 0.0377 - val_mse: 0.0254 - lr: 5.0000e-04\n",
            "Epoch 120/1000\n",
            "2/2 [==============================] - 2s 871ms/step - loss: 0.0165 - mse: 0.0129 - val_loss: 0.0409 - val_mse: 0.0271 - lr: 5.0000e-04\n",
            "Epoch 121/1000\n",
            "2/2 [==============================] - 2s 877ms/step - loss: 0.0157 - mse: 0.0124 - val_loss: 0.0417 - val_mse: 0.0277 - lr: 5.0000e-04\n",
            "Epoch 122/1000\n",
            "2/2 [==============================] - 2s 871ms/step - loss: 0.0153 - mse: 0.0121 - val_loss: 0.0398 - val_mse: 0.0269 - lr: 5.0000e-04\n",
            "Epoch 123/1000\n",
            "2/2 [==============================] - 2s 868ms/step - loss: 0.0148 - mse: 0.0117 - val_loss: 0.0406 - val_mse: 0.0266 - lr: 5.0000e-04\n",
            "Epoch 124/1000\n",
            "2/2 [==============================] - 2s 878ms/step - loss: 0.0144 - mse: 0.0113 - val_loss: 0.0407 - val_mse: 0.0275 - lr: 5.0000e-04\n",
            "Epoch 125/1000\n",
            "2/2 [==============================] - 2s 873ms/step - loss: 0.0142 - mse: 0.0114 - val_loss: 0.0403 - val_mse: 0.0268 - lr: 5.0000e-04\n",
            "Epoch 126/1000\n",
            "2/2 [==============================] - 2s 878ms/step - loss: 0.0138 - mse: 0.0110 - val_loss: 0.0406 - val_mse: 0.0271 - lr: 5.0000e-04\n",
            "Epoch 127/1000\n",
            "2/2 [==============================] - 2s 869ms/step - loss: 0.0134 - mse: 0.0108 - val_loss: 0.0415 - val_mse: 0.0274 - lr: 5.0000e-04\n",
            "Epoch 128/1000\n",
            "2/2 [==============================] - 2s 873ms/step - loss: 0.0131 - mse: 0.0106 - val_loss: 0.0423 - val_mse: 0.0279 - lr: 5.0000e-04\n",
            "Epoch 129/1000\n",
            "2/2 [==============================] - 2s 870ms/step - loss: 0.0129 - mse: 0.0105 - val_loss: 0.0428 - val_mse: 0.0282 - lr: 5.0000e-04\n",
            "Epoch 130/1000\n",
            "2/2 [==============================] - 2s 874ms/step - loss: 0.0126 - mse: 0.0102 - val_loss: 0.0416 - val_mse: 0.0275 - lr: 5.0000e-04\n",
            "Epoch 131/1000\n",
            "2/2 [==============================] - 2s 877ms/step - loss: 0.0122 - mse: 0.0100 - val_loss: 0.0410 - val_mse: 0.0271 - lr: 5.0000e-04\n",
            "Epoch 132/1000\n",
            "2/2 [==============================] - 2s 875ms/step - loss: 0.0121 - mse: 0.0100 - val_loss: 0.0421 - val_mse: 0.0277 - lr: 5.0000e-04\n",
            "Epoch 133/1000\n",
            "2/2 [==============================] - 2s 875ms/step - loss: 0.0118 - mse: 0.0097 - val_loss: 0.0433 - val_mse: 0.0286 - lr: 5.0000e-04\n",
            "Epoch 134/1000\n",
            "2/2 [==============================] - 2s 876ms/step - loss: 0.0121 - mse: 0.0100 - val_loss: 0.0469 - val_mse: 0.0301 - lr: 5.0000e-04\n",
            "Epoch 135/1000\n",
            "2/2 [==============================] - 2s 878ms/step - loss: 0.0142 - mse: 0.0114 - val_loss: 0.0512 - val_mse: 0.0332 - lr: 5.0000e-04\n",
            "Epoch 136/1000\n",
            "2/2 [==============================] - 2s 882ms/step - loss: 0.0164 - mse: 0.0130 - val_loss: 0.0414 - val_mse: 0.0261 - lr: 5.0000e-04\n",
            "Epoch 137/1000\n",
            "2/2 [==============================] - 2s 874ms/step - loss: 0.0124 - mse: 0.0097 - val_loss: 0.0401 - val_mse: 0.0274 - lr: 5.0000e-04\n",
            "Epoch 138/1000\n",
            "2/2 [==============================] - 2s 873ms/step - loss: 0.0141 - mse: 0.0109 - val_loss: 0.0377 - val_mse: 0.0256 - lr: 5.0000e-04\n",
            "Epoch 139/1000\n",
            "2/2 [==============================] - 2s 875ms/step - loss: 0.0138 - mse: 0.0115 - val_loss: 0.0402 - val_mse: 0.0267 - lr: 5.0000e-04\n",
            "Epoch 140/1000\n",
            "2/2 [==============================] - 2s 871ms/step - loss: 0.0122 - mse: 0.0100 - val_loss: 0.0482 - val_mse: 0.0305 - lr: 5.0000e-04\n",
            "Epoch 141/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0134 - mse: 0.0103 - val_loss: 0.0395 - val_mse: 0.0261 - lr: 5.0000e-04\n",
            "Epoch 142/1000\n",
            "2/2 [==============================] - 2s 915ms/step - loss: 0.0127 - mse: 0.0098 - val_loss: 0.0387 - val_mse: 0.0268 - lr: 5.0000e-04\n",
            "Epoch 143/1000\n",
            "2/2 [==============================] - 2s 912ms/step - loss: 0.0157 - mse: 0.0127 - val_loss: 0.0382 - val_mse: 0.0250 - lr: 5.0000e-04\n",
            "Epoch 144/1000\n",
            "2/2 [==============================] - 2s 957ms/step - loss: 0.0134 - mse: 0.0110 - val_loss: 0.0510 - val_mse: 0.0321 - lr: 5.0000e-04\n",
            "Epoch 145/1000\n",
            "2/2 [==============================] - 2s 876ms/step - loss: 0.0146 - mse: 0.0110 - val_loss: 0.0377 - val_mse: 0.0265 - lr: 5.0000e-04\n",
            "Epoch 146/1000\n",
            "2/2 [==============================] - 2s 881ms/step - loss: 0.0177 - mse: 0.0135 - val_loss: 0.0382 - val_mse: 0.0254 - lr: 5.0000e-04\n",
            "Epoch 147/1000\n",
            "2/2 [==============================] - 2s 870ms/step - loss: 0.0136 - mse: 0.0113 - val_loss: 0.0524 - val_mse: 0.0341 - lr: 5.0000e-04\n",
            "Epoch 148/1000\n",
            "2/2 [==============================] - 2s 875ms/step - loss: 0.0150 - mse: 0.0115 - val_loss: 0.0374 - val_mse: 0.0270 - lr: 5.0000e-04\n",
            "Epoch 149/1000\n",
            "2/2 [==============================] - 2s 880ms/step - loss: 0.0189 - mse: 0.0148 - val_loss: 0.0413 - val_mse: 0.0267 - lr: 5.0000e-04\n",
            "Epoch 150/1000\n",
            "2/2 [==============================] - 2s 891ms/step - loss: 0.0171 - mse: 0.0139 - val_loss: 0.0482 - val_mse: 0.0303 - lr: 5.0000e-04\n",
            "Epoch 151/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0154 - mse: 0.0114 - val_loss: 0.0382 - val_mse: 0.0279 - lr: 5.0000e-04\n",
            "Epoch 152/1000\n",
            "2/2 [==============================] - 2s 890ms/step - loss: 0.0171 - mse: 0.0126 - val_loss: 0.0469 - val_mse: 0.0284 - lr: 5.0000e-04\n",
            "Epoch 153/1000\n",
            "2/2 [==============================] - 2s 883ms/step - loss: 0.0181 - mse: 0.0131 - val_loss: 0.0409 - val_mse: 0.0289 - lr: 5.0000e-04\n",
            "Epoch 154/1000\n",
            "2/2 [==============================] - 2s 877ms/step - loss: 0.0144 - mse: 0.0111 - val_loss: 0.0383 - val_mse: 0.0248 - lr: 5.0000e-04\n",
            "Epoch 155/1000\n",
            "2/2 [==============================] - 2s 881ms/step - loss: 0.0136 - mse: 0.0107 - val_loss: 0.0423 - val_mse: 0.0293 - lr: 5.0000e-04\n",
            "Epoch 156/1000\n",
            "2/2 [==============================] - 2s 877ms/step - loss: 0.0128 - mse: 0.0105 - val_loss: 0.0375 - val_mse: 0.0256 - lr: 5.0000e-04\n",
            "Epoch 157/1000\n",
            "2/2 [==============================] - 2s 883ms/step - loss: 0.0127 - mse: 0.0099 - val_loss: 0.0416 - val_mse: 0.0269 - lr: 5.0000e-04\n",
            "Epoch 158/1000\n",
            "2/2 [==============================] - 2s 880ms/step - loss: 0.0114 - mse: 0.0090 - val_loss: 0.0386 - val_mse: 0.0263 - lr: 5.0000e-04\n",
            "Epoch 159/1000\n",
            "2/2 [==============================] - 2s 879ms/step - loss: 0.0111 - mse: 0.0089 - val_loss: 0.0394 - val_mse: 0.0253 - lr: 5.0000e-04\n",
            "Epoch 160/1000\n",
            "2/2 [==============================] - 2s 876ms/step - loss: 0.0107 - mse: 0.0088 - val_loss: 0.0423 - val_mse: 0.0288 - lr: 5.0000e-04\n",
            "Epoch 161/1000\n",
            "2/2 [==============================] - 2s 877ms/step - loss: 0.0103 - mse: 0.0086 - val_loss: 0.0381 - val_mse: 0.0255 - lr: 5.0000e-04\n",
            "Epoch 162/1000\n",
            "2/2 [==============================] - 2s 875ms/step - loss: 0.0100 - mse: 0.0083 - val_loss: 0.0411 - val_mse: 0.0269 - lr: 5.0000e-04\n",
            "Epoch 163/1000\n",
            "2/2 [==============================] - 2s 875ms/step - loss: 0.0098 - mse: 0.0082 - val_loss: 0.0410 - val_mse: 0.0275 - lr: 5.0000e-04\n",
            "Epoch 164/1000\n",
            "2/2 [==============================] - 2s 883ms/step - loss: 0.0094 - mse: 0.0079 - val_loss: 0.0390 - val_mse: 0.0257 - lr: 5.0000e-04\n",
            "Epoch 165/1000\n",
            "2/2 [==============================] - 2s 879ms/step - loss: 0.0093 - mse: 0.0078 - val_loss: 0.0415 - val_mse: 0.0276 - lr: 5.0000e-04\n",
            "Epoch 166/1000\n",
            "2/2 [==============================] - 2s 874ms/step - loss: 0.0091 - mse: 0.0077 - val_loss: 0.0406 - val_mse: 0.0268 - lr: 5.0000e-04\n",
            "Epoch 167/1000\n",
            "2/2 [==============================] - 2s 879ms/step - loss: 0.0089 - mse: 0.0075 - val_loss: 0.0398 - val_mse: 0.0262 - lr: 5.0000e-04\n",
            "Epoch 168/1000\n",
            "2/2 [==============================] - 2s 879ms/step - loss: 0.0088 - mse: 0.0075 - val_loss: 0.0414 - val_mse: 0.0274 - lr: 5.0000e-04\n",
            "Epoch 169/1000\n",
            "2/2 [==============================] - 2s 879ms/step - loss: 0.0086 - mse: 0.0074 - val_loss: 0.0408 - val_mse: 0.0268 - lr: 5.0000e-04\n",
            "Epoch 170/1000\n",
            "2/2 [==============================] - 2s 881ms/step - loss: 0.0086 - mse: 0.0073 - val_loss: 0.0403 - val_mse: 0.0268 - lr: 5.0000e-04\n",
            "Epoch 171/1000\n",
            "2/2 [==============================] - 2s 878ms/step - loss: 0.0084 - mse: 0.0073 - val_loss: 0.0418 - val_mse: 0.0274 - lr: 5.0000e-04\n",
            "Epoch 172/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0083 - mse: 0.0072 - val_loss: 0.0407 - val_mse: 0.0268 - lr: 5.0000e-04\n",
            "Epoch 173/1000\n",
            "2/2 [==============================] - 2s 883ms/step - loss: 0.0082 - mse: 0.0071 - val_loss: 0.0407 - val_mse: 0.0268 - lr: 5.0000e-04\n",
            "Epoch 174/1000\n",
            "2/2 [==============================] - 2s 887ms/step - loss: 0.0081 - mse: 0.0070 - val_loss: 0.0417 - val_mse: 0.0274 - lr: 5.0000e-04\n",
            "Epoch 175/1000\n",
            "2/2 [==============================] - 2s 874ms/step - loss: 0.0080 - mse: 0.0069 - val_loss: 0.0413 - val_mse: 0.0272 - lr: 5.0000e-04\n",
            "Epoch 176/1000\n",
            "2/2 [==============================] - 2s 875ms/step - loss: 0.0079 - mse: 0.0069 - val_loss: 0.0408 - val_mse: 0.0268 - lr: 5.0000e-04\n",
            "Epoch 177/1000\n",
            "2/2 [==============================] - 2s 869ms/step - loss: 0.0078 - mse: 0.0068 - val_loss: 0.0419 - val_mse: 0.0275 - lr: 5.0000e-04\n",
            "Epoch 178/1000\n",
            "2/2 [==============================] - 2s 880ms/step - loss: 0.0077 - mse: 0.0067 - val_loss: 0.0411 - val_mse: 0.0270 - lr: 5.0000e-04\n",
            "Epoch 179/1000\n",
            "2/2 [==============================] - 2s 875ms/step - loss: 0.0077 - mse: 0.0067 - val_loss: 0.0403 - val_mse: 0.0266 - lr: 5.0000e-04\n",
            "Epoch 180/1000\n",
            "2/2 [==============================] - 2s 871ms/step - loss: 0.0076 - mse: 0.0067 - val_loss: 0.0429 - val_mse: 0.0279 - lr: 5.0000e-04\n",
            "Epoch 181/1000\n",
            "2/2 [==============================] - 2s 874ms/step - loss: 0.0076 - mse: 0.0067 - val_loss: 0.0418 - val_mse: 0.0274 - lr: 5.0000e-04\n",
            "Epoch 182/1000\n",
            "2/2 [==============================] - 2s 878ms/step - loss: 0.0074 - mse: 0.0065 - val_loss: 0.0410 - val_mse: 0.0269 - lr: 5.0000e-04\n",
            "Epoch 183/1000\n",
            "2/2 [==============================] - 2s 877ms/step - loss: 0.0074 - mse: 0.0065 - val_loss: 0.0423 - val_mse: 0.0278 - lr: 5.0000e-04\n",
            "Epoch 184/1000\n",
            "2/2 [==============================] - 2s 873ms/step - loss: 0.0073 - mse: 0.0064 - val_loss: 0.0423 - val_mse: 0.0276 - lr: 5.0000e-04\n",
            "Epoch 185/1000\n",
            "2/2 [==============================] - 2s 881ms/step - loss: 0.0072 - mse: 0.0064 - val_loss: 0.0417 - val_mse: 0.0275 - lr: 5.0000e-04\n",
            "Epoch 186/1000\n",
            "2/2 [==============================] - 2s 940ms/step - loss: 0.0072 - mse: 0.0063 - val_loss: 0.0410 - val_mse: 0.0269 - lr: 5.0000e-04\n",
            "Epoch 187/1000\n",
            "2/2 [==============================] - 2s 873ms/step - loss: 0.0071 - mse: 0.0063 - val_loss: 0.0420 - val_mse: 0.0276 - lr: 5.0000e-04\n",
            "Epoch 188/1000\n",
            "2/2 [==============================] - 2s 877ms/step - loss: 0.0070 - mse: 0.0062 - val_loss: 0.0428 - val_mse: 0.0278 - lr: 5.0000e-04\n",
            "Epoch 189/1000\n",
            "2/2 [==============================] - 2s 873ms/step - loss: 0.0070 - mse: 0.0062 - val_loss: 0.0420 - val_mse: 0.0276 - lr: 5.0000e-04\n",
            "Epoch 190/1000\n",
            "2/2 [==============================] - 2s 876ms/step - loss: 0.0069 - mse: 0.0061 - val_loss: 0.0411 - val_mse: 0.0270 - lr: 5.0000e-04\n",
            "Epoch 191/1000\n",
            "2/2 [==============================] - 2s 868ms/step - loss: 0.0069 - mse: 0.0061 - val_loss: 0.0422 - val_mse: 0.0277 - lr: 5.0000e-04\n",
            "Epoch 192/1000\n",
            "2/2 [==============================] - 2s 878ms/step - loss: 0.0068 - mse: 0.0061 - val_loss: 0.0435 - val_mse: 0.0283 - lr: 5.0000e-04\n",
            "Epoch 193/1000\n",
            "2/2 [==============================] - 2s 876ms/step - loss: 0.0069 - mse: 0.0061 - val_loss: 0.0417 - val_mse: 0.0273 - lr: 5.0000e-04\n",
            "Epoch 194/1000\n",
            "2/2 [==============================] - 2s 885ms/step - loss: 0.0068 - mse: 0.0060 - val_loss: 0.0413 - val_mse: 0.0272 - lr: 5.0000e-04\n",
            "Epoch 195/1000\n",
            "2/2 [==============================] - 2s 877ms/step - loss: 0.0068 - mse: 0.0060 - val_loss: 0.0415 - val_mse: 0.0272 - lr: 5.0000e-04\n",
            "Epoch 196/1000\n",
            "2/2 [==============================] - 2s 876ms/step - loss: 0.0066 - mse: 0.0059 - val_loss: 0.0438 - val_mse: 0.0285 - lr: 5.0000e-04\n",
            "Epoch 197/1000\n",
            "2/2 [==============================] - 2s 876ms/step - loss: 0.0068 - mse: 0.0060 - val_loss: 0.0436 - val_mse: 0.0284 - lr: 5.0000e-04\n",
            "Epoch 198/1000\n",
            "2/2 [==============================] - 2s 866ms/step - loss: 0.0066 - mse: 0.0059 - val_loss: 0.0417 - val_mse: 0.0274 - lr: 5.0000e-04\n",
            "Epoch 199/1000\n",
            "2/2 [==============================] - 2s 873ms/step - loss: 0.0066 - mse: 0.0058 - val_loss: 0.0412 - val_mse: 0.0270 - lr: 5.0000e-04\n",
            "Epoch 200/1000\n",
            "2/2 [==============================] - 2s 874ms/step - loss: 0.0066 - mse: 0.0059 - val_loss: 0.0422 - val_mse: 0.0276 - lr: 5.0000e-04\n",
            "Epoch 201/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0064 - mse: 0.0057 - val_loss: 0.0437 - val_mse: 0.0284 - lr: 5.0000e-04\n",
            "Epoch 202/1000\n",
            "2/2 [==============================] - 2s 881ms/step - loss: 0.0065 - mse: 0.0058 - val_loss: 0.0433 - val_mse: 0.0282 - lr: 5.0000e-04\n",
            "Epoch 203/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0064 - mse: 0.0057 - val_loss: 0.0422 - val_mse: 0.0276 - lr: 5.0000e-04\n",
            "Epoch 204/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0064 - mse: 0.0057 - val_loss: 0.0412 - val_mse: 0.0271 - lr: 5.0000e-04\n",
            "Epoch 205/1000\n",
            "2/2 [==============================] - 2s 878ms/step - loss: 0.0063 - mse: 0.0057 - val_loss: 0.0435 - val_mse: 0.0282 - lr: 5.0000e-04\n",
            "Epoch 206/1000\n",
            "2/2 [==============================] - 2s 873ms/step - loss: 0.0063 - mse: 0.0056 - val_loss: 0.0449 - val_mse: 0.0291 - lr: 5.0000e-04\n",
            "Epoch 207/1000\n",
            "2/2 [==============================] - 2s 881ms/step - loss: 0.0067 - mse: 0.0059 - val_loss: 0.0449 - val_mse: 0.0290 - lr: 5.0000e-04\n",
            "Epoch 208/1000\n",
            "2/2 [==============================] - 2s 890ms/step - loss: 0.0064 - mse: 0.0056 - val_loss: 0.0421 - val_mse: 0.0275 - lr: 5.0000e-04\n",
            "Epoch 209/1000\n",
            "2/2 [==============================] - 2s 877ms/step - loss: 0.0062 - mse: 0.0055 - val_loss: 0.0416 - val_mse: 0.0273 - lr: 5.0000e-04\n",
            "Epoch 210/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0064 - mse: 0.0057 - val_loss: 0.0408 - val_mse: 0.0269 - lr: 5.0000e-04\n",
            "Epoch 211/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0064 - mse: 0.0056 - val_loss: 0.0423 - val_mse: 0.0277 - lr: 5.0000e-04\n",
            "Epoch 212/1000\n",
            "2/2 [==============================] - 2s 886ms/step - loss: 0.0061 - mse: 0.0055 - val_loss: 0.0442 - val_mse: 0.0284 - lr: 5.0000e-04\n",
            "Epoch 213/1000\n",
            "2/2 [==============================] - 2s 871ms/step - loss: 0.0064 - mse: 0.0057 - val_loss: 0.0453 - val_mse: 0.0294 - lr: 5.0000e-04\n",
            "Epoch 214/1000\n",
            "2/2 [==============================] - 2s 877ms/step - loss: 0.0067 - mse: 0.0059 - val_loss: 0.0443 - val_mse: 0.0285 - lr: 5.0000e-04\n",
            "Epoch 215/1000\n",
            "2/2 [==============================] - 2s 879ms/step - loss: 0.0063 - mse: 0.0055 - val_loss: 0.0423 - val_mse: 0.0277 - lr: 5.0000e-04\n",
            "Epoch 216/1000\n",
            "2/2 [==============================] - 2s 876ms/step - loss: 0.0062 - mse: 0.0055 - val_loss: 0.0412 - val_mse: 0.0271 - lr: 5.0000e-04\n",
            "Epoch 217/1000\n",
            "2/2 [==============================] - 2s 874ms/step - loss: 0.0065 - mse: 0.0058 - val_loss: 0.0409 - val_mse: 0.0267 - lr: 5.0000e-04\n",
            "Epoch 218/1000\n",
            "2/2 [==============================] - 2s 879ms/step - loss: 0.0062 - mse: 0.0055 - val_loss: 0.0474 - val_mse: 0.0305 - lr: 5.0000e-04\n",
            "Epoch 219/1000\n",
            "2/2 [==============================] - 2s 878ms/step - loss: 0.0074 - mse: 0.0063 - val_loss: 0.0475 - val_mse: 0.0303 - lr: 5.0000e-04\n",
            "Epoch 220/1000\n",
            "2/2 [==============================] - 2s 881ms/step - loss: 0.0077 - mse: 0.0063 - val_loss: 0.0432 - val_mse: 0.0284 - lr: 5.0000e-04\n",
            "Epoch 221/1000\n",
            "2/2 [==============================] - 2s 880ms/step - loss: 0.0065 - mse: 0.0056 - val_loss: 0.0415 - val_mse: 0.0269 - lr: 5.0000e-04\n",
            "Epoch 222/1000\n",
            "2/2 [==============================] - 2s 873ms/step - loss: 0.0065 - mse: 0.0056 - val_loss: 0.0419 - val_mse: 0.0276 - lr: 5.0000e-04\n",
            "Epoch 223/1000\n",
            "2/2 [==============================] - 2s 876ms/step - loss: 0.0063 - mse: 0.0055 - val_loss: 0.0434 - val_mse: 0.0284 - lr: 5.0000e-04\n",
            "Epoch 224/1000\n",
            "2/2 [==============================] - 2s 874ms/step - loss: 0.0062 - mse: 0.0054 - val_loss: 0.0433 - val_mse: 0.0279 - lr: 5.0000e-04\n",
            "Epoch 225/1000\n",
            "2/2 [==============================] - 2s 882ms/step - loss: 0.0061 - mse: 0.0053 - val_loss: 0.0427 - val_mse: 0.0279 - lr: 5.0000e-04\n",
            "Epoch 226/1000\n",
            "2/2 [==============================] - 2s 880ms/step - loss: 0.0059 - mse: 0.0053 - val_loss: 0.0420 - val_mse: 0.0273 - lr: 5.0000e-04\n",
            "Epoch 227/1000\n",
            "2/2 [==============================] - 2s 882ms/step - loss: 0.0059 - mse: 0.0052 - val_loss: 0.0422 - val_mse: 0.0279 - lr: 5.0000e-04\n",
            "Epoch 228/1000\n",
            "2/2 [==============================] - 2s 884ms/step - loss: 0.0058 - mse: 0.0052 - val_loss: 0.0435 - val_mse: 0.0281 - lr: 5.0000e-04\n",
            "Epoch 229/1000\n",
            "2/2 [==============================] - 2s 874ms/step - loss: 0.0058 - mse: 0.0052 - val_loss: 0.0437 - val_mse: 0.0285 - lr: 5.0000e-04\n",
            "Epoch 230/1000\n",
            "2/2 [==============================] - 2s 880ms/step - loss: 0.0058 - mse: 0.0052 - val_loss: 0.0428 - val_mse: 0.0279 - lr: 5.0000e-04\n",
            "Epoch 231/1000\n",
            "2/2 [==============================] - 2s 869ms/step - loss: 0.0057 - mse: 0.0051 - val_loss: 0.0418 - val_mse: 0.0272 - lr: 5.0000e-04\n",
            "Epoch 232/1000\n",
            "2/2 [==============================] - 2s 876ms/step - loss: 0.0058 - mse: 0.0052 - val_loss: 0.0413 - val_mse: 0.0273 - lr: 5.0000e-04\n",
            "Epoch 233/1000\n",
            "2/2 [==============================] - 2s 875ms/step - loss: 0.0057 - mse: 0.0051 - val_loss: 0.0431 - val_mse: 0.0279 - lr: 5.0000e-04\n",
            "Epoch 234/1000\n",
            "2/2 [==============================] - 2s 881ms/step - loss: 0.0057 - mse: 0.0051 - val_loss: 0.0447 - val_mse: 0.0291 - lr: 5.0000e-04\n",
            "Epoch 235/1000\n",
            "2/2 [==============================] - 2s 887ms/step - loss: 0.0059 - mse: 0.0053 - val_loss: 0.0450 - val_mse: 0.0291 - lr: 5.0000e-04\n",
            "Epoch 236/1000\n",
            "2/2 [==============================] - 2s 876ms/step - loss: 0.0059 - mse: 0.0052 - val_loss: 0.0441 - val_mse: 0.0285 - lr: 5.0000e-04\n",
            "Epoch 237/1000\n",
            "2/2 [==============================] - 2s 877ms/step - loss: 0.0056 - mse: 0.0050 - val_loss: 0.0423 - val_mse: 0.0279 - lr: 5.0000e-04\n",
            "Epoch 238/1000\n",
            "2/2 [==============================] - 2s 878ms/step - loss: 0.0056 - mse: 0.0050 - val_loss: 0.0415 - val_mse: 0.0272 - lr: 5.0000e-04\n",
            "Epoch 239/1000\n",
            "2/2 [==============================] - 2s 879ms/step - loss: 0.0061 - mse: 0.0054 - val_loss: 0.0398 - val_mse: 0.0265 - lr: 5.0000e-04\n",
            "Epoch 240/1000\n",
            "2/2 [==============================] - 2s 866ms/step - loss: 0.0063 - mse: 0.0056 - val_loss: 0.0423 - val_mse: 0.0277 - lr: 5.0000e-04\n",
            "Epoch 241/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0055 - mse: 0.0050 - val_loss: 0.0442 - val_mse: 0.0286 - lr: 5.0000e-04\n",
            "Epoch 242/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0059 - mse: 0.0052 - val_loss: 0.0473 - val_mse: 0.0307 - lr: 5.0000e-04\n",
            "Epoch 243/1000\n",
            "2/2 [==============================] - 2s 890ms/step - loss: 0.0062 - mse: 0.0055 - val_loss: 0.0451 - val_mse: 0.0292 - lr: 5.0000e-04\n",
            "Epoch 244/1000\n",
            "2/2 [==============================] - 2s 880ms/step - loss: 0.0058 - mse: 0.0051 - val_loss: 0.0423 - val_mse: 0.0276 - lr: 5.0000e-04\n",
            "Epoch 245/1000\n",
            "2/2 [==============================] - 2s 876ms/step - loss: 0.0058 - mse: 0.0051 - val_loss: 0.0393 - val_mse: 0.0265 - lr: 5.0000e-04\n",
            "Epoch 246/1000\n",
            "2/2 [==============================] - 2s 998ms/step - loss: 0.0080 - mse: 0.0067 - val_loss: 0.0393 - val_mse: 0.0264 - lr: 5.0000e-04\n",
            "Epoch 247/1000\n",
            "2/2 [==============================] - 2s 881ms/step - loss: 0.0075 - mse: 0.0061 - val_loss: 0.0411 - val_mse: 0.0268 - lr: 5.0000e-04\n",
            "Epoch 248/1000\n",
            "2/2 [==============================] - 2s 883ms/step - loss: 0.0061 - mse: 0.0053 - val_loss: 0.0479 - val_mse: 0.0304 - lr: 5.0000e-04\n",
            "Epoch 249/1000\n",
            "2/2 [==============================] - 2s 881ms/step - loss: 0.0079 - mse: 0.0065 - val_loss: 0.0481 - val_mse: 0.0311 - lr: 5.0000e-04\n",
            "Epoch 250/1000\n",
            "2/2 [==============================] - 2s 884ms/step - loss: 0.0075 - mse: 0.0062 - val_loss: 0.0431 - val_mse: 0.0280 - lr: 5.0000e-04\n",
            "Epoch 251/1000\n",
            "2/2 [==============================] - 2s 877ms/step - loss: 0.0059 - mse: 0.0051 - val_loss: 0.0394 - val_mse: 0.0265 - lr: 5.0000e-04\n",
            "Epoch 252/1000\n",
            "2/2 [==============================] - 2s 893ms/step - loss: 0.0076 - mse: 0.0063 - val_loss: 0.0397 - val_mse: 0.0262 - lr: 5.0000e-04\n",
            "Epoch 253/1000\n",
            "2/2 [==============================] - 2s 875ms/step - loss: 0.0060 - mse: 0.0053 - val_loss: 0.0485 - val_mse: 0.0309 - lr: 5.0000e-04\n",
            "Epoch 254/1000\n",
            "2/2 [==============================] - 2s 894ms/step - loss: 0.0082 - mse: 0.0068 - val_loss: 0.0458 - val_mse: 0.0296 - lr: 5.0000e-04\n",
            "Epoch 255/1000\n",
            "2/2 [==============================] - 2s 879ms/step - loss: 0.0064 - mse: 0.0054 - val_loss: 0.0401 - val_mse: 0.0268 - lr: 5.0000e-04\n",
            "Epoch 256/1000\n",
            "2/2 [==============================] - 2s 886ms/step - loss: 0.0093 - mse: 0.0076 - val_loss: 0.0376 - val_mse: 0.0252 - lr: 5.0000e-04\n",
            "Epoch 257/1000\n",
            "2/2 [==============================] - 2s 871ms/step - loss: 0.0071 - mse: 0.0062 - val_loss: 0.0530 - val_mse: 0.0336 - lr: 5.0000e-04\n",
            "Epoch 258/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0102 - mse: 0.0079 - val_loss: 0.0426 - val_mse: 0.0282 - lr: 5.0000e-04\n",
            "Epoch 259/1000\n",
            "2/2 [==============================] - 2s 885ms/step - loss: 0.0069 - mse: 0.0056 - val_loss: 0.0392 - val_mse: 0.0268 - lr: 5.0000e-04\n",
            "Epoch 260/1000\n",
            "2/2 [==============================] - 2s 883ms/step - loss: 0.0090 - mse: 0.0075 - val_loss: 0.0417 - val_mse: 0.0268 - lr: 5.0000e-04\n",
            "Epoch 261/1000\n",
            "2/2 [==============================] - 2s 883ms/step - loss: 0.0082 - mse: 0.0068 - val_loss: 0.0528 - val_mse: 0.0342 - lr: 5.0000e-04\n",
            "Epoch 262/1000\n",
            "2/2 [==============================] - 2s 897ms/step - loss: 0.0095 - mse: 0.0076 - val_loss: 0.0382 - val_mse: 0.0261 - lr: 5.0000e-04\n",
            "Epoch 263/1000\n",
            "2/2 [==============================] - 2s 918ms/step - loss: 0.0121 - mse: 0.0095 - val_loss: 0.0397 - val_mse: 0.0257 - lr: 5.0000e-04\n",
            "Epoch 264/1000\n",
            "2/2 [==============================] - 2s 943ms/step - loss: 0.0137 - mse: 0.0108 - val_loss: 0.0641 - val_mse: 0.0403 - lr: 5.0000e-04\n",
            "Epoch 265/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0172 - mse: 0.0119 - val_loss: 0.0464 - val_mse: 0.0358 - lr: 5.0000e-04\n",
            "Epoch 266/1000\n",
            "2/2 [==============================] - 2s 965ms/step - loss: 0.0404 - mse: 0.0278 - val_loss: 0.0483 - val_mse: 0.0267 - lr: 5.0000e-04\n",
            "Epoch 267/1000\n",
            "2/2 [==============================] - 2s 893ms/step - loss: 0.0371 - mse: 0.0275 - val_loss: 0.0740 - val_mse: 0.0549 - lr: 5.0000e-04\n",
            "Epoch 268/1000\n",
            "2/2 [==============================] - 2s 885ms/step - loss: 0.0277 - mse: 0.0224 - val_loss: 0.0395 - val_mse: 0.0292 - lr: 5.0000e-04\n",
            "Epoch 269/1000\n",
            "2/2 [==============================] - 2s 950ms/step - loss: 0.0377 - mse: 0.0283 - val_loss: 0.0367 - val_mse: 0.0253 - lr: 5.0000e-04\n",
            "Epoch 270/1000\n",
            "2/2 [==============================] - 2s 900ms/step - loss: 0.0400 - mse: 0.0298 - val_loss: 0.0344 - val_mse: 0.0219 - lr: 5.0000e-04\n",
            "Epoch 271/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0346 - mse: 0.0213 - val_loss: 0.0361 - val_mse: 0.0250 - lr: 5.0000e-04\n",
            "Epoch 272/1000\n",
            "2/2 [==============================] - 2s 889ms/step - loss: 0.0290 - mse: 0.0233 - val_loss: 0.0545 - val_mse: 0.0358 - lr: 5.0000e-04\n",
            "Epoch 273/1000\n",
            "2/2 [==============================] - 2s 884ms/step - loss: 0.0265 - mse: 0.0184 - val_loss: 0.0330 - val_mse: 0.0243 - lr: 5.0000e-04\n",
            "Epoch 274/1000\n",
            "2/2 [==============================] - 2s 907ms/step - loss: 0.0246 - mse: 0.0184 - val_loss: 0.0449 - val_mse: 0.0291 - lr: 5.0000e-04\n"
          ]
        }
      ],
      "source": [
        "# Learning Rate Scheduler\n",
        "def scheduler(epoch, lr):\n",
        "  if epoch == 500:\n",
        "    return lr /5\n",
        "  else:\n",
        "    return lr\n",
        "\n",
        "scheduler_cb = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "# Early stopping criteria\n",
        "early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",min_delta=0.0005, patience=200, verbose=0, mode=\"auto\", baseline=None, restore_best_weights=True)\n",
        "\n",
        "# Training (Fit)\n",
        "history = model.fit(train_data, train_labels, epochs=1000, validation_data=(validation_data, validation_labels), callbacks=[early, scheduler_cb])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This next plot shows loss of the trianing and validation sets."
      ],
      "metadata": {
        "id": "xIGiYmh3fwP2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UgCp0oNUAfzt",
        "outputId": "1381f684-81da-4060-db6f-73f0121bbba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'mse', 'val_loss', 'val_mse', 'lr'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "print(history.history.keys())\n",
        "# # summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the results\n",
        "\n",
        "After our training, we need to plot our results to verify if we are making a good prediction since the value of the loss can be heavily influenced by outliers. The following cell includes nine plots we use to evaluate performance on each of the points."
      ],
      "metadata": {
        "id": "Hb4C5FSDf-2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for the volume plot of hotspot\n",
        "\n",
        "def area_hotspot(datapoint):\n",
        "  tinc = 5\n",
        "  tnum = int(4500/tinc)\n",
        "\n",
        "  tinc = 5\n",
        "  tnum = int(4500/tinc)\n",
        "\n",
        "  bins=np.zeros((tnum,2))\n",
        "  bins[:,0] = [ tinc*(0.5 + x) for x in list(range(tnum))]\n",
        "\n",
        "  for bin_index, temp in np.ndenumerate(datapoint):\n",
        "    theta = temp * 1000\n",
        "    tind=math.floor(theta/tinc)\n",
        "    bins[:tind, 1] += 4 # ~ Roughly 2*2*1 nm^3 (volume value from Chunyu)\n",
        "  \n",
        "  return bins"
      ],
      "metadata": {
        "id": "cVbLrXkBNWDI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def datapoint_results_print(simulation_point, simulation_temperatures, prediction_tensor):\n",
        "\n",
        "  # Simulation point is the input train_data[<point order>,<dim 0>,<dim 1>,<dim 2>,<channel>]\n",
        "  # For example, simulation_point = train_data[i,:,:,:,:]\n",
        "\n",
        "\n",
        "\n",
        "  fig = make_subplots(rows=3, cols=3, specs=[[{\"type\": \"scatter3d\"},{\"type\": \"scatter3d\"},{\"type\": \"scatter3d\"}],\n",
        "                                             [{\"type\": \"scatter3d\"},{\"type\": \"scatter3d\"},{\"type\": \"scatter\"}],\n",
        "                                             [{\"type\": \"histogram\"},{\"type\": \"histogram\"},{\"type\": \"scatter\"}]],\n",
        "                      subplot_titles=[\"Input 1\",\"Input 2\",\"Input 3\",\n",
        "                                      \"Temp (Labels)\",\"Temp (Predictions)\",\"Parity Plot\",\n",
        "                                      \"Temp (Distributions)\", \"Residuals\", \"Hotspot volume\"], horizontal_spacing = 0.1, vertical_spacing = 0.1)\n",
        "  \n",
        "  fig.update_layout(autosize=False, width=800, height=800) \n",
        "\n",
        "  # FIRST PLOT --> INPUT 1\n",
        "\n",
        "  input_1 = simulation_point[:,:,:,0].squeeze()\n",
        "\n",
        "  X,Y,Z = np.mgrid[0:input_1.shape[0], 0:input_1.shape[1], 0:input_1.shape[2]]\n",
        "  #input_1_xz = np.swapaxes(input_1, 2, 0)\n",
        "\n",
        "  trace_1 = go.Scatter3d(x = X.flatten(), y = Y.flatten(), z=Z.flatten(),\n",
        "                          mode='markers', marker=dict(colorscale='Viridis', size=8, line=dict(width=0), symbol='square', color = input_1.flatten(), colorbar=dict(thickness=20, len=0.3, x=0.27, y=0.9)), showlegend=False)\n",
        "  fig.add_trace(trace_1, row=1, col=1)\n",
        "\n",
        "  # SECOND PLOT --> INPUT 2\n",
        "\n",
        "  input_2 = simulation_point[:,:,:,1].squeeze()\n",
        "\n",
        "  X,Y,Z = np.mgrid[0:input_2.shape[0], 0:input_2.shape[1], 0:input_2.shape[2]]\n",
        "  #input_2_xz = np.swapaxes(input_2, 2, 0)\n",
        "\n",
        "  trace_2 = go.Scatter3d(x = X.flatten(), y = Y.flatten(), z=Z.flatten(),\n",
        "                          mode='markers', marker=dict(colorscale='Viridis', size=8, line=dict(width=0), symbol='square', color = input_2.flatten(), colorbar=dict(thickness=20, len=0.3, x=0.62, y=0.9)), showlegend=False)\n",
        "  fig.add_trace(trace_2, row=1, col=2)\n",
        "\n",
        "\n",
        "  # THIRD PLOT --> INPUT 3\n",
        "\n",
        "  input_3 = simulation_point[:,:,:,2].squeeze()\n",
        "\n",
        "  X,Y,Z = np.mgrid[0:input_3.shape[0], 0:input_3.shape[1], 0:input_3.shape[2]]\n",
        "  #input_3_xz = np.swapaxes(input_3, 2, 0)\n",
        "\n",
        "  trace_3 = go.Scatter3d(x = X.flatten(), y = Y.flatten(), z=Z.flatten(),\n",
        "                          mode='markers', marker=dict(colorscale='Viridis', size=8, line=dict(width=0), symbol='square', color = input_3.flatten(), colorbar=dict(thickness=20, len=0.3, x=1, y=0.9)), showlegend=False)\n",
        "  fig.add_trace(trace_3, row=1, col=3)\n",
        "\n",
        "\n",
        "  # FOURTH PLOT --> TEMPS (LABELS)\n",
        "\n",
        "  maxval = max(np.max(prediction_tensor), np.max(simulation_temperatures))\n",
        "  \n",
        "\n",
        "  X,Y,Z = np.mgrid[0:simulation_temperatures.shape[0], 0:simulation_temperatures.shape[1], 0:simulation_temperatures.shape[2]]\n",
        "  #simulation_temperatures_xz = np.swapaxes(simulation_temperatures, 2, 0)\n",
        "\n",
        "  trace_4 = go.Scatter3d(x = X.flatten(), y = Y.flatten(), z=Z.flatten(),\n",
        "                          mode='markers', marker=dict(cmin=0, cmax=maxval, colorscale='Reds', size=8, line=dict(width=0), symbol='square', color = simulation_temperatures.flatten(), colorbar=dict(thickness=20,len=0.3, x=0.27, y=0.5)), showlegend=False)\n",
        "  fig.add_trace(trace_4, row=2, col=1)\n",
        "\n",
        "\n",
        "  # FIFTH PLOT --> TEMPS (PREDICTIONS)\n",
        "\n",
        "  X,Y,Z = np.mgrid[0:prediction_tensor.shape[0], 0:prediction_tensor.shape[1], 0:prediction_tensor.shape[2]]\n",
        "  #prediction_tensor_xz = np.swapaxes(prediction_tensor, 2, 0)\n",
        "\n",
        "  trace_5 = go.Scatter3d(x = X.flatten(), y = Y.flatten(), z=Z.flatten(),\n",
        "                          mode='markers', marker=dict(cmin=0, cmax=maxval, colorscale='Reds', size=8, line=dict(width=0), symbol='square', color = prediction_tensor.flatten(), colorbar=dict(thickness=20, len=0.3, x=0.62, y=0.5)), showlegend=False)\n",
        "  fig.add_trace(trace_5, row=2, col=2)\n",
        "\n",
        "  # SIXTH PLOT --> PARITY PLOT\n",
        "\n",
        "  trace_6 = go.Scatter(x=simulation_temperatures.flatten(), y = prediction_tensor.flatten(), mode='markers', showlegend=False)\n",
        "  fig.add_trace(trace_6, row=2, col=3)\n",
        "  fig.update_xaxes(title=\"Scaled Temperature (K) - Labels\", row=2, col=3)\n",
        "  fig.update_yaxes(title=\"Scaled Temperature (K) - Predictions\", row=2, col=3)\n",
        "\n",
        "\n",
        "  # SEVENTH PLOT --> TEMP (Distributions)\n",
        "\n",
        "  trace_7 = go.Histogram(x=prediction_tensor.flatten(), name='Predictions', marker=dict(color='red'), showlegend=True, legendgroup = '1')\n",
        "  trace_7b = go.Histogram(x=simulation_temperatures.flatten(), name='Truth', marker=dict(color='green'), showlegend=True, legendgroup = '1')\n",
        "  fig.update_xaxes(title=\"Temperature (K) - Labels\", row=3, col=1)\n",
        "  fig.add_trace(trace_7, row=3, col=1)\n",
        "  fig.add_trace(trace_7b, row=3, col=1) \n",
        "\n",
        "\n",
        "  # EIGHTH PLOT --> RESIDUALS\n",
        "\n",
        "  diff_xz = prediction_tensor - simulation_temperatures\n",
        "  flat_diff_xz = diff_xz.flatten()\n",
        "\n",
        "  trace_8 = go.Histogram(x=flat_diff_xz, showlegend=False)\n",
        "  trace_line = go.Scatter(x=[0,0], y = [0,700], mode='lines', showlegend=False)\n",
        "\n",
        "  fig.add_trace(trace_8, row=3, col=2)\n",
        "  fig.add_trace(trace_line, row=3, col=2)\n",
        "\n",
        "  # NINTH PLOT ---> VOLUME OF HOTSPOT\n",
        "  \n",
        "  bins_labels = area_hotspot(simulation_temperatures)\n",
        "  bins_predictions = area_hotspot(prediction_tensor)\n",
        "  trace_9 = go.Scatter(x=bins_predictions[:,1], y=bins_predictions[:,0], mode='lines',  name='Predictions', marker=dict(color='red'), showlegend=True, legendgroup = '2')\n",
        "  trace_9b = go.Scatter(x=bins_labels[:,1], y=bins_labels[:,0], mode='lines', name='Truth', marker=dict(color='green'), showlegend=True, legendgroup = '2')\n",
        "  \n",
        "  fig.add_trace(trace_9, row=3, col=3)\n",
        "  fig.add_trace(trace_9b, row=3, col=3) \n",
        "  fig.update_xaxes(type=\"log\", row=3, col=3)\n",
        "  fig.update_xaxes(title=\"Hotspot Volume (nm^3)\", row=3, col=3)\n",
        "  fig.update_yaxes(title=\"Temperature (K)\", row=3, col=3)  \n",
        "\n",
        "  #### \n",
        "\n",
        "  fig.update_layout(autosize=False, width=1400, height=1000, legend_tracegroupgap = 180, legend=dict(font=dict(size=16),orientation=\"h\"))   \n",
        "\n",
        "  return fig"
      ],
      "metadata": {
        "id": "p65_1oRxgTu1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since rendering multiple plots for each system is not ideal, we will save a numpy array with the model predictions and an HTML file with the interactive plots for exploration."
      ],
      "metadata": {
        "id": "0Jx7VbNCihTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p results/train\n",
        "!mkdir -p results/validation"
      ],
      "metadata": {
        "id": "zVpCWbXshU4h"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PREDICTIONS OVER TRAINING DATA\n",
        "\n",
        "for i, title in enumerate(paths):\n",
        "  print(i)\n",
        "  inppoint = train_data[i,:,:,:,:].squeeze()\n",
        "  inplabel = train_labels[i,:,:,:,:].squeeze()\n",
        "\n",
        "  prediction_point = model.predict(tf.expand_dims(inppoint, axis=0))\n",
        "  prediction_tensor = prediction_point.squeeze()\n",
        "  #print(prediction_tensor.shape)\n",
        "\n",
        "  inppoint = inppoint[:, 1:-1, 1:-1] # NON PERIODIC GETS PLOTTED\n",
        "\n",
        "  fig = datapoint_results_print(inppoint, inplabel, prediction_tensor)\n",
        "\n",
        "  os.mkdir('results/'+str(title))\n",
        "\n",
        "  ### SAVING NUMPY PREDICTIONS\n",
        "  np.save('results/'+str(title)+'/prediction.npy', prediction_tensor)\n",
        "  ### SAVING HTML IMAGES\n",
        "  fig.write_html('results/'+str(title)+'/visualization.html')"
      ],
      "metadata": {
        "id": "nTuoEr8Khjpw",
        "outputId": "3b863bdc-feb5-4756-e696-e54af20f9d09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "8\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "10\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "11\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "12\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "13\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "14\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "15\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "16\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "17\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "18\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "19\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "20\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "21\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "22\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "23\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "24\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "25\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "26\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "27\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "28\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "29\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "30\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "31\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "32\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "33\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "34\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "35\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "36\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "37\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "38\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "39\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "40\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "41\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "42\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "43\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "44\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "45\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "46\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "47\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "48\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "49\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "50\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "51\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "52\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "53\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "54\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "55\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "56\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "57\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "58\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "59\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "60\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "61\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "62\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "63\n",
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PREDICTIONS OVER VALIDATION DATA\n",
        "\n",
        "for i, title in enumerate(validation_paths):\n",
        "  print(i)\n",
        "  inppoint = validation_data[i,:,:,:,:].squeeze()\n",
        "  inplabel = validation_labels[i,:,:,:,:].squeeze()\n",
        "\n",
        "  prediction_point = model.predict(tf.expand_dims(inppoint, axis=0))\n",
        "  prediction_tensor = prediction_point.squeeze()\n",
        "\n",
        "  inppoint = inppoint[:, 1:-1, 1:-1] # NON PERIODIC GETS PLOTTED\n",
        "  fig = datapoint_results_print(inppoint, inplabel, prediction_tensor)\n",
        "  \n",
        "  os.mkdir('results/'+str(title))\n",
        "\n",
        "  ### SAVING NUMPY PREDICTIONS\n",
        "  np.save('results/'+str(title)+'/prediction.npy', prediction_tensor)\n",
        "  ### SAVING HTML IMAGES\n",
        "  fig.write_html('results/'+str(title)+'/visualization.html')"
      ],
      "metadata": {
        "id": "nYhrkn0_iK52",
        "outputId": "8d20ed37-abac-4550-b6ed-4a8fec36d27e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "8\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "10\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "11\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "12\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "13\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "14\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "15\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "16\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "17\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "18\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "19\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "20\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "21\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "22\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "23\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "24\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "25\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "26\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "27\n",
            "1/1 [==============================] - 0s 19ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cluster Analysis \n",
        "In the following cells we perform cluster analysis to compare hotspots produced by the MD simulation and the predictions made by the CNN. "
      ],
      "metadata": {
        "id": "yxkN6Bos4wrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_clusters(temp_grid):\n",
        "  x = []\n",
        "  y = []\n",
        "  z = []\n",
        "  temp = []\n",
        "  for i in range(16):\n",
        "    for j in range(32):\n",
        "      for k in range(32):\n",
        "        if temp_grid[i,j,k] >= 2.0: #temp cut-off\n",
        "          x.append(i+1)\n",
        "          y.append(j+1)\n",
        "          z.append(k+1)\n",
        "          temp.append(temp_grid[i,j,k])\n",
        "  \n",
        "  df = pd.DataFrame(temp,columns=['Temperature'])\n",
        "  df['X'] = x\n",
        "  df['Y'] = y\n",
        "  df['Z'] = z\n",
        "\n",
        "  pos = df[['X','Y','Z']].values\n",
        "  agglo = AgglomerativeClustering(n_clusters=None, distance_threshold=1.8, linkage='single').fit(pos)\n",
        "  df['Cluster ID'] = agglo.labels_\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "-qn0BmGQ6-pY"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_clusters(df):\n",
        "  dataframe = df.copy()\n",
        "  vols = []\n",
        "  mean_temps = []\n",
        "  std_temps = []\n",
        "  cms = []\n",
        "  mis = []\n",
        "  ids = []\n",
        "  #filt = dataframe[dataframe['New ID']<100].dropna()\n",
        "  for i in range(int(dataframe['Cluster ID'].max())+1):\n",
        "    if i in dataframe['Cluster ID'].tolist():\n",
        "      tmp = dataframe[dataframe['Cluster ID'] == i]\n",
        "      v = len(tmp)*4\n",
        "      mean = np.mean(tmp['Temperature']*1000)\n",
        "      std = np.std(tmp['Temperature']*1000)\n",
        "      m = len(tmp)\n",
        "      cm_x = tmp['X'].sum()/m\n",
        "      cm_y = tmp['Y'].sum()/m\n",
        "      cm_z = tmp['Z'].sum()/m\n",
        "      cm = np.array([cm_x,cm_y,cm_z])\n",
        "      r_i = tmp[['X','Y','Z']].values\n",
        "      mom_int = 0\n",
        "      for j in range(len(tmp)):\n",
        "        mom_int += np.linalg.norm(r_i[j]-cm)**2\n",
        "      vols.append(v)\n",
        "      mean_temps.append(mean)\n",
        "      std_temps.append(std)\n",
        "      cms.append(cm)\n",
        "      mis.append(mom_int)\n",
        "      ids.append(i)\n",
        "    else:\n",
        "      pass\n",
        "  \n",
        "  df_clust = pd.DataFrame(ids, columns=['cluster id'])\n",
        "  df_clust['volume'] = vols\n",
        "  df_clust['mean T (K)'] = mean_temps\n",
        "  df_clust['std T (K)'] = std_temps\n",
        "  df_clust['R center of mass'] = cms\n",
        "  df_clust['moment of inertia'] = mis\n",
        "  return df_clust"
      ],
      "metadata": {
        "id": "XdRCjJNX7ivF"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_clusters(md,pred):\n",
        "  fig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"scatter3d\"},{\"type\": \"scatter3d\"}]],\n",
        "                    subplot_titles=[\"MD Clusters\",\"CNN Clusters\"], horizontal_spacing = 0.1, vertical_spacing = 0.1)\n",
        "  fig.update_layout(autosize=False, width=1200, height=800) \n",
        "  trace_1 = go.Scatter3d(x = md['X'], y = md['Y'], z=md['Z'], hovertemplate = 'Cluster ID: %{marker.color:.2f}<extra></extra>',\n",
        "                      mode='markers',  marker=dict(symbol='square', colorscale='rainbow', color = md['Cluster ID']), showlegend=False)\n",
        "  fig.add_trace(trace_1, row=1, col=1)\n",
        "  trace_2 = go.Scatter3d(x = pred['X'], y = pred['Y'], z=pred['Z'], hovertemplate = 'Cluster ID: %{marker.color:.2f}<extra></extra>',\n",
        "                      mode='markers',  marker=dict(symbol='square', colorscale='rainbow', color = pred['Cluster ID']), showlegend=False)\n",
        "  fig.add_trace(trace_2, row=1, col=2)\n",
        "\n",
        "  return fig"
      ],
      "metadata": {
        "id": "f_NPdsZF8YEP"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8mL0swCW8xxf"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "md_temp = np.load(str(paths[0])+'/output.npy')/1000\n",
        "pred_temp = np.load('results/'+str(paths[0])+'/prediction.npy')\n",
        "\n",
        "md_1 = get_clusters(md_temp)\n",
        "pred_1 = get_clusters(pred_temp)\n",
        "\n",
        "md_clust = analyze_clusters(md_1)\n",
        "pred_clust = analyze_clusters(pred_1)"
      ],
      "metadata": {
        "id": "rtRb8l4w7BHd"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_clusters(md_1,pred_1)"
      ],
      "metadata": {
        "id": "Eie6xA577X2H",
        "outputId": "74637593-680c-4319-8a72-9f650b13f4c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"23cc7eaf-81b5-4033-97ba-66cf64295787\" class=\"plotly-graph-div\" style=\"height:800px; width:1200px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"23cc7eaf-81b5-4033-97ba-66cf64295787\")) {                    Plotly.newPlot(                        \"23cc7eaf-81b5-4033-97ba-66cf64295787\",                        [{\"hovertemplate\":\"Cluster ID: %{marker.color:.2f}<extra></extra>\",\"marker\":{\"color\":[25,25,25,25,29,29,16,23,24,10,10,10,10,10,10,10,10,0,10,10,10,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,25,25,25,25,29,16,29,29,16,16,16,10,10,10,10,10,10,10,10,10,10,10,10,10,10,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,15,25,25,25,15,15,15,15,29,29,29,16,10,10,10,10,10,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,15,15,25,15,15,15,15,15,15,15,15,16,16,16,20,20,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,7,27,0,0,0,0,0,7,7,0,0,0,0,0,0,0,0,0,15,15,15,15,15,15,15,6,15,15,6,30,28,28,20,0,0,7,7,0,0,0,7,7,7,7,0,0,0,0,7,7,7,0,0,0,0,0,0,0,0,6,6,30,6,28,28,0,0,7,7,7,7,7,0,7,7,7,0,0,0,0,0,0,6,6,6,6,6,6,6,6,6,28,17,3,0,0,0,11,11,7,7,7,0,0,18,6,6,6,6,6,6,6,6,3,3,0,0,0,11,7,7,6,6,6,6,6,6,6,3,0,0,11,21,21,21,6,6,6,0,0,0,21,21,6,6,0,1,1,1,1,1,22,22,22,22,22,2,0,1,1,1,1,1,1,1,22,22,22,22,22,22,22,2,2,2,0,14,2,22,2,22,2,22,0,0,14,14,4,12,5,0,0,0,0,14,4,12,12,26,5,19,19,19,8,13,13,13,0,0,0,0,0,0,0,0,0,0,0,0,0],\"colorscale\":[[0.0,\"rgb(150,0,90)\"],[0.125,\"rgb(0,0,200)\"],[0.25,\"rgb(0,25,255)\"],[0.375,\"rgb(0,152,255)\"],[0.5,\"rgb(44,255,150)\"],[0.625,\"rgb(151,255,0)\"],[0.75,\"rgb(255,234,0)\"],[0.875,\"rgb(255,111,0)\"],[1.0,\"rgb(255,0,0)\"]],\"symbol\":\"square\"},\"mode\":\"markers\",\"showlegend\":false,\"x\":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,11,11,11,11,11,12,12,12,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16],\"y\":[3,3,3,3,9,9,9,12,14,21,21,21,21,22,22,22,22,23,23,23,23,24,24,24,25,25,25,25,25,26,26,26,26,26,26,27,27,27,27,28,28,28,29,29,29,30,30,30,31,31,32,32,3,3,3,4,8,8,9,9,9,9,10,21,21,21,21,22,22,22,22,22,23,23,23,23,23,24,24,24,25,25,25,26,26,26,26,26,26,26,27,27,27,27,27,28,28,28,28,29,29,29,29,30,30,30,31,31,31,32,32,32,1,1,3,3,4,4,5,5,6,8,9,9,9,22,22,23,23,23,24,25,26,26,26,27,27,27,27,27,28,28,28,28,28,29,29,29,29,29,29,30,30,30,30,30,31,31,31,31,32,32,32,32,1,1,2,3,3,3,4,4,4,5,5,6,9,10,10,16,17,25,26,27,27,28,28,28,28,28,29,29,29,29,29,29,29,29,30,30,30,30,30,30,30,30,31,31,31,31,31,32,32,32,32,1,2,3,3,4,4,4,4,5,5,5,7,8,9,17,24,28,28,28,29,29,29,29,29,29,29,30,30,30,30,30,30,30,31,31,31,31,32,32,32,32,5,5,7,7,8,9,24,25,28,28,29,29,29,30,30,30,30,31,31,31,32,32,32,5,5,6,7,7,7,8,8,8,9,14,17,24,24,25,26,26,27,28,28,31,31,1,6,6,7,7,7,8,8,8,16,17,23,24,24,26,27,27,5,6,6,7,7,7,8,16,23,24,26,1,1,2,6,7,8,23,24,24,1,1,7,8,24,8,9,9,10,10,21,21,22,22,23,24,24,7,8,8,8,9,9,9,21,21,21,22,22,22,23,23,24,24,24,26,20,21,21,22,22,23,24,25,25,26,30,3,10,24,24,25,25,25,30,3,3,9,10,14,15,15,15,20,21,22,24,24,25,25,25,26,26,26,27,28,29,30,31],\"z\":[1,2,3,4,1,2,6,30,3,27,28,29,30,27,28,29,30,22,28,29,31,20,21,22,19,20,21,22,23,19,20,21,22,23,24,20,21,22,23,21,22,23,21,22,23,21,22,23,21,22,21,22,2,3,4,2,2,5,1,2,5,6,6,27,28,29,30,27,28,29,30,31,27,28,29,30,31,20,21,22,20,21,22,15,19,20,21,22,23,24,20,21,22,23,24,20,21,22,23,20,21,22,23,21,22,23,21,22,23,20,21,22,21,22,2,3,2,20,18,19,18,2,1,2,5,27,28,27,28,29,20,20,15,20,21,20,21,22,23,24,20,21,22,23,24,20,21,22,23,24,25,20,21,22,23,24,20,21,22,23,19,20,21,22,21,22,21,2,20,21,19,20,21,18,19,18,5,4,5,1,1,20,20,20,21,20,21,23,24,25,20,21,22,23,24,25,28,29,16,20,21,22,23,24,28,29,19,20,21,22,23,19,20,21,22,22,21,20,21,18,19,20,29,18,19,29,10,13,13,1,19,21,29,30,20,21,25,28,29,30,31,20,21,22,23,28,29,30,19,20,21,22,19,20,21,22,29,30,10,30,12,13,19,19,29,30,28,29,30,22,28,29,30,20,21,22,20,21,22,29,30,30,29,30,31,29,30,31,13,6,29,18,19,19,1,2,29,29,30,21,22,2,30,31,29,30,31,29,30,31,29,29,18,18,19,1,29,30,32,30,31,29,30,31,30,29,18,19,1,14,15,15,30,30,30,19,18,19,14,15,30,30,19,21,21,22,21,22,2,3,2,3,2,11,19,21,20,21,22,20,21,22,1,2,3,1,2,3,2,11,10,11,19,32,10,2,10,2,10,2,19,19,32,32,6,1,5,19,20,19,20,32,6,1,2,2,6,3,3,4,32,28,27,27,20,21,19,20,21,19,20,21,21,22,22,22,22],\"type\":\"scatter3d\",\"scene\":\"scene\"},{\"hovertemplate\":\"Cluster ID: %{marker.color:.2f}<extra></extra>\",\"marker\":{\"color\":[7,7,7,11,11,6,6,3,3,3,3,3,3,3,3,20,3,3,3,3,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,12,7,7,7,7,11,11,11,11,6,3,3,3,3,3,3,3,20,20,3,3,3,3,3,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,12,12,12,12,7,7,12,12,12,12,12,11,20,3,20,20,20,2,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,12,12,12,12,12,12,12,12,12,12,12,12,12,20,20,2,20,20,20,20,20,20,20,20,20,21,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,12,12,12,12,12,12,12,12,12,12,12,12,13,13,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,1,13,13,13,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,1,1,1,1,1,1,1,1,8,8,20,20,20,20,20,20,20,20,1,1,1,1,1,1,1,1,1,15,8,8,8,8,20,20,20,20,20,20,1,1,1,1,1,1,1,1,8,8,8,20,20,20,1,1,8,14,14,14,14,4,4,9,9,9,9,14,14,14,14,14,0,4,4,4,4,4,4,9,9,9,9,18,14,4,4,0,4,4,0,4,9,9,18,18,5,5,5,17,18,18,18,18,5,5,5,5,16,19,10,10,10,10,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18],\"colorscale\":[[0.0,\"rgb(150,0,90)\"],[0.125,\"rgb(0,0,200)\"],[0.25,\"rgb(0,25,255)\"],[0.375,\"rgb(0,152,255)\"],[0.5,\"rgb(44,255,150)\"],[0.625,\"rgb(151,255,0)\"],[0.75,\"rgb(255,234,0)\"],[0.875,\"rgb(255,111,0)\"],[1.0,\"rgb(255,0,0)\"]],\"symbol\":\"square\"},\"mode\":\"markers\",\"showlegend\":false,\"x\":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,9,9,9,10,10,10,11,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16],\"y\":[3,3,3,8,9,17,18,20,21,21,21,22,22,22,22,23,23,23,23,23,24,24,24,24,25,25,25,25,25,25,26,26,26,26,26,26,27,27,27,27,27,28,28,28,29,29,29,30,30,30,31,31,32,32,1,3,3,3,4,8,8,9,9,17,21,21,22,22,22,22,22,23,23,23,23,23,23,23,24,24,24,25,25,25,25,25,26,26,26,26,26,26,27,27,27,27,27,28,28,28,28,28,29,29,29,29,29,29,30,30,30,30,31,31,31,31,32,32,32,1,1,1,2,3,3,3,3,4,4,5,8,23,23,24,25,25,26,26,26,26,27,27,27,27,27,27,28,28,28,28,28,28,29,29,29,29,29,29,29,29,30,30,30,30,30,30,30,30,31,31,31,31,31,32,32,32,32,1,1,1,2,2,3,3,4,4,4,4,5,5,25,26,27,27,27,27,27,28,28,28,28,28,29,29,29,29,29,29,29,29,29,29,29,29,30,30,30,30,30,30,30,30,30,31,31,31,31,31,32,32,32,32,1,1,1,2,2,3,3,4,4,4,5,5,8,9,28,28,28,29,29,29,29,29,29,29,29,30,30,30,30,30,30,30,30,31,31,31,32,32,32,32,7,8,8,9,27,28,28,29,29,29,29,30,30,30,30,31,31,32,32,5,6,7,7,7,8,8,8,23,24,26,27,27,28,28,30,31,31,5,6,6,7,7,7,8,8,8,16,23,23,24,24,26,26,27,27,30,31,5,5,6,6,7,7,7,8,22,23,24,26,27,31,6,7,23,9,8,9,10,21,22,23,23,24,24,7,8,8,9,10,19,20,20,21,21,22,23,23,23,24,24,24,8,20,20,20,21,21,21,22,23,24,24,25,29,30,30,4,24,25,25,26,29,29,30,30,3,17,20,21,21,22,24,24,25,25,25,26,26,26,26,27,27,27,27,28,28,29,30,31,31],\"z\":[2,3,4,2,2,18,18,27,27,28,29,27,28,29,30,22,27,28,30,31,20,21,22,23,19,20,21,22,23,24,19,20,21,22,23,24,20,21,22,23,24,21,22,23,21,22,23,21,22,23,21,22,21,22,21,2,3,4,2,1,2,1,2,18,27,28,27,28,29,30,31,20,21,27,28,29,30,31,20,21,22,20,21,22,23,24,19,20,21,22,23,24,20,21,22,23,24,20,21,22,23,24,21,22,23,24,26,27,20,21,22,23,20,21,22,23,20,21,22,20,21,22,21,2,3,20,21,19,20,19,2,20,28,20,20,21,15,20,21,22,20,21,22,23,24,25,20,21,22,23,24,25,20,21,22,23,24,25,26,27,20,21,22,23,24,25,26,27,19,20,21,22,23,19,20,21,22,20,21,22,20,21,20,21,18,19,20,21,18,19,20,20,15,20,21,24,25,20,21,22,24,25,16,19,20,21,22,23,24,25,26,27,28,29,19,20,21,22,23,24,25,27,28,19,20,21,22,23,19,20,21,22,20,21,22,20,21,20,21,18,19,20,18,19,13,13,21,29,30,20,21,22,25,28,29,30,31,20,21,22,23,28,29,30,31,20,21,22,19,20,21,22,30,12,13,13,30,29,30,21,28,29,30,21,22,28,29,21,22,21,22,30,30,29,30,31,29,30,31,18,18,30,29,30,29,30,22,21,22,30,30,31,29,30,31,29,30,31,29,18,19,18,19,29,30,29,30,22,22,30,31,30,31,29,30,31,30,18,18,18,30,30,22,30,30,18,21,21,21,21,2,2,10,11,10,11,21,20,21,21,21,11,2,3,2,3,2,2,10,11,10,11,19,21,2,3,10,2,3,10,2,11,11,19,19,6,6,7,9,19,19,20,20,6,7,6,7,2,18,27,27,28,27,19,20,19,20,21,19,20,21,22,20,21,22,23,21,22,22,22,21,22],\"type\":\"scatter3d\",\"scene\":\"scene2\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"scene\":{\"domain\":{\"x\":[0.0,0.45],\"y\":[0.0,1.0]}},\"scene2\":{\"domain\":{\"x\":[0.55,1.0],\"y\":[0.0,1.0]}},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"MD Clusters\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"CNN Clusters\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"autosize\":false,\"width\":1200,\"height\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('23cc7eaf-81b5-4033-97ba-66cf64295787');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(md_1, pred_1, md_clust, pred_clust):\n",
        "  fig = make_subplots(rows=1, cols=3, specs=[[{\"type\": \"scatter3d\"},{\"type\": \"scatter3d\"},{\"type\": \"scatter\"}]],\n",
        "                      subplot_titles=[\"MD Clusters\",\"CNN Clusters\",\"Temp vs Volume\"], horizontal_spacing = 0.1, vertical_spacing = 0.1)\n",
        "  fig.update_layout(autosize=False, width=1800, height=600) \n",
        "\n",
        "\n",
        "  ## MD SIMULATION CLUSTERS ##\n",
        "  tmp = md_1\n",
        "  trace_1 = go.Scatter3d(x = tmp['X'], y = tmp['Y'], z = tmp['Z'],text=tmp['Cluster ID'],\n",
        "                        mode='markers', marker=dict(size=8, line=dict(width=0), symbol='square', colorscale='rainbow', color = tmp['Cluster ID']), showlegend=False, scene='scene1')\n",
        " \n",
        "  fig.add_trace(trace_1, row=1, col=1)\n",
        "\n",
        "  ## CNN PREDICTED CLUSTERS ##\n",
        "  tmp2 = pred_1\n",
        "  trace_4 = go.Scatter3d(x = tmp2['X'], y = tmp2['Y'], z = tmp2['Z'],text=tmp2['Cluster ID'],\n",
        "                        mode='markers', marker=dict(size=8, line=dict(width=0), symbol='square', colorscale='rainbow', color = tmp2['Cluster ID']), showlegend=False, scene='scene2')\n",
        "\n",
        "\n",
        "  fig.add_trace(trace_4, row=1, col=2)\n",
        "\n",
        "\n",
        "\n",
        "  ### Hotspot Temperature vs Volume ###\n",
        "  trace_7 = go.Scatter(x=md_clust['volume'],y=md_clust['mean T (K)'],error_y=dict(type='data', array=md_clust['std T (K)'],visible=True),text=md_clust['cluster id'],\n",
        "                      mode='markers',marker=dict(symbol='square', color = 'green',size=18),name='MD')\n",
        "  trace_8 = go.Scatter(x=pred_clust['volume'],y=pred_clust['mean T (K)'],error_y=dict(type='data', array=pred_clust['std T (K)'],visible=True),text=md_clust['cluster id'],\n",
        "                        mode='markers',marker=dict(symbol='circle', color = 'red',size=18),name='CNN')\n",
        "\n",
        "  fig.add_trace(trace_7, row=1, col=3)\n",
        "  fig.add_trace(trace_8, row=1, col=3)\n",
        "  fig.update_xaxes(title=\"Volume\")\n",
        "  fig.update_yaxes(title=\"Temperature (K)\")\n",
        "\n",
        "  ### Hotspot Moment inertia parity plot ###\n",
        "  #trace_9 = go.Scatter(x=np.log10(md_clust['moment of inertia']),y=np.log10(pred_clust['moment of inertia']),\n",
        "   #                   mode='markers',marker=dict(symbol='square',color='green',size=14), showlegend=False)\n",
        "\n",
        "  #fig.add_trace(trace_9, row=2, col=2)\n",
        "  #fig.update_yaxes(title=\"Predicted log(moment of inertia)\")\n",
        "  #fig.update_xaxes(title=\"MD Simulated log(moment of inertia))\")\n",
        "\n",
        "  #def cam_change(layout, camera):\n",
        "  #   fig.layout.scene2.camera = camera\n",
        "  #fig.layout.scene1.on_change(cam_change, 'camera')\n",
        "  return fig"
      ],
      "metadata": {
        "id": "k4qJEPY07X5Y"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize(md_1,pred_1,md_clust,pred_clust)"
      ],
      "metadata": {
        "id": "sXjtJnug9QqB",
        "outputId": "66fbcabf-c483-4455-85c3-82f7744ee391",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"ea761e16-e4d4-46f9-8519-7c466e00334d\" class=\"plotly-graph-div\" style=\"height:600px; width:1800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ea761e16-e4d4-46f9-8519-7c466e00334d\")) {                    Plotly.newPlot(                        \"ea761e16-e4d4-46f9-8519-7c466e00334d\",                        [{\"marker\":{\"color\":[25,25,25,25,29,29,16,23,24,10,10,10,10,10,10,10,10,0,10,10,10,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,25,25,25,25,29,16,29,29,16,16,16,10,10,10,10,10,10,10,10,10,10,10,10,10,10,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,15,25,25,25,15,15,15,15,29,29,29,16,10,10,10,10,10,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,15,15,25,15,15,15,15,15,15,15,15,16,16,16,20,20,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,7,27,0,0,0,0,0,7,7,0,0,0,0,0,0,0,0,0,15,15,15,15,15,15,15,6,15,15,6,30,28,28,20,0,0,7,7,0,0,0,7,7,7,7,0,0,0,0,7,7,7,0,0,0,0,0,0,0,0,6,6,30,6,28,28,0,0,7,7,7,7,7,0,7,7,7,0,0,0,0,0,0,6,6,6,6,6,6,6,6,6,28,17,3,0,0,0,11,11,7,7,7,0,0,18,6,6,6,6,6,6,6,6,3,3,0,0,0,11,7,7,6,6,6,6,6,6,6,3,0,0,11,21,21,21,6,6,6,0,0,0,21,21,6,6,0,1,1,1,1,1,22,22,22,22,22,2,0,1,1,1,1,1,1,1,22,22,22,22,22,22,22,2,2,2,0,14,2,22,2,22,2,22,0,0,14,14,4,12,5,0,0,0,0,14,4,12,12,26,5,19,19,19,8,13,13,13,0,0,0,0,0,0,0,0,0,0,0,0,0],\"colorscale\":[[0.0,\"rgb(150,0,90)\"],[0.125,\"rgb(0,0,200)\"],[0.25,\"rgb(0,25,255)\"],[0.375,\"rgb(0,152,255)\"],[0.5,\"rgb(44,255,150)\"],[0.625,\"rgb(151,255,0)\"],[0.75,\"rgb(255,234,0)\"],[0.875,\"rgb(255,111,0)\"],[1.0,\"rgb(255,0,0)\"]],\"line\":{\"width\":0},\"size\":8,\"symbol\":\"square\"},\"mode\":\"markers\",\"scene\":\"scene\",\"showlegend\":false,\"text\":[25.0,25.0,25.0,25.0,29.0,29.0,16.0,23.0,24.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,0.0,10.0,10.0,10.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,25.0,25.0,25.0,25.0,29.0,16.0,29.0,29.0,16.0,16.0,16.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,0.0,0.0,0.0,0.0,0.0,0.0,9.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,15.0,15.0,25.0,25.0,25.0,15.0,15.0,15.0,15.0,29.0,29.0,29.0,16.0,10.0,10.0,10.0,10.0,10.0,0.0,0.0,9.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,15.0,15.0,15.0,25.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,16.0,16.0,16.0,20.0,20.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,7.0,7.0,27.0,0.0,0.0,0.0,0.0,0.0,7.0,7.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,6.0,15.0,15.0,6.0,30.0,28.0,28.0,20.0,0.0,0.0,7.0,7.0,0.0,0.0,0.0,7.0,7.0,7.0,7.0,0.0,0.0,0.0,0.0,7.0,7.0,7.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,6.0,6.0,30.0,6.0,28.0,28.0,0.0,0.0,7.0,7.0,7.0,7.0,7.0,0.0,7.0,7.0,7.0,0.0,0.0,0.0,0.0,0.0,0.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,28.0,17.0,3.0,0.0,0.0,0.0,11.0,11.0,7.0,7.0,7.0,0.0,0.0,18.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,3.0,3.0,0.0,0.0,0.0,11.0,7.0,7.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,3.0,0.0,0.0,11.0,21.0,21.0,21.0,6.0,6.0,6.0,0.0,0.0,0.0,21.0,21.0,6.0,6.0,0.0,1.0,1.0,1.0,1.0,1.0,22.0,22.0,22.0,22.0,22.0,2.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,22.0,22.0,22.0,22.0,22.0,22.0,22.0,2.0,2.0,2.0,0.0,14.0,2.0,22.0,2.0,22.0,2.0,22.0,0.0,0.0,14.0,14.0,4.0,12.0,5.0,0.0,0.0,0.0,0.0,14.0,4.0,12.0,12.0,26.0,5.0,19.0,19.0,19.0,8.0,13.0,13.0,13.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"x\":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,11,11,11,11,11,12,12,12,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16],\"y\":[3,3,3,3,9,9,9,12,14,21,21,21,21,22,22,22,22,23,23,23,23,24,24,24,25,25,25,25,25,26,26,26,26,26,26,27,27,27,27,28,28,28,29,29,29,30,30,30,31,31,32,32,3,3,3,4,8,8,9,9,9,9,10,21,21,21,21,22,22,22,22,22,23,23,23,23,23,24,24,24,25,25,25,26,26,26,26,26,26,26,27,27,27,27,27,28,28,28,28,29,29,29,29,30,30,30,31,31,31,32,32,32,1,1,3,3,4,4,5,5,6,8,9,9,9,22,22,23,23,23,24,25,26,26,26,27,27,27,27,27,28,28,28,28,28,29,29,29,29,29,29,30,30,30,30,30,31,31,31,31,32,32,32,32,1,1,2,3,3,3,4,4,4,5,5,6,9,10,10,16,17,25,26,27,27,28,28,28,28,28,29,29,29,29,29,29,29,29,30,30,30,30,30,30,30,30,31,31,31,31,31,32,32,32,32,1,2,3,3,4,4,4,4,5,5,5,7,8,9,17,24,28,28,28,29,29,29,29,29,29,29,30,30,30,30,30,30,30,31,31,31,31,32,32,32,32,5,5,7,7,8,9,24,25,28,28,29,29,29,30,30,30,30,31,31,31,32,32,32,5,5,6,7,7,7,8,8,8,9,14,17,24,24,25,26,26,27,28,28,31,31,1,6,6,7,7,7,8,8,8,16,17,23,24,24,26,27,27,5,6,6,7,7,7,8,16,23,24,26,1,1,2,6,7,8,23,24,24,1,1,7,8,24,8,9,9,10,10,21,21,22,22,23,24,24,7,8,8,8,9,9,9,21,21,21,22,22,22,23,23,24,24,24,26,20,21,21,22,22,23,24,25,25,26,30,3,10,24,24,25,25,25,30,3,3,9,10,14,15,15,15,20,21,22,24,24,25,25,25,26,26,26,27,28,29,30,31],\"z\":[1,2,3,4,1,2,6,30,3,27,28,29,30,27,28,29,30,22,28,29,31,20,21,22,19,20,21,22,23,19,20,21,22,23,24,20,21,22,23,21,22,23,21,22,23,21,22,23,21,22,21,22,2,3,4,2,2,5,1,2,5,6,6,27,28,29,30,27,28,29,30,31,27,28,29,30,31,20,21,22,20,21,22,15,19,20,21,22,23,24,20,21,22,23,24,20,21,22,23,20,21,22,23,21,22,23,21,22,23,20,21,22,21,22,2,3,2,20,18,19,18,2,1,2,5,27,28,27,28,29,20,20,15,20,21,20,21,22,23,24,20,21,22,23,24,20,21,22,23,24,25,20,21,22,23,24,20,21,22,23,19,20,21,22,21,22,21,2,20,21,19,20,21,18,19,18,5,4,5,1,1,20,20,20,21,20,21,23,24,25,20,21,22,23,24,25,28,29,16,20,21,22,23,24,28,29,19,20,21,22,23,19,20,21,22,22,21,20,21,18,19,20,29,18,19,29,10,13,13,1,19,21,29,30,20,21,25,28,29,30,31,20,21,22,23,28,29,30,19,20,21,22,19,20,21,22,29,30,10,30,12,13,19,19,29,30,28,29,30,22,28,29,30,20,21,22,20,21,22,29,30,30,29,30,31,29,30,31,13,6,29,18,19,19,1,2,29,29,30,21,22,2,30,31,29,30,31,29,30,31,29,29,18,18,19,1,29,30,32,30,31,29,30,31,30,29,18,19,1,14,15,15,30,30,30,19,18,19,14,15,30,30,19,21,21,22,21,22,2,3,2,3,2,11,19,21,20,21,22,20,21,22,1,2,3,1,2,3,2,11,10,11,19,32,10,2,10,2,10,2,19,19,32,32,6,1,5,19,20,19,20,32,6,1,2,2,6,3,3,4,32,28,27,27,20,21,19,20,21,19,20,21,21,22,22,22,22],\"type\":\"scatter3d\"},{\"marker\":{\"color\":[7,7,7,11,11,6,6,3,3,3,3,3,3,3,3,20,3,3,3,3,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,12,7,7,7,7,11,11,11,11,6,3,3,3,3,3,3,3,20,20,3,3,3,3,3,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,12,12,12,12,7,7,12,12,12,12,12,11,20,3,20,20,20,2,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,12,12,12,12,12,12,12,12,12,12,12,12,12,20,20,2,20,20,20,20,20,20,20,20,20,21,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,12,12,12,12,12,12,12,12,12,12,12,12,13,13,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,1,13,13,13,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,1,1,1,1,1,1,1,1,8,8,20,20,20,20,20,20,20,20,1,1,1,1,1,1,1,1,1,15,8,8,8,8,20,20,20,20,20,20,1,1,1,1,1,1,1,1,8,8,8,20,20,20,1,1,8,14,14,14,14,4,4,9,9,9,9,14,14,14,14,14,0,4,4,4,4,4,4,9,9,9,9,18,14,4,4,0,4,4,0,4,9,9,18,18,5,5,5,17,18,18,18,18,5,5,5,5,16,19,10,10,10,10,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18],\"colorscale\":[[0.0,\"rgb(150,0,90)\"],[0.125,\"rgb(0,0,200)\"],[0.25,\"rgb(0,25,255)\"],[0.375,\"rgb(0,152,255)\"],[0.5,\"rgb(44,255,150)\"],[0.625,\"rgb(151,255,0)\"],[0.75,\"rgb(255,234,0)\"],[0.875,\"rgb(255,111,0)\"],[1.0,\"rgb(255,0,0)\"]],\"line\":{\"width\":0},\"size\":8,\"symbol\":\"square\"},\"mode\":\"markers\",\"scene\":\"scene2\",\"showlegend\":false,\"text\":[7.0,7.0,7.0,11.0,11.0,6.0,6.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,20.0,3.0,3.0,3.0,3.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,12.0,7.0,7.0,7.0,7.0,11.0,11.0,11.0,11.0,6.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,20.0,20.0,3.0,3.0,3.0,3.0,3.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,12.0,12.0,12.0,12.0,7.0,7.0,12.0,12.0,12.0,12.0,12.0,11.0,20.0,3.0,20.0,20.0,20.0,2.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,12.0,12.0,12.0,12.0,12.0,12.0,12.0,12.0,12.0,12.0,12.0,12.0,12.0,20.0,20.0,2.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,21.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,12.0,12.0,12.0,12.0,12.0,12.0,12.0,12.0,12.0,12.0,12.0,12.0,13.0,13.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,1.0,13.0,13.0,13.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,8.0,8.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,20.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,15.0,8.0,8.0,8.0,8.0,20.0,20.0,20.0,20.0,20.0,20.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,8.0,8.0,8.0,20.0,20.0,20.0,1.0,1.0,8.0,14.0,14.0,14.0,14.0,4.0,4.0,9.0,9.0,9.0,9.0,14.0,14.0,14.0,14.0,14.0,0.0,4.0,4.0,4.0,4.0,4.0,4.0,9.0,9.0,9.0,9.0,18.0,14.0,4.0,4.0,0.0,4.0,4.0,0.0,4.0,9.0,9.0,18.0,18.0,5.0,5.0,5.0,17.0,18.0,18.0,18.0,18.0,5.0,5.0,5.0,5.0,16.0,19.0,10.0,10.0,10.0,10.0,18.0,18.0,18.0,18.0,18.0,18.0,18.0,18.0,18.0,18.0,18.0,18.0,18.0,18.0,18.0,18.0,18.0,18.0,18.0],\"x\":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,9,9,9,10,10,10,11,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16],\"y\":[3,3,3,8,9,17,18,20,21,21,21,22,22,22,22,23,23,23,23,23,24,24,24,24,25,25,25,25,25,25,26,26,26,26,26,26,27,27,27,27,27,28,28,28,29,29,29,30,30,30,31,31,32,32,1,3,3,3,4,8,8,9,9,17,21,21,22,22,22,22,22,23,23,23,23,23,23,23,24,24,24,25,25,25,25,25,26,26,26,26,26,26,27,27,27,27,27,28,28,28,28,28,29,29,29,29,29,29,30,30,30,30,31,31,31,31,32,32,32,1,1,1,2,3,3,3,3,4,4,5,8,23,23,24,25,25,26,26,26,26,27,27,27,27,27,27,28,28,28,28,28,28,29,29,29,29,29,29,29,29,30,30,30,30,30,30,30,30,31,31,31,31,31,32,32,32,32,1,1,1,2,2,3,3,4,4,4,4,5,5,25,26,27,27,27,27,27,28,28,28,28,28,29,29,29,29,29,29,29,29,29,29,29,29,30,30,30,30,30,30,30,30,30,31,31,31,31,31,32,32,32,32,1,1,1,2,2,3,3,4,4,4,5,5,8,9,28,28,28,29,29,29,29,29,29,29,29,30,30,30,30,30,30,30,30,31,31,31,32,32,32,32,7,8,8,9,27,28,28,29,29,29,29,30,30,30,30,31,31,32,32,5,6,7,7,7,8,8,8,23,24,26,27,27,28,28,30,31,31,5,6,6,7,7,7,8,8,8,16,23,23,24,24,26,26,27,27,30,31,5,5,6,6,7,7,7,8,22,23,24,26,27,31,6,7,23,9,8,9,10,21,22,23,23,24,24,7,8,8,9,10,19,20,20,21,21,22,23,23,23,24,24,24,8,20,20,20,21,21,21,22,23,24,24,25,29,30,30,4,24,25,25,26,29,29,30,30,3,17,20,21,21,22,24,24,25,25,25,26,26,26,26,27,27,27,27,28,28,29,30,31,31],\"z\":[2,3,4,2,2,18,18,27,27,28,29,27,28,29,30,22,27,28,30,31,20,21,22,23,19,20,21,22,23,24,19,20,21,22,23,24,20,21,22,23,24,21,22,23,21,22,23,21,22,23,21,22,21,22,21,2,3,4,2,1,2,1,2,18,27,28,27,28,29,30,31,20,21,27,28,29,30,31,20,21,22,20,21,22,23,24,19,20,21,22,23,24,20,21,22,23,24,20,21,22,23,24,21,22,23,24,26,27,20,21,22,23,20,21,22,23,20,21,22,20,21,22,21,2,3,20,21,19,20,19,2,20,28,20,20,21,15,20,21,22,20,21,22,23,24,25,20,21,22,23,24,25,20,21,22,23,24,25,26,27,20,21,22,23,24,25,26,27,19,20,21,22,23,19,20,21,22,20,21,22,20,21,20,21,18,19,20,21,18,19,20,20,15,20,21,24,25,20,21,22,24,25,16,19,20,21,22,23,24,25,26,27,28,29,19,20,21,22,23,24,25,27,28,19,20,21,22,23,19,20,21,22,20,21,22,20,21,20,21,18,19,20,18,19,13,13,21,29,30,20,21,22,25,28,29,30,31,20,21,22,23,28,29,30,31,20,21,22,19,20,21,22,30,12,13,13,30,29,30,21,28,29,30,21,22,28,29,21,22,21,22,30,30,29,30,31,29,30,31,18,18,30,29,30,29,30,22,21,22,30,30,31,29,30,31,29,30,31,29,18,19,18,19,29,30,29,30,22,22,30,31,30,31,29,30,31,30,18,18,18,30,30,22,30,30,18,21,21,21,21,2,2,10,11,10,11,21,20,21,21,21,11,2,3,2,3,2,2,10,11,10,11,19,21,2,3,10,2,3,10,2,11,11,19,19,6,6,7,9,19,19,20,20,6,7,6,7,2,18,27,27,28,27,19,20,19,20,21,19,20,21,22,20,21,22,23,21,22,22,22,21,22],\"type\":\"scatter3d\"},{\"error_y\":{\"array\":[557.8056664722553,240.98000335868124,100.20491914276549,7.009012055917811,73.74000000000001,6.494999999999891,309.1094257714872,283.3447320053392,0.0,63.85500000000002,310.59650526473524,89.8379013835475,131.14121684487887,71.64436055964208,26.97288731300382,301.8978973549946,170.68528343195524,0.0,0.0,56.05575220756172,147.41338481366688,109.71930688807689,226.41124184299878,0.0,0.0,318.174814400433,0.0,0.0,119.88671042279883,189.70168185453048,115.13000000000011],\"type\":\"data\",\"visible\":true},\"marker\":{\"color\":\"green\",\"size\":18,\"symbol\":\"square\"},\"mode\":\"markers\",\"name\":\"MD\",\"text\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,22.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0],\"x\":[756,48,28,16,8,8,136,104,4,8,120,16,12,12,16,104,36,4,4,12,12,20,60,4,4,48,4,4,20,32,8],\"y\":[2665.0955026455026,2267.6924999999997,2157.167142857143,2015.66,2141.99,2016.3749999999998,2422.1885294117646,2325.954230769231,2043.7500000000002,2135.795,2453.098,2101.485,2294.876666666667,2191.87,2039.88,2440.6426923076924,2244.485555555556,2194.41,2012.1299999999999,2120.3966666666665,2306.346666666667,2141.746,2291.4206666666664,2079.44,2115.38,2514.5875,2209.23,2046.22,2163.2880000000005,2377.4162499999998,2121.96],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"error_y\":{\"array\":[12.879219055175781,214.41566467285156,18.33343505859375,181.85675048828125,182.2961883544922,80.5062255859375,92.91870880126953,182.70347595214844,68.77290344238281,163.93280029296875,92.99191284179688,72.82861328125,232.18771362304688,87.88333129882812,188.5144805908203,0.0,0.0,0.0,230.38394165039062,0.0,497.4657287597656,0.0],\"type\":\"data\",\"visible\":true},\"marker\":{\"color\":\"red\",\"size\":18,\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"CNN\",\"text\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,22.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0],\"x\":[12,112,8,100,52,28,12,36,40,40,16,28,140,20,40,4,4,4,104,4,880,4],\"y\":[2052.743896484375,2270.73193359375,2029.20166015625,2288.459716796875,2211.14599609375,2199.86376953125,2106.638671875,2383.522705078125,2083.913330078125,2206.80712890625,2116.45654296875,2099.322998046875,2337.3017578125,2168.73876953125,2254.677001953125,2027.3363037109375,2123.597900390625,2054.991455078125,2333.371826171875,2055.17529296875,2582.06298828125,2016.328369140625],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"scene\":{\"domain\":{\"x\":[0.0,0.26666666666666666],\"y\":[0.0,1.0]}},\"scene2\":{\"domain\":{\"x\":[0.3666666666666667,0.6333333333333333],\"y\":[0.0,1.0]}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.7333333333333334,1.0],\"title\":{\"text\":\"Volume\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Temperature (K)\"}},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"MD Clusters\",\"x\":0.13333333333333333,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"CNN Clusters\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Temp vs Volume\",\"x\":0.8666666666666667,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"autosize\":false,\"width\":1800,\"height\":600},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ea761e16-e4d4-46f9-8519-7c466e00334d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CLUSTER ANALYSIS TRAINING DATA\n",
        "\n",
        "for i, title in enumerate(paths):\n",
        "  print(i)\n",
        "  md_temp = np.load(str(title)+'/output.npy')/1000\n",
        "  pred_temp = np.load('results/'+str(title)+'/prediction.npy')\n",
        "\n",
        "  md_1 = get_clusters(md_temp)\n",
        "  pred_1 = get_clusters(pred_temp)\n",
        "\n",
        "  #md_corr, pred_corr, over = overlap(md_1,pred_1)\n",
        "  md_clust = analyze_clusters(md_1)\n",
        "  pred_clust = analyze_clusters(pred_1)\n",
        "\n",
        "  fig = visualize(md_1,pred_1,md_clust,pred_clust)\n",
        "\n",
        "  fig.write_html('results/'+str(title)+'/cluster_2.0.html')"
      ],
      "metadata": {
        "id": "-7rDHgJW-45_",
        "outputId": "abddb901-beae-43b1-ea98-7a67886ab213",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CLUSTER ANALYSIS VALIDATION DATA\n",
        "\n",
        "for i, title in enumerate(validation_paths):\n",
        "  print(i)\n",
        "  md_temp = np.load(str(title)+'/output.npy')/1000\n",
        "  pred_temp = np.load('results/'+str(title)+'/prediction.npy')\n",
        "\n",
        "  md_1 = get_clusters(md_temp)\n",
        "  pred_1 = get_clusters(pred_temp)\n",
        "\n",
        "  #md_corr, pred_corr, over = overlap(md_1,pred_1)\n",
        "  md_clust = analyze_clusters(md_1)\n",
        "  pred_clust = analyze_clusters(pred_1)\n",
        "\n",
        "  fig = visualize(md_1,pred_1,md_clust,pred_clust)\n",
        "\n",
        "  fig.write_html('results/'+str(title)+'/cluster_2.0.html')"
      ],
      "metadata": {
        "id": "gqBW_Zy2_IuM",
        "outputId": "fede93fd-4b0b-4837-d08a-35d020d85918",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the overlap between clusters in the MD and clusters in the CNN. (Under development)"
      ],
      "metadata": {
        "id": "OjhLKedlE44u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def overlap(df1,df2):\n",
        "  md = df1.copy()\n",
        "  pred = df2.copy()\n",
        "  overlap = []\n",
        "  for i in range(md['Cluster ID'].max()+1):\n",
        "    for j in range(pred['Cluster ID'].max()+1):\n",
        "      md_tmp = md[md['Cluster ID'] == i]\n",
        "      pred_tmp = pred[pred['Cluster ID'] == j]\n",
        "      counts = 0\n",
        "      for k in range(len(md_tmp)):\n",
        "        for l in range(len(pred_tmp)):\n",
        "          if (md_tmp[['X','Y','Z']].values[k] == pred_tmp[['X','Y','Z']].values[l]).all():\n",
        "            counts += 1\n",
        "      #if counts > 0:\n",
        "      overlap.append([i,j,counts/len(md_tmp)])\n",
        "  df_overlap = pd.DataFrame(overlap,columns=['MD id','Pred id','fraction'])\n",
        "  over_array = df_overlap[df_overlap['fraction']>0].drop_duplicates(subset=['Pred id'],keep=False).drop_duplicates(subset=['MD id'],keep=False).values\n",
        "  new_id = []\n",
        "  for i in range(len(pred)):\n",
        "    if not (pred['Cluster ID'][i] in over_array[:,1].tolist()):\n",
        "      if pred['Cluster ID'][i] in df_overlap[df_overlap['fraction']>0]['Pred id'].tolist():\n",
        "        new_id.append(100)\n",
        "      else:\n",
        "        new_id.append(None)\n",
        "    for j in range(len(over_array)):\n",
        "      if pred['Cluster ID'][i] == over_array[j,1]:\n",
        "        new_id.append(int(over_array[j,0]))\n",
        "  pred['New ID'] = new_id\n",
        "\n",
        "  new_id = []\n",
        "  for i in range(len(md)):\n",
        "    if not (md['Cluster ID'][i] in over_array[:,0].tolist()):\n",
        "      if md['Cluster ID'][i] in df_overlap[df_overlap['fraction']>0]['MD id'].tolist():\n",
        "          new_id.append(100)\n",
        "      else:\n",
        "          new_id.append(None)\n",
        "    else:\n",
        "      new_id.append(int(md['Cluster ID'][i]))\n",
        "  md['New ID'] = new_id\n",
        "  return md, pred, df_overlap\n",
        "\n",
        "def analyze_clusters(df):\n",
        "  dataframe = df.copy()\n",
        "  vols = []\n",
        "  mean_temps = []\n",
        "  std_temps = []\n",
        "  cms = []\n",
        "  mis = []\n",
        "  ids = []\n",
        "  filt = dataframe[dataframe['New ID']<100].dropna()\n",
        "  for i in range(int(filt['New ID'].max())+1):\n",
        "    if i in filt['New ID'].tolist():\n",
        "      tmp = filt[filt['New ID'] == i]\n",
        "      v = len(tmp)*4\n",
        "      mean = np.mean(tmp['Temperature']*1000)\n",
        "      std = np.std(tmp['Temperature']*1000)\n",
        "      m = len(tmp)\n",
        "      cm_x = tmp['X'].sum()/m\n",
        "      cm_y = tmp['Y'].sum()/m\n",
        "      cm_z = tmp['Z'].sum()/m\n",
        "      cm = np.array([cm_x,cm_y,cm_z])\n",
        "      r_i = tmp[['X','Y','Z']].values\n",
        "      mom_int = 0\n",
        "      for j in range(len(tmp)):\n",
        "        mom_int += np.linalg.norm(r_i[j]-cm)**2\n",
        "      vols.append(v)\n",
        "      mean_temps.append(mean)\n",
        "      std_temps.append(std)\n",
        "      cms.append(cm)\n",
        "      mis.append(mom_int)\n",
        "      ids.append(i)\n",
        "    else:\n",
        "      pass\n",
        "  \n",
        "  df_clust = pd.DataFrame(ids, columns=['cluster id'])\n",
        "  df_clust['volume'] = vols\n",
        "  df_clust['mean T (K)'] = mean_temps\n",
        "  df_clust['std T (K)'] = std_temps\n",
        "  df_clust['R center of mass'] = cms\n",
        "  df_clust['moment of inertia'] = mis\n",
        "  return df_clust"
      ],
      "metadata": {
        "id": "TfOztIGF8B3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(md_corr, pred_corr, md_clust, pred_clust):\n",
        "  fig = make_subplots(rows=2, cols=2, specs=[[{\"type\": \"scatter3d\"},{\"type\": \"scatter3d\"}],\n",
        "                                            [{\"type\": \"scatter\"},{\"type\": \"scatter\"}]],\n",
        "                      subplot_titles=[\"MD Clusters\",\"CNN Clusters\",\"Temp vs Volume\",\"MI Parity Plot\"], horizontal_spacing = 0.1, vertical_spacing = 0.1)\n",
        "  fig.update_layout(autosize=False, width=1200, height=800) \n",
        "\n",
        "\n",
        "  ## MD SIMULATION CLUSTERS ##\n",
        "  tmp = md_corr[md_corr['New ID']<99].dropna()\n",
        "  trace_1 = go.Scatter3d(x = tmp['X'], y = tmp['Y'], z = tmp['Z'],text=tmp['New ID'],\n",
        "                        mode='markers', marker=dict(size=8, line=dict(width=0), symbol='square', colorscale='rainbow', color = tmp['New ID']), showlegend=False, scene='scene1')\n",
        "  tmp = md_corr[md_corr['New ID']==100]\n",
        "  trace_2 = go.Scatter3d(x = tmp['X'], y = tmp['Y'], z = tmp['Z'],text=tmp['Cluster ID'],\n",
        "                        mode='markers', marker=dict(size=8, line=dict(width=0), symbol='square', color = 'grey'), showlegend=False, scene='scene1')\n",
        "  tmp = md_corr[md_corr['New ID'].isnull()]\n",
        "  trace_3 = go.Scatter3d(x = tmp['X'], y = tmp['Y'], z = tmp['Z'],text=tmp['Cluster ID'],\n",
        "                        mode='markers', marker=dict(size=8, line=dict(width=0), symbol='square', color = 'black'), showlegend=False, scene='scene1')    \n",
        "  fig.add_trace(trace_1, row=1, col=1)\n",
        "  fig.add_trace(trace_2, row=1, col=1)\n",
        "  fig.add_trace(trace_3, row=1, col=1)\n",
        "\n",
        "  ## CNN PREDICTED CLUSTERS ##\n",
        "  tmp2 = pred_corr[pred_corr['New ID']<99].dropna()\n",
        "  trace_4 = go.Scatter3d(x = tmp2['X'], y = tmp2['Y'], z = tmp2['Z'],text=tmp2['New ID'],\n",
        "                        mode='markers', marker=dict(size=8, line=dict(width=0), symbol='square', colorscale='rainbow', color = tmp2['New ID']), showlegend=False, scene='scene2')\n",
        "  tmp2 = pred_corr[pred_corr['New ID']==100]\n",
        "  trace_5 = go.Scatter3d(x = tmp2['X'], y = tmp2['Y'], z = tmp2['Z'],text=tmp2['Cluster ID'],\n",
        "                        mode='markers', marker=dict(size=8, line=dict(width=0), symbol='square', color = 'grey'), showlegend=False, scene='scene2')\n",
        "  tmp2 = pred_corr[pred_corr['New ID'].isnull()]\n",
        "  trace_6 = go.Scatter3d(x = tmp2['X'], y = tmp2['Y'], z = tmp2['Z'],text=tmp2['Cluster ID'],\n",
        "                        mode='markers', marker=dict(size=8, line=dict(width=0), symbol='square', color = 'black'), showlegend=False, scene='scene2')\n",
        "\n",
        "  fig.add_trace(trace_4, row=1, col=2)\n",
        "  fig.add_trace(trace_5, row=1, col=2)\n",
        "  fig.add_trace(trace_6, row=1, col=2)\n",
        "\n",
        "\n",
        "  ### Hotspot Temperature vs Volume ###\n",
        "  trace_7 = go.Scatter(x=md_clust['volume'],y=md_clust['mean T (K)'],error_y=dict(type='data', array=md_clust['std T (K)'],visible=True),text=md_clust['cluster id'],\n",
        "                      mode='markers',marker=dict(symbol='square',colorscale='rainbow', color = md_clust['cluster id'],size=18),name='MD')\n",
        "  trace_8 = go.Scatter(x=pred_clust['volume'],y=pred_clust['mean T (K)'],error_y=dict(type='data', array=pred_clust['std T (K)'],visible=True),text=md_clust['cluster id'],\n",
        "                        mode='markers',marker=dict(symbol='circle',colorscale='rainbow', color = md_clust['cluster id'],size=18),name='CNN')\n",
        "\n",
        "  fig.add_trace(trace_7, row=2, col=1)\n",
        "  fig.add_trace(trace_8, row=2, col=1)\n",
        "  fig.update_xaxes(title=\"Volume\")\n",
        "  fig.update_yaxes(title=\"Temperature (K)\")\n",
        "\n",
        "  ### Hotspot Moment inertia parity plot ###\n",
        "  trace_9 = go.Scatter(x=np.log10(md_clust['moment of inertia']),y=np.log10(pred_clust['moment of inertia']),\n",
        "                      mode='markers',marker=dict(symbol='square',color='green',size=14), showlegend=False)\n",
        "\n",
        "  fig.add_trace(trace_9, row=2, col=2)\n",
        "  fig.update_yaxes(title=\"Predicted log(moment of inertia)\")\n",
        "  fig.update_xaxes(title=\"MD Simulated log(moment of inertia))\")\n",
        "\n",
        "  #def cam_change(layout, camera):\n",
        "  #   fig.layout.scene2.camera = camera\n",
        "  #fig.layout.scene1.on_change(cam_change, 'camera')\n",
        "  return fig"
      ],
      "metadata": {
        "id": "UePKih3V3s9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploration GUI  (Under development)"
      ],
      "metadata": {
        "id": "8GgptMfOlBs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FUNCTIONS TO OBSERVE\n",
        "def populate_sliders(change):\n",
        "\n",
        "  with output_plot:\n",
        "    clear_output()\n",
        "  \n",
        "  example_label = np.load(main_dropdown.value + \"/output.npy\").squeeze() / 1000\n",
        "  example_pred = np.load('results/'+main_dropdown.value+\"/prediction.npy\").squeeze()\n",
        "\n",
        "  md_tmp_slider.min = np.min(example_label)\n",
        "  md_tmp_slider.max = np.max(example_label)\n",
        "  md_tmp_slider.value = [np.min(example_label), np.max(example_label)]\n",
        "\n",
        "  pred_tmp_slider.min = np.min(example_pred)\n",
        "  pred_tmp_slider.max = np.max(example_pred)\n",
        "  pred_tmp_slider.value = [np.min(example_pred), np.max(example_pred)]\n",
        "\n",
        "def display_fullplot(change):\n",
        "\n",
        "  with output_plot:\n",
        "    clear_output()\n",
        "\n",
        "  example_inp = np.load(main_dropdown.value + \"/input.npy\").squeeze()\n",
        "  example_inp = example_inp[:, 1:-1, 1:-1] # NON PERIODIC GETS PLOTTED\n",
        "  example_label = np.load(main_dropdown.value + \"/output.npy\").squeeze() / 1000\n",
        "  example_pred = np.load('results/'+main_dropdown.value+\"/prediction.npy\").squeeze()\n",
        "\n",
        "  example_fig = datapoint_results_print(example_inp, example_label, example_pred)\n",
        "  example_fig = go.FigureWidget(example_fig)\n",
        "\n",
        "  if toggle_button.value == \"MD\":\n",
        "\n",
        "    map = np.where(np.logical_and(example_label >=md_tmp_slider.value[0], example_label <=md_tmp_slider.value[1]), 8, 0)\n",
        "    with example_fig.batch_update():\n",
        "      example_fig.data[0].marker.size = map.flatten()\n",
        "      example_fig.data[1].marker.size = map.flatten()\n",
        "      example_fig.data[2].marker.size = map.flatten()\n",
        "      example_fig.data[3].marker.size = map.flatten()\n",
        "      example_fig.data[4].marker.size = map.flatten()\n",
        "\n",
        "  elif toggle_button.value == \"Pred\":\n",
        "\n",
        "    map = np.where(np.logical_and(example_pred>=pred_tmp_slider.value[0],example_pred<=pred_tmp_slider.value[1]), 8, 0)\n",
        "    with example_fig.batch_update():\n",
        "      example_fig.data[0].marker.size = map.flatten()\n",
        "      example_fig.data[1].marker.size = map.flatten()\n",
        "      example_fig.data[2].marker.size = map.flatten()\n",
        "      example_fig.data[3].marker.size = map.flatten()\n",
        "      example_fig.data[4].marker.size = map.flatten()\n",
        "\n",
        "  with output_plot:\n",
        "    example_fig.show()\n",
        "\n",
        "def slider_function(b):\n",
        "  md_tmp_slider.disabled = (toggle_button.value == 'Pred')\n",
        "  pred_tmp_slider.disabled = (toggle_button.value == 'MD')\n",
        "\n",
        "# GETTING LABELS FOR SYSTEMS\n",
        "systems = [x[0] for x in os.walk('results')]\n",
        "systems.remove('results')\n",
        "systems.remove('results/train')\n",
        "systems.remove('results/validation')\n",
        "systems = sorted(['/'.join(x.split('/')[1:]) for x in systems])\n",
        "\n",
        "# WIDGETS\n",
        "main_dropdown = widgets.Dropdown(options=systems, description = \"System: \", continuous_update=False)\n",
        "toggle_button = widgets.ToggleButtons(options=['MD', 'Pred'], description='Filter by:', button_style='')\n",
        "md_tmp_slider = widgets.FloatRangeSlider(value=[0, 1], min=0, max=1, description='MD Temp:', disabled=False, continuous_update=False)\n",
        "pred_tmp_slider = widgets.FloatRangeSlider(value=[0, 1], min=0, max=1, description='CNN Temp:', disabled=True, continuous_update=False)\n",
        "generate_button = widgets.Button(description='Generate', button_style='success', icon='fa-hand-pointer-o')\n",
        "\n",
        "output_plot = widgets.Output()\n",
        "\n",
        "# OBSERVERS\n",
        "main_dropdown.observe(populate_sliders, names='value')\n",
        "toggle_button.observe(slider_function)\n",
        "generate_button.on_click(display_fullplot)\n",
        "\n",
        "controls_box =widgets.VBox([main_dropdown, toggle_button, md_tmp_slider, pred_tmp_slider, generate_button], layout=widgets.Layout(width='100%', display='flex', flex_flow='column', align_items='flex-start'))\n",
        "frame_box = widgets.HBox([controls_box, output_plot])\n",
        "\n",
        "display(frame_box)"
      ],
      "metadata": {
        "id": "-sPms_uLlel7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ru-M1kbxIO5a"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "pbx-local",
      "language": "python",
      "name": "pbx-local"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "f806901b044f1f905f6f73d9d34ac86b2be2e087ac41c051b6f31285dd315984"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}