{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jverduzc/CNN_PBX_Model/blob/master/CNN_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Networks (CNN) for prediction of hotspots on PBX\n",
        "\n",
        "In this notebook we create a CNN model with a U-Net architecture for the prediction of temperature for a plastically bonded explosive molecular dynamics simulation."
      ],
      "metadata": {
        "id": "4QfRMy9VFrcW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries\n",
        "\n",
        "First, we need to set up libraries that are not part of the default environment in Google Colab. In our case, this is only the rendering library ```kaleido```.\n",
        "\n",
        "You will need to restart the runtime to update the kernel.\n",
        "- Menu Runtime -> Restart Runtime"
      ],
      "metadata": {
        "id": "C2UgThuCGG3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaleido"
      ],
      "metadata": {
        "id": "M79B0dH7ftZW",
        "outputId": "ae2fc6de-be19-46c7-8a6f-5e6328d7380b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaleido in /usr/local/lib/python3.7/dist-packages (0.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will then import the required libraries for our notebook to run. The following cells import:\n",
        "- Standard python libraries\n",
        "- Plotting libraries\n",
        "- Machine learning libraries (tensorflow / keras)"
      ],
      "metadata": {
        "id": "2ECMQghLGzUA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5Nd2jeT8r8uu"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import clear_output\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "qrgVqntVG6YP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "V08TFba6G_nw"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import initializers\n",
        "from keras.layers import Input, Dropout, BatchNormalization, Conv3DTranspose, concatenate, Dense, Conv3D, Flatten, MaxPooling3D\n",
        "from keras.models import Sequential\n",
        "import keras.backend as K\n",
        "tf.keras.utils.set_random_seed(0)\n",
        "\n",
        "from sklearn.cluster import AgglomerativeClustering"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to verify that we are running an enviroment with a GPU in Colab. The next cell shows if you have a GPU front-end execution host allocated to the notebook. \n",
        "\n",
        "<font color='red'><b>Warning:</b></font> If you don't have one, you'll need to re-run the previous cells after going to:\n",
        "- Menu Runtime -> Change runtime type -> Hardware accelerator"
      ],
      "metadata": {
        "id": "Wh5PkIn3H9dD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KnH0b5QqG_ny",
        "outputId": "b3565b23-fea7-45fe-c340-b57121918b86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data\n",
        "\n",
        "After setting up the environment, we need the repository files to create the model and access the training/validation data. \n",
        "\n",
        "<font color='orange'><b>Attention:</b></font> This is not trivial in Colab, but to access a private repository on Github like this, you need to provide Colab with your Github Key. You can get that key here: https://github.com/settings/tokens\n",
        "\n",
        "After that, you need to execute a command with this syntax:\n",
        "```\n",
        "!git clone https://username:github_key@github.com/Jverduzc/CNN_PBX_Model.git\n",
        "```\n",
        "You can fill up the blanks in the following cell. We will also change the current working directory. You should see the a new directory in your directory tree (on your left) with the files on the repository.\n"
      ],
      "metadata": {
        "id": "hYseV3r9LkME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone XXX\n",
        "os.chdir(\"CNN_PBX_Model\")"
      ],
      "metadata": {
        "id": "Cr1dF6TJHU2J",
        "outputId": "c04102c7-827d-4fd2-b8d9-944b24a44388",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CNN_PBX_Model'...\n",
            "remote: Enumerating objects: 538, done.\u001b[K\n",
            "remote: Counting objects: 100% (538/538), done.\u001b[K\n",
            "remote: Compressing objects: 100% (352/352), done.\u001b[K\n",
            "remote: Total 538 (delta 245), reused 443 (delta 185), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (538/538), 25.23 MiB | 8.12 MiB/s, done.\n",
            "Resolving deltas: 100% (245/245), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and validation data\n",
        "\n",
        "This notebook was designed to read everything in the ```/train/``` folder as training data and everything in the ```/validation/``` folder as validation data. These directories contain individual labeled subdirectories that represent each of our simulation systems (data points).\n",
        "\n",
        "In each of the simulation systems subdirectories there are two files as numpy arrays: ```input.npy``` and ```output.npy```.\n",
        "\n",
        "\n",
        "```input.npy``` contains a (16 x 34 x 34 x 3) array with the input mappings from our simulations. The first three numbers represent the dimensions (in bins) of our system. The last number represents the number of mappings for our inputs. For each of our 3D structures, we generate the following:\n",
        "- Total density\n",
        "- HE density\n",
        "- GB interface parameter\n",
        "\n",
        "```output.npy``` contains a (16 x 32 x 32 x 1) array with the output mapping (temperature) from our simulations. The first three numbers represent the dimensions (in bins) of our system, but note that they are different from the inputs due to periodic boundary conditions. The last number represents the temperature mapping. \n",
        "- Temperature\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B2wbmJTjOpoe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please verify that after running the next cells you get the following results:\n",
        "\n",
        "<b>Training data:</b><br>\n",
        "\n",
        "(64, 16, 34, 34, 3) <br>\n",
        "(64, 16, 32, 32, 1) <br>\n",
        "\n",
        "<b>Validation data:</b><br>\n",
        "\n",
        "(28, 16, 34, 34, 3) <br>\n",
        "(28, 16, 32, 32, 1) <br>\n",
        "\n",
        "You can see that there is a new number in these arrays. It indicates the number of datapoints in each set. You can read this as having 64 points with (16 x 34 x 34 x 3) shape."
      ],
      "metadata": {
        "id": "ogxA0zxHRUIl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KZxqA1mmG_nz",
        "outputId": "d2bc8179-40b2-4d51-ca38-37d8ca44531c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 16, 34, 34, 3)\n",
            "(64, 16, 32, 32, 1)\n"
          ]
        }
      ],
      "source": [
        "# TRAINING DATA\n",
        "\n",
        "paths = [x[0] for x in os.walk('train/')][1:]\n",
        "\n",
        "train_data = []\n",
        "train_labels = []\n",
        "\n",
        "for i in paths:\n",
        "  train_ex = np.load(i + \"/input.npy\")\n",
        "\n",
        "  if train_ex.shape != (16,34,34,3):\n",
        "\n",
        "    first_axis_pad = int(0.5 * (34 - train_ex.shape[1]))\n",
        "    second_axis_pad = int(0.5 * (34 - train_ex.shape[2]))\n",
        "\n",
        "    train_ex = np.pad(train_ex, ((0, 0), (first_axis_pad, first_axis_pad), (second_axis_pad, second_axis_pad), (0,0)), 'wrap')\n",
        "\n",
        "  train_lb = np.load(i + \"/output.npy\")\n",
        "  train_data.append(train_ex)\n",
        "  train_labels.append(train_lb)\n",
        "\n",
        "train_data = np.array(train_data)\n",
        "train_labels = np.array(train_labels) / 1000\n",
        "\n",
        "print(train_data.shape)\n",
        "print(train_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "02ORxH_vZNOC",
        "outputId": "1e0f93e1-9af6-44c2-ac84-b495595d4501",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 16, 34, 34, 3)\n",
            "(28, 16, 32, 32, 1)\n"
          ]
        }
      ],
      "source": [
        "# VALIDATION DATA\n",
        "\n",
        "validation_paths = [x[0] for x in os.walk('validation/')][1:]\n",
        "\n",
        "validation_data = []\n",
        "validation_labels = []\n",
        "\n",
        "for i in validation_paths:\n",
        "  validation_ex= np.load(i + \"/input.npy\")\n",
        "\n",
        "  if validation_ex.shape != (16,34,34,1):\n",
        "\n",
        "    first_axis_pad = int(0.5 * (34 - validation_ex.shape[1]))\n",
        "    second_axis_pad = int(0.5 * (34 - validation_ex.shape[2]))\n",
        "\n",
        "    validation_ex = np.pad(validation_ex, ((0, 0), (first_axis_pad, first_axis_pad), (second_axis_pad, second_axis_pad), (0,0)), 'wrap')\n",
        "\n",
        "\n",
        "  validation_lb = np.load(i + \"/output.npy\")\n",
        "  validation_data.append(validation_ex)\n",
        "  validation_labels.append(validation_lb)\n",
        "\n",
        "validation_data = np.array(validation_data)\n",
        "validation_labels = np.array(validation_labels) / 1000\n",
        "\n",
        "print(validation_data.shape)\n",
        "print(validation_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model\n",
        "\n",
        "This notebook creates an architecture based on U-Net, a CNN algorithm for image segmentation. We will go a bit into the design of the architecture in the following cells.\n",
        "\n",
        "This first function addresses periodic padding for tensors in the model."
      ],
      "metadata": {
        "id": "xQrUeLx5R1mp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fWvLsqQXsWGy"
      },
      "outputs": [],
      "source": [
        "# Code taken from: https://stackoverflow.com/questions/39088489/tensorflow-periodic-padding\n",
        "\n",
        "def periodic_padding_flexible(tensor, axis, padding=1):\n",
        "\n",
        "    if isinstance(axis,int):\n",
        "        axis = (axis,)\n",
        "    if isinstance(padding,int):\n",
        "        padding = (padding,)\n",
        "\n",
        "    ndim = len(tensor.shape)\n",
        "\n",
        "    for ax,p in zip(axis,padding):\n",
        "        # create a slice object that selects everything from all axes,\n",
        "        # except only 0:p for the specified for right, and -p: for left\n",
        "\n",
        "        ind_right = [slice(-p,None) if i == ax else slice(None) for i in range(ndim)]\n",
        "        ind_left = [slice(0, p) if i == ax else slice(None) for i in range(ndim)]\n",
        "        right = tensor[ind_right]\n",
        "        left = tensor[ind_left]\n",
        "        middle = tensor\n",
        "        tensor = tf.concat([right,middle,left], axis=ax)\n",
        "\n",
        "    return tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since this architecture is going to be complicated, we will start by creating mini-blocks. This first function ```DownConvBlock``` executes the following operations sequentially:\n",
        "\n",
        "- (Optional) Periodic Padding\n",
        "- 3D Convolutional Layer\n",
        "- Periodic Padding\n",
        "- 3D Convolutional Layer\n",
        "- Batch normalization\n",
        "- (Optional) MaxPooling3D Layer"
      ],
      "metadata": {
        "id": "i2sWbazsagHg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rLhZ3NIocWJ9"
      },
      "outputs": [],
      "source": [
        "def DownConvBlock(inputs, n_filters=32, filter_size = 3, max_pooling=True, special_padding=False):\n",
        "\n",
        "  padding_size = int((filter_size-1)/2)\n",
        "  kernel_init =   tf.keras.initializers.GlorotUniform(seed=0)\n",
        "  bias_init = tf.keras.initializers.Zeros()\n",
        "\n",
        "\n",
        "  # PERIODIC PADDING\n",
        "\n",
        "  inputs = periodic_padding_flexible(inputs, axis=1,padding=padding_size)\n",
        "  if special_padding == False:\n",
        "    inputs = periodic_padding_flexible(inputs, axis=2,padding=padding_size)\n",
        "    inputs = periodic_padding_flexible(inputs, axis=3,padding=padding_size)\n",
        "  \n",
        "  conv = Conv3D(n_filters, filter_size, activation='relu', padding='valid', kernel_initializer=kernel_init, bias_initializer=bias_init)(inputs)\n",
        "  print(conv.shape)\n",
        "  conv = periodic_padding_flexible(conv, axis=(1,2,3),padding=(padding_size,padding_size,padding_size))\n",
        "  conv = Conv3D(n_filters, filter_size, activation='relu', padding='valid', kernel_initializer=kernel_init, bias_initializer=bias_init)(conv)\n",
        "  print(conv.shape)\n",
        "  conv = BatchNormalization()(conv, training=False)\n",
        "      \n",
        "  if max_pooling:\n",
        "    next_layer = tf.keras.layers.MaxPooling3D(pool_size = (2,2,2))(conv)\n",
        "  else:\n",
        "    next_layer = conv\n",
        "  \n",
        "  skip_connection = conv   \n",
        "\n",
        "  print(\"end_of_block\") \n",
        "  return next_layer, skip_connection"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This second function ```UpConvBlock``` executes the following operations sequentially:\n",
        "\n",
        "- Transpose 3D Convolutional Layer\n",
        "- Merge with <i>skip connection</i> from the corresponding ```DownConvBlock```\n",
        "- Periodic Padding\n",
        "- 3D Convolutional Layer\n",
        "- Periodic Padding\n",
        "- 3D Convolutional Layer"
      ],
      "metadata": {
        "id": "i8h2MOJHa_Aq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YvMNFlsHseOF"
      },
      "outputs": [],
      "source": [
        "def UpConvBlock(prev_layer_input, skip_layer_input, filter_size = 3, n_filters=32):\n",
        "\n",
        "    padding_size = int((filter_size-1)/2)\n",
        "    kernel_init = tf.keras.initializers.GlorotUniform(seed=0)\n",
        "    bias_init = tf.keras.initializers.Zeros()   \n",
        "\n",
        "    up = Conv3DTranspose(n_filters, (filter_size,filter_size,filter_size),\n",
        "                         strides=(filter_size-1,filter_size-1,filter_size-1),\n",
        "                         padding='same', kernel_initializer=kernel_init, bias_initializer=bias_init)(prev_layer_input)\n",
        "\n",
        "    merge = concatenate([up, skip_layer_input], axis=4)\n",
        "    merge = periodic_padding_flexible(merge, axis=(1,2,3),padding=(padding_size,padding_size,padding_size))\n",
        "    conv = Conv3D(n_filters, filter_size, activation='relu', padding='valid', kernel_initializer=kernel_init,  bias_initializer=bias_init)(merge)\n",
        "    print(conv.shape)\n",
        "    conv = periodic_padding_flexible(conv, axis=(1,2,3),padding=(padding_size,padding_size,padding_size))\n",
        "    conv = Conv3D(n_filters, filter_size, activation='relu',padding='valid', kernel_initializer=kernel_init,  bias_initializer=bias_init)(conv)\n",
        "    print(conv.shape)\n",
        "\n",
        "    print(\"end_of_block\")\n",
        "    return conv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The architecture will be composed of several ```DownConvBlock``` blocks followed by the same number of ```UpConvBlock``` blocks. "
      ],
      "metadata": {
        "id": "evWdWAkXbzfq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fe-fUh99sgKg"
      },
      "outputs": [],
      "source": [
        "\n",
        "def UNet3DModel(input_size=(16, 34, 34, 3), n_filters=32, filter_size=3, n_classes=1):\n",
        "  kernel_init =  tf.keras.initializers.GlorotUniform(seed=0)\n",
        "  bias_init = tf.keras.initializers.Zeros()  \n",
        "  \n",
        "  inputs = Input(input_size)\n",
        "  print(\"Inputs\", inputs.shape)\n",
        "\n",
        "  cblock0 = DownConvBlock(inputs,     n_filters = n_filters    , filter_size = filter_size, max_pooling=False, special_padding=True)\n",
        "  print(\"CB0\", cblock0[0].shape)\n",
        "\n",
        "  cblock1 = DownConvBlock(cblock0[0],     n_filters = n_filters    , filter_size = filter_size, max_pooling=True, special_padding=False)\n",
        "  print(\"CB1\", cblock1[0].shape)\n",
        "\n",
        "  cblock2 = DownConvBlock(cblock1[0], n_filters = n_filters*2  , filter_size = filter_size, max_pooling=True, special_padding=False)\n",
        "  print(\"CB2\", cblock2[0].shape)\n",
        "    \n",
        "  cblock3 = DownConvBlock(cblock2[0], n_filters = n_filters*4  , filter_size = filter_size, max_pooling=True, special_padding=False)\n",
        "  print(\"CB3\", cblock3[0].shape)\n",
        "  \n",
        "  cblock4 = DownConvBlock(cblock3[0], n_filters = n_filters*8  , filter_size = filter_size, max_pooling=False, special_padding=False)\n",
        "  print(\"CB4\", cblock4[0].shape)\n",
        "\n",
        "\n",
        "  print(\"------------------\")\n",
        "\n",
        "  ublock7 = UpConvBlock(cblock4[0]   , cblock3[1],  n_filters = n_filters * 4, filter_size = filter_size)\n",
        "  print(\"UB7\", ublock7.shape)\n",
        "  \n",
        "  ublock8 = UpConvBlock(ublock7   , cblock2[1],  n_filters = n_filters * 2, filter_size = filter_size)\n",
        "  print(\"UB8\", ublock8.shape)\n",
        "  \n",
        "  ublock9 = UpConvBlock(ublock8   , cblock1[1],  n_filters = n_filters, filter_size = filter_size)\n",
        "  print(\"UB9\", ublock9.shape)\n",
        "\n",
        "  ublock9 = periodic_padding_flexible(ublock9, axis=(1,2,3),padding=(1,1,1))\n",
        "  \n",
        "  conv9 = Conv3D(n_filters, 3, activation='relu', padding='valid', kernel_initializer=kernel_init,  bias_initializer=bias_init)(ublock9)\n",
        "  print(\"C9\", conv9.shape)\n",
        "  \n",
        "  conv10 = Conv3D(n_classes, 1, padding='same', kernel_initializer=kernel_init,  bias_initializer=bias_init)(conv9)\n",
        "  print(\"C10\", conv10.shape)\n",
        "\n",
        "  model = tf.keras.Model(inputs=inputs, outputs=conv10)  \n",
        "\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this application, we are concerned with the detection and accurate prediction of hotspots (areas with higher temperatures), which are significantly less common than the rest of the material at a lower temperature. To address this, we are using a custon loss function based on a weighted Mean Squared Error (MSE)."
      ],
      "metadata": {
        "id": "vUDnv4nLeTQH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "d2a5FVUYPHTB"
      },
      "outputs": [],
      "source": [
        "def custom_mse(y_true,y_pred):\n",
        "    w_hot = 5.0\n",
        "    w_cold = 1.0\n",
        "    cutoff = 1.8\n",
        "    weightmat = tf.cast(tf.where(tf.greater(y_true, cutoff), w_hot, w_cold),float)\n",
        "    loss = tf.cast(K.square(y_pred - y_true),float)\n",
        "    loss = loss*weightmat\n",
        "    loss = K.mean(loss)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, this last cell calls the function to generate the model, pair it with an optimizer and compile the model object."
      ],
      "metadata": {
        "id": "-uvZjSSeekHu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "R3SJtgKps6tc",
        "outputId": "00e6f4e3-8bc5-46c2-c41c-3c6282b8d0da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs (None, 16, 34, 34, 3)\n",
            "(None, 16, 32, 32, 32)\n",
            "(None, 16, 32, 32, 32)\n",
            "end_of_block\n",
            "CB0 (None, 16, 32, 32, 32)\n",
            "(None, 16, 32, 32, 32)\n",
            "(None, 16, 32, 32, 32)\n",
            "end_of_block\n",
            "CB1 (None, 8, 16, 16, 32)\n",
            "(None, 8, 16, 16, 64)\n",
            "(None, 8, 16, 16, 64)\n",
            "end_of_block\n",
            "CB2 (None, 4, 8, 8, 64)\n",
            "(None, 4, 8, 8, 128)\n",
            "(None, 4, 8, 8, 128)\n",
            "end_of_block\n",
            "CB3 (None, 2, 4, 4, 128)\n",
            "(None, 2, 4, 4, 256)\n",
            "(None, 2, 4, 4, 256)\n",
            "end_of_block\n",
            "CB4 (None, 2, 4, 4, 256)\n",
            "------------------\n",
            "(None, 4, 8, 8, 128)\n",
            "(None, 4, 8, 8, 128)\n",
            "end_of_block\n",
            "UB7 (None, 4, 8, 8, 128)\n",
            "(None, 8, 16, 16, 64)\n",
            "(None, 8, 16, 16, 64)\n",
            "end_of_block\n",
            "UB8 (None, 8, 16, 16, 64)\n",
            "(None, 16, 32, 32, 32)\n",
            "(None, 16, 32, 32, 32)\n",
            "end_of_block\n",
            "UB9 (None, 16, 32, 32, 32)\n",
            "C9 (None, 16, 32, 32, 32)\n",
            "C10 (None, 16, 32, 32, 1)\n"
          ]
        }
      ],
      "source": [
        "model = UNet3DModel(input_size=(16, 34, 34, 3), n_filters=32, filter_size = 3, n_classes=1)\n",
        "optimizer = tf.optimizers.Adam(learning_rate = 0.0005)\n",
        "model.compile(loss=custom_mse, optimizer=optimizer, metrics=['mse'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the model\n",
        "\n",
        "This cell implements two techniques to prevent overfitting. The first one is a learning rate scheduler that decreases the learning rate after a fixed number of epochs. The second one is an early stopping criteria that monitors the validation loss to ensure the model continues to learn."
      ],
      "metadata": {
        "id": "BLFb04QIevl2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "baIEkfpntuOW",
        "outputId": "71d45807-4b42-4c52-db03-af260e595339",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "2/2 [==============================] - 18s 3s/step - loss: 1.4006 - mse: 0.9397 - val_loss: 1.0529 - val_mse: 0.7182 - lr: 5.0000e-04\n",
            "Epoch 2/1000\n",
            "2/2 [==============================] - 2s 993ms/step - loss: 0.9520 - mse: 0.5761 - val_loss: 0.5838 - val_mse: 0.5412 - lr: 5.0000e-04\n",
            "Epoch 3/1000\n",
            "2/2 [==============================] - 1s 855ms/step - loss: 0.4995 - mse: 0.3448 - val_loss: 0.4037 - val_mse: 0.1945 - lr: 5.0000e-04\n",
            "Epoch 4/1000\n",
            "2/2 [==============================] - 1s 852ms/step - loss: 0.4822 - mse: 0.2113 - val_loss: 0.2863 - val_mse: 0.1149 - lr: 5.0000e-04\n",
            "Epoch 5/1000\n",
            "2/2 [==============================] - 1s 812ms/step - loss: 0.3490 - mse: 0.1434 - val_loss: 0.3118 - val_mse: 0.2285 - lr: 5.0000e-04\n",
            "Epoch 6/1000\n",
            "2/2 [==============================] - 1s 839ms/step - loss: 0.3872 - mse: 0.2666 - val_loss: 0.2447 - val_mse: 0.1462 - lr: 5.0000e-04\n",
            "Epoch 7/1000\n",
            "2/2 [==============================] - 2s 993ms/step - loss: 0.2974 - mse: 0.1430 - val_loss: 0.2290 - val_mse: 0.0880 - lr: 5.0000e-04\n",
            "Epoch 8/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.2801 - mse: 0.1048 - val_loss: 0.1876 - val_mse: 0.0851 - lr: 5.0000e-04\n",
            "Epoch 9/1000\n",
            "2/2 [==============================] - 1s 857ms/step - loss: 0.2540 - mse: 0.1524 - val_loss: 0.1761 - val_mse: 0.0825 - lr: 5.0000e-04\n",
            "Epoch 10/1000\n",
            "2/2 [==============================] - 1s 820ms/step - loss: 0.2092 - mse: 0.0893 - val_loss: 0.1969 - val_mse: 0.0761 - lr: 5.0000e-04\n",
            "Epoch 11/1000\n",
            "2/2 [==============================] - 1s 853ms/step - loss: 0.1824 - mse: 0.0725 - val_loss: 0.1622 - val_mse: 0.1032 - lr: 5.0000e-04\n",
            "Epoch 12/1000\n",
            "2/2 [==============================] - 1s 861ms/step - loss: 0.1557 - mse: 0.1143 - val_loss: 0.1499 - val_mse: 0.0656 - lr: 5.0000e-04\n",
            "Epoch 13/1000\n",
            "2/2 [==============================] - 1s 829ms/step - loss: 0.1251 - mse: 0.0610 - val_loss: 0.1609 - val_mse: 0.0755 - lr: 5.0000e-04\n",
            "Epoch 14/1000\n",
            "2/2 [==============================] - 1s 830ms/step - loss: 0.1144 - mse: 0.0769 - val_loss: 0.1520 - val_mse: 0.0851 - lr: 5.0000e-04\n",
            "Epoch 15/1000\n",
            "2/2 [==============================] - 2s 871ms/step - loss: 0.1108 - mse: 0.0769 - val_loss: 0.1841 - val_mse: 0.0945 - lr: 5.0000e-04\n",
            "Epoch 16/1000\n",
            "2/2 [==============================] - 2s 972ms/step - loss: 0.1087 - mse: 0.0673 - val_loss: 0.1539 - val_mse: 0.0872 - lr: 5.0000e-04\n",
            "Epoch 17/1000\n",
            "2/2 [==============================] - 1s 828ms/step - loss: 0.1045 - mse: 0.0786 - val_loss: 0.1540 - val_mse: 0.0795 - lr: 5.0000e-04\n",
            "Epoch 18/1000\n",
            "2/2 [==============================] - 2s 886ms/step - loss: 0.0946 - mse: 0.0595 - val_loss: 0.1492 - val_mse: 0.0733 - lr: 5.0000e-04\n",
            "Epoch 19/1000\n",
            "2/2 [==============================] - 2s 896ms/step - loss: 0.0903 - mse: 0.0573 - val_loss: 0.1360 - val_mse: 0.0744 - lr: 5.0000e-04\n",
            "Epoch 20/1000\n",
            "2/2 [==============================] - 2s 944ms/step - loss: 0.0891 - mse: 0.0611 - val_loss: 0.1385 - val_mse: 0.0662 - lr: 5.0000e-04\n",
            "Epoch 21/1000\n",
            "2/2 [==============================] - 2s 932ms/step - loss: 0.0878 - mse: 0.0495 - val_loss: 0.1350 - val_mse: 0.0666 - lr: 5.0000e-04\n",
            "Epoch 22/1000\n",
            "2/2 [==============================] - 2s 892ms/step - loss: 0.0851 - mse: 0.0548 - val_loss: 0.1338 - val_mse: 0.0723 - lr: 5.0000e-04\n",
            "Epoch 23/1000\n",
            "2/2 [==============================] - 2s 859ms/step - loss: 0.0818 - mse: 0.0531 - val_loss: 0.1419 - val_mse: 0.0710 - lr: 5.0000e-04\n",
            "Epoch 24/1000\n",
            "2/2 [==============================] - 2s 877ms/step - loss: 0.0799 - mse: 0.0494 - val_loss: 0.1392 - val_mse: 0.0774 - lr: 5.0000e-04\n",
            "Epoch 25/1000\n",
            "2/2 [==============================] - 1s 833ms/step - loss: 0.0788 - mse: 0.0561 - val_loss: 0.1427 - val_mse: 0.0756 - lr: 5.0000e-04\n",
            "Epoch 26/1000\n",
            "2/2 [==============================] - 1s 835ms/step - loss: 0.0773 - mse: 0.0503 - val_loss: 0.1400 - val_mse: 0.0743 - lr: 5.0000e-04\n",
            "Epoch 27/1000\n",
            "2/2 [==============================] - 2s 978ms/step - loss: 0.0764 - mse: 0.0534 - val_loss: 0.1349 - val_mse: 0.0719 - lr: 5.0000e-04\n",
            "Epoch 28/1000\n",
            "2/2 [==============================] - 1s 849ms/step - loss: 0.0732 - mse: 0.0476 - val_loss: 0.1349 - val_mse: 0.0671 - lr: 5.0000e-04\n",
            "Epoch 29/1000\n",
            "2/2 [==============================] - 2s 867ms/step - loss: 0.0729 - mse: 0.0465 - val_loss: 0.1286 - val_mse: 0.0690 - lr: 5.0000e-04\n",
            "Epoch 30/1000\n",
            "2/2 [==============================] - 1s 841ms/step - loss: 0.0719 - mse: 0.0478 - val_loss: 0.1311 - val_mse: 0.0652 - lr: 5.0000e-04\n",
            "Epoch 31/1000\n",
            "2/2 [==============================] - 2s 983ms/step - loss: 0.0702 - mse: 0.0438 - val_loss: 0.1295 - val_mse: 0.0683 - lr: 5.0000e-04\n",
            "Epoch 32/1000\n",
            "2/2 [==============================] - 1s 842ms/step - loss: 0.0691 - mse: 0.0464 - val_loss: 0.1322 - val_mse: 0.0682 - lr: 5.0000e-04\n",
            "Epoch 33/1000\n",
            "2/2 [==============================] - 2s 977ms/step - loss: 0.0683 - mse: 0.0443 - val_loss: 0.1316 - val_mse: 0.0691 - lr: 5.0000e-04\n",
            "Epoch 34/1000\n",
            "2/2 [==============================] - 2s 854ms/step - loss: 0.0673 - mse: 0.0452 - val_loss: 0.1299 - val_mse: 0.0678 - lr: 5.0000e-04\n",
            "Epoch 35/1000\n",
            "2/2 [==============================] - 2s 847ms/step - loss: 0.0662 - mse: 0.0439 - val_loss: 0.1288 - val_mse: 0.0651 - lr: 5.0000e-04\n",
            "Epoch 36/1000\n",
            "2/2 [==============================] - 2s 882ms/step - loss: 0.0656 - mse: 0.0420 - val_loss: 0.1264 - val_mse: 0.0658 - lr: 5.0000e-04\n",
            "Epoch 37/1000\n",
            "2/2 [==============================] - 2s 849ms/step - loss: 0.0653 - mse: 0.0427 - val_loss: 0.1270 - val_mse: 0.0652 - lr: 5.0000e-04\n",
            "Epoch 38/1000\n",
            "2/2 [==============================] - 1s 845ms/step - loss: 0.0641 - mse: 0.0427 - val_loss: 0.1291 - val_mse: 0.0655 - lr: 5.0000e-04\n",
            "Epoch 39/1000\n",
            "2/2 [==============================] - 2s 848ms/step - loss: 0.0634 - mse: 0.0407 - val_loss: 0.1268 - val_mse: 0.0676 - lr: 5.0000e-04\n",
            "Epoch 40/1000\n",
            "2/2 [==============================] - 2s 856ms/step - loss: 0.0626 - mse: 0.0425 - val_loss: 0.1310 - val_mse: 0.0647 - lr: 5.0000e-04\n",
            "Epoch 41/1000\n",
            "2/2 [==============================] - 2s 890ms/step - loss: 0.0622 - mse: 0.0398 - val_loss: 0.1249 - val_mse: 0.0654 - lr: 5.0000e-04\n",
            "Epoch 42/1000\n",
            "2/2 [==============================] - 2s 997ms/step - loss: 0.0606 - mse: 0.0403 - val_loss: 0.1286 - val_mse: 0.0647 - lr: 5.0000e-04\n",
            "Epoch 43/1000\n",
            "2/2 [==============================] - 2s 859ms/step - loss: 0.0615 - mse: 0.0416 - val_loss: 0.1280 - val_mse: 0.0642 - lr: 5.0000e-04\n",
            "Epoch 44/1000\n",
            "2/2 [==============================] - 2s 892ms/step - loss: 0.0594 - mse: 0.0376 - val_loss: 0.1232 - val_mse: 0.0651 - lr: 5.0000e-04\n",
            "Epoch 45/1000\n",
            "2/2 [==============================] - 2s 860ms/step - loss: 0.0591 - mse: 0.0396 - val_loss: 0.1246 - val_mse: 0.0636 - lr: 5.0000e-04\n",
            "Epoch 46/1000\n",
            "2/2 [==============================] - 2s 858ms/step - loss: 0.0592 - mse: 0.0408 - val_loss: 0.1325 - val_mse: 0.0642 - lr: 5.0000e-04\n",
            "Epoch 47/1000\n",
            "2/2 [==============================] - 2s 862ms/step - loss: 0.0602 - mse: 0.0368 - val_loss: 0.1237 - val_mse: 0.0685 - lr: 5.0000e-04\n",
            "Epoch 48/1000\n",
            "2/2 [==============================] - 2s 985ms/step - loss: 0.0596 - mse: 0.0416 - val_loss: 0.1317 - val_mse: 0.0645 - lr: 5.0000e-04\n",
            "Epoch 49/1000\n",
            "2/2 [==============================] - 2s 903ms/step - loss: 0.0581 - mse: 0.0382 - val_loss: 0.1195 - val_mse: 0.0626 - lr: 5.0000e-04\n",
            "Epoch 50/1000\n",
            "2/2 [==============================] - 2s 869ms/step - loss: 0.0561 - mse: 0.0367 - val_loss: 0.1260 - val_mse: 0.0611 - lr: 5.0000e-04\n",
            "Epoch 51/1000\n",
            "2/2 [==============================] - 2s 861ms/step - loss: 0.0570 - mse: 0.0382 - val_loss: 0.1235 - val_mse: 0.0628 - lr: 5.0000e-04\n",
            "Epoch 52/1000\n",
            "2/2 [==============================] - 2s 865ms/step - loss: 0.0558 - mse: 0.0362 - val_loss: 0.1230 - val_mse: 0.0635 - lr: 5.0000e-04\n",
            "Epoch 53/1000\n",
            "2/2 [==============================] - 2s 862ms/step - loss: 0.0533 - mse: 0.0372 - val_loss: 0.1233 - val_mse: 0.0618 - lr: 5.0000e-04\n",
            "Epoch 54/1000\n",
            "2/2 [==============================] - 2s 862ms/step - loss: 0.0524 - mse: 0.0347 - val_loss: 0.1228 - val_mse: 0.0606 - lr: 5.0000e-04\n",
            "Epoch 55/1000\n",
            "2/2 [==============================] - 2s 860ms/step - loss: 0.0516 - mse: 0.0339 - val_loss: 0.1214 - val_mse: 0.0619 - lr: 5.0000e-04\n",
            "Epoch 56/1000\n",
            "2/2 [==============================] - 2s 861ms/step - loss: 0.0507 - mse: 0.0342 - val_loss: 0.1247 - val_mse: 0.0624 - lr: 5.0000e-04\n",
            "Epoch 57/1000\n",
            "2/2 [==============================] - 2s 864ms/step - loss: 0.0510 - mse: 0.0350 - val_loss: 0.1251 - val_mse: 0.0616 - lr: 5.0000e-04\n",
            "Epoch 58/1000\n",
            "2/2 [==============================] - 2s 999ms/step - loss: 0.0509 - mse: 0.0340 - val_loss: 0.1217 - val_mse: 0.0615 - lr: 5.0000e-04\n",
            "Epoch 59/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0491 - mse: 0.0329 - val_loss: 0.1209 - val_mse: 0.0619 - lr: 5.0000e-04\n",
            "Epoch 60/1000\n",
            "2/2 [==============================] - 2s 867ms/step - loss: 0.0486 - mse: 0.0338 - val_loss: 0.1263 - val_mse: 0.0612 - lr: 5.0000e-04\n",
            "Epoch 61/1000\n",
            "2/2 [==============================] - 2s 860ms/step - loss: 0.0503 - mse: 0.0336 - val_loss: 0.1214 - val_mse: 0.0610 - lr: 5.0000e-04\n",
            "Epoch 62/1000\n",
            "2/2 [==============================] - 2s 866ms/step - loss: 0.0479 - mse: 0.0315 - val_loss: 0.1194 - val_mse: 0.0618 - lr: 5.0000e-04\n",
            "Epoch 63/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0498 - mse: 0.0341 - val_loss: 0.1188 - val_mse: 0.0605 - lr: 5.0000e-04\n",
            "Epoch 64/1000\n",
            "2/2 [==============================] - 2s 882ms/step - loss: 0.0484 - mse: 0.0349 - val_loss: 0.1314 - val_mse: 0.0632 - lr: 5.0000e-04\n",
            "Epoch 65/1000\n",
            "2/2 [==============================] - 2s 866ms/step - loss: 0.0502 - mse: 0.0332 - val_loss: 0.1189 - val_mse: 0.0602 - lr: 5.0000e-04\n",
            "Epoch 66/1000\n",
            "2/2 [==============================] - 2s 862ms/step - loss: 0.0456 - mse: 0.0308 - val_loss: 0.1214 - val_mse: 0.0596 - lr: 5.0000e-04\n",
            "Epoch 67/1000\n",
            "2/2 [==============================] - 2s 899ms/step - loss: 0.0469 - mse: 0.0333 - val_loss: 0.1269 - val_mse: 0.0613 - lr: 5.0000e-04\n",
            "Epoch 68/1000\n",
            "2/2 [==============================] - 2s 865ms/step - loss: 0.0457 - mse: 0.0298 - val_loss: 0.1192 - val_mse: 0.0629 - lr: 5.0000e-04\n",
            "Epoch 69/1000\n",
            "2/2 [==============================] - 2s 868ms/step - loss: 0.0466 - mse: 0.0324 - val_loss: 0.1220 - val_mse: 0.0596 - lr: 5.0000e-04\n",
            "Epoch 70/1000\n",
            "2/2 [==============================] - 2s 869ms/step - loss: 0.0443 - mse: 0.0311 - val_loss: 0.1212 - val_mse: 0.0596 - lr: 5.0000e-04\n",
            "Epoch 71/1000\n",
            "2/2 [==============================] - 2s 870ms/step - loss: 0.0423 - mse: 0.0290 - val_loss: 0.1227 - val_mse: 0.0602 - lr: 5.0000e-04\n",
            "Epoch 72/1000\n",
            "2/2 [==============================] - 2s 875ms/step - loss: 0.0423 - mse: 0.0297 - val_loss: 0.1235 - val_mse: 0.0604 - lr: 5.0000e-04\n",
            "Epoch 73/1000\n",
            "2/2 [==============================] - 2s 877ms/step - loss: 0.0413 - mse: 0.0279 - val_loss: 0.1196 - val_mse: 0.0631 - lr: 5.0000e-04\n",
            "Epoch 74/1000\n",
            "2/2 [==============================] - 2s 901ms/step - loss: 0.0479 - mse: 0.0331 - val_loss: 0.1177 - val_mse: 0.0598 - lr: 5.0000e-04\n",
            "Epoch 75/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0421 - mse: 0.0312 - val_loss: 0.1285 - val_mse: 0.0612 - lr: 5.0000e-04\n",
            "Epoch 76/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0433 - mse: 0.0291 - val_loss: 0.1184 - val_mse: 0.0595 - lr: 5.0000e-04\n",
            "Epoch 77/1000\n",
            "2/2 [==============================] - 2s 889ms/step - loss: 0.0422 - mse: 0.0287 - val_loss: 0.1193 - val_mse: 0.0595 - lr: 5.0000e-04\n",
            "Epoch 78/1000\n",
            "2/2 [==============================] - 2s 880ms/step - loss: 0.0401 - mse: 0.0298 - val_loss: 0.1288 - val_mse: 0.0618 - lr: 5.0000e-04\n",
            "Epoch 79/1000\n",
            "2/2 [==============================] - 2s 875ms/step - loss: 0.0401 - mse: 0.0269 - val_loss: 0.1199 - val_mse: 0.0650 - lr: 5.0000e-04\n",
            "Epoch 80/1000\n",
            "2/2 [==============================] - 2s 879ms/step - loss: 0.0475 - mse: 0.0332 - val_loss: 0.1249 - val_mse: 0.0587 - lr: 5.0000e-04\n",
            "Epoch 81/1000\n",
            "2/2 [==============================] - 2s 882ms/step - loss: 0.0494 - mse: 0.0361 - val_loss: 0.1202 - val_mse: 0.0575 - lr: 5.0000e-04\n",
            "Epoch 82/1000\n",
            "2/2 [==============================] - 2s 894ms/step - loss: 0.0408 - mse: 0.0267 - val_loss: 0.1207 - val_mse: 0.0600 - lr: 5.0000e-04\n",
            "Epoch 83/1000\n",
            "2/2 [==============================] - 2s 881ms/step - loss: 0.0386 - mse: 0.0286 - val_loss: 0.1252 - val_mse: 0.0612 - lr: 5.0000e-04\n",
            "Epoch 84/1000\n",
            "2/2 [==============================] - 2s 920ms/step - loss: 0.0374 - mse: 0.0256 - val_loss: 0.1170 - val_mse: 0.0597 - lr: 5.0000e-04\n",
            "Epoch 85/1000\n",
            "2/2 [==============================] - 2s 900ms/step - loss: 0.0369 - mse: 0.0273 - val_loss: 0.1248 - val_mse: 0.0603 - lr: 5.0000e-04\n",
            "Epoch 86/1000\n",
            "2/2 [==============================] - 2s 886ms/step - loss: 0.0356 - mse: 0.0252 - val_loss: 0.1198 - val_mse: 0.0606 - lr: 5.0000e-04\n",
            "Epoch 87/1000\n",
            "2/2 [==============================] - 2s 887ms/step - loss: 0.0348 - mse: 0.0251 - val_loss: 0.1235 - val_mse: 0.0601 - lr: 5.0000e-04\n",
            "Epoch 88/1000\n",
            "2/2 [==============================] - 2s 887ms/step - loss: 0.0340 - mse: 0.0249 - val_loss: 0.1238 - val_mse: 0.0607 - lr: 5.0000e-04\n",
            "Epoch 89/1000\n",
            "2/2 [==============================] - 2s 892ms/step - loss: 0.0331 - mse: 0.0235 - val_loss: 0.1203 - val_mse: 0.0617 - lr: 5.0000e-04\n",
            "Epoch 90/1000\n",
            "2/2 [==============================] - 2s 886ms/step - loss: 0.0326 - mse: 0.0242 - val_loss: 0.1268 - val_mse: 0.0609 - lr: 5.0000e-04\n",
            "Epoch 91/1000\n",
            "2/2 [==============================] - 2s 893ms/step - loss: 0.0337 - mse: 0.0248 - val_loss: 0.1274 - val_mse: 0.0615 - lr: 5.0000e-04\n",
            "Epoch 92/1000\n",
            "2/2 [==============================] - 2s 896ms/step - loss: 0.0321 - mse: 0.0220 - val_loss: 0.1185 - val_mse: 0.0633 - lr: 5.0000e-04\n",
            "Epoch 93/1000\n",
            "2/2 [==============================] - 2s 892ms/step - loss: 0.0358 - mse: 0.0260 - val_loss: 0.1239 - val_mse: 0.0598 - lr: 5.0000e-04\n",
            "Epoch 94/1000\n",
            "2/2 [==============================] - 2s 896ms/step - loss: 0.0319 - mse: 0.0237 - val_loss: 0.1281 - val_mse: 0.0623 - lr: 5.0000e-04\n",
            "Epoch 95/1000\n",
            "2/2 [==============================] - 2s 899ms/step - loss: 0.0303 - mse: 0.0210 - val_loss: 0.1180 - val_mse: 0.0619 - lr: 5.0000e-04\n",
            "Epoch 96/1000\n",
            "2/2 [==============================] - 2s 895ms/step - loss: 0.0304 - mse: 0.0227 - val_loss: 0.1332 - val_mse: 0.0636 - lr: 5.0000e-04\n",
            "Epoch 97/1000\n",
            "2/2 [==============================] - 2s 899ms/step - loss: 0.0325 - mse: 0.0231 - val_loss: 0.1229 - val_mse: 0.0618 - lr: 5.0000e-04\n",
            "Epoch 98/1000\n",
            "2/2 [==============================] - 2s 903ms/step - loss: 0.0281 - mse: 0.0200 - val_loss: 0.1228 - val_mse: 0.0605 - lr: 5.0000e-04\n",
            "Epoch 99/1000\n",
            "2/2 [==============================] - 2s 901ms/step - loss: 0.0266 - mse: 0.0199 - val_loss: 0.1242 - val_mse: 0.0607 - lr: 5.0000e-04\n",
            "Epoch 100/1000\n",
            "2/2 [==============================] - 2s 907ms/step - loss: 0.0256 - mse: 0.0187 - val_loss: 0.1243 - val_mse: 0.0616 - lr: 5.0000e-04\n",
            "Epoch 101/1000\n",
            "2/2 [==============================] - 2s 897ms/step - loss: 0.0247 - mse: 0.0184 - val_loss: 0.1259 - val_mse: 0.0625 - lr: 5.0000e-04\n",
            "Epoch 102/1000\n",
            "2/2 [==============================] - 2s 903ms/step - loss: 0.0243 - mse: 0.0182 - val_loss: 0.1280 - val_mse: 0.0630 - lr: 5.0000e-04\n",
            "Epoch 103/1000\n",
            "2/2 [==============================] - 2s 902ms/step - loss: 0.0254 - mse: 0.0193 - val_loss: 0.1352 - val_mse: 0.0664 - lr: 5.0000e-04\n",
            "Epoch 104/1000\n",
            "2/2 [==============================] - 2s 903ms/step - loss: 0.0284 - mse: 0.0209 - val_loss: 0.1221 - val_mse: 0.0592 - lr: 5.0000e-04\n",
            "Epoch 105/1000\n",
            "2/2 [==============================] - 2s 900ms/step - loss: 0.0246 - mse: 0.0173 - val_loss: 0.1206 - val_mse: 0.0620 - lr: 5.0000e-04\n",
            "Epoch 106/1000\n",
            "2/2 [==============================] - 2s 902ms/step - loss: 0.0246 - mse: 0.0188 - val_loss: 0.1258 - val_mse: 0.0618 - lr: 5.0000e-04\n",
            "Epoch 107/1000\n",
            "2/2 [==============================] - 2s 904ms/step - loss: 0.0231 - mse: 0.0173 - val_loss: 0.1255 - val_mse: 0.0609 - lr: 5.0000e-04\n",
            "Epoch 108/1000\n",
            "2/2 [==============================] - 2s 900ms/step - loss: 0.0222 - mse: 0.0161 - val_loss: 0.1230 - val_mse: 0.0623 - lr: 5.0000e-04\n",
            "Epoch 109/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0217 - mse: 0.0163 - val_loss: 0.1227 - val_mse: 0.0616 - lr: 5.0000e-04\n",
            "Epoch 110/1000\n",
            "2/2 [==============================] - 2s 915ms/step - loss: 0.0206 - mse: 0.0157 - val_loss: 0.1259 - val_mse: 0.0618 - lr: 5.0000e-04\n",
            "Epoch 111/1000\n",
            "2/2 [==============================] - 2s 900ms/step - loss: 0.0201 - mse: 0.0151 - val_loss: 0.1266 - val_mse: 0.0630 - lr: 5.0000e-04\n",
            "Epoch 112/1000\n",
            "2/2 [==============================] - 2s 896ms/step - loss: 0.0195 - mse: 0.0148 - val_loss: 0.1243 - val_mse: 0.0616 - lr: 5.0000e-04\n",
            "Epoch 113/1000\n",
            "2/2 [==============================] - 2s 901ms/step - loss: 0.0192 - mse: 0.0145 - val_loss: 0.1218 - val_mse: 0.0619 - lr: 5.0000e-04\n",
            "Epoch 114/1000\n",
            "2/2 [==============================] - 2s 908ms/step - loss: 0.0202 - mse: 0.0151 - val_loss: 0.1198 - val_mse: 0.0615 - lr: 5.0000e-04\n",
            "Epoch 115/1000\n",
            "2/2 [==============================] - 2s 903ms/step - loss: 0.0199 - mse: 0.0152 - val_loss: 0.1233 - val_mse: 0.0609 - lr: 5.0000e-04\n",
            "Epoch 116/1000\n",
            "2/2 [==============================] - 2s 901ms/step - loss: 0.0183 - mse: 0.0144 - val_loss: 0.1345 - val_mse: 0.0656 - lr: 5.0000e-04\n",
            "Epoch 117/1000\n",
            "2/2 [==============================] - 2s 902ms/step - loss: 0.0227 - mse: 0.0173 - val_loss: 0.1356 - val_mse: 0.0646 - lr: 5.0000e-04\n",
            "Epoch 118/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0214 - mse: 0.0152 - val_loss: 0.1179 - val_mse: 0.0621 - lr: 5.0000e-04\n",
            "Epoch 119/1000\n",
            "2/2 [==============================] - 2s 907ms/step - loss: 0.0267 - mse: 0.0198 - val_loss: 0.1227 - val_mse: 0.0612 - lr: 5.0000e-04\n",
            "Epoch 120/1000\n",
            "2/2 [==============================] - 2s 898ms/step - loss: 0.0194 - mse: 0.0152 - val_loss: 0.1326 - val_mse: 0.0632 - lr: 5.0000e-04\n",
            "Epoch 121/1000\n",
            "2/2 [==============================] - 2s 903ms/step - loss: 0.0194 - mse: 0.0138 - val_loss: 0.1194 - val_mse: 0.0617 - lr: 5.0000e-04\n",
            "Epoch 122/1000\n",
            "2/2 [==============================] - 2s 905ms/step - loss: 0.0207 - mse: 0.0158 - val_loss: 0.1249 - val_mse: 0.0606 - lr: 5.0000e-04\n",
            "Epoch 123/1000\n",
            "2/2 [==============================] - 2s 907ms/step - loss: 0.0193 - mse: 0.0153 - val_loss: 0.1364 - val_mse: 0.0665 - lr: 5.0000e-04\n",
            "Epoch 124/1000\n",
            "2/2 [==============================] - 2s 903ms/step - loss: 0.0208 - mse: 0.0155 - val_loss: 0.1181 - val_mse: 0.0633 - lr: 5.0000e-04\n",
            "Epoch 125/1000\n",
            "2/2 [==============================] - 2s 907ms/step - loss: 0.0254 - mse: 0.0187 - val_loss: 0.1257 - val_mse: 0.0609 - lr: 5.0000e-04\n",
            "Epoch 126/1000\n",
            "2/2 [==============================] - 2s 904ms/step - loss: 0.0212 - mse: 0.0165 - val_loss: 0.1320 - val_mse: 0.0635 - lr: 5.0000e-04\n",
            "Epoch 127/1000\n",
            "2/2 [==============================] - 2s 900ms/step - loss: 0.0195 - mse: 0.0137 - val_loss: 0.1192 - val_mse: 0.0628 - lr: 5.0000e-04\n",
            "Epoch 128/1000\n",
            "2/2 [==============================] - 2s 902ms/step - loss: 0.0203 - mse: 0.0161 - val_loss: 0.1296 - val_mse: 0.0627 - lr: 5.0000e-04\n",
            "Epoch 129/1000\n",
            "2/2 [==============================] - 2s 900ms/step - loss: 0.0189 - mse: 0.0146 - val_loss: 0.1212 - val_mse: 0.0598 - lr: 5.0000e-04\n",
            "Epoch 130/1000\n",
            "2/2 [==============================] - 2s 896ms/step - loss: 0.0175 - mse: 0.0130 - val_loss: 0.1212 - val_mse: 0.0614 - lr: 5.0000e-04\n",
            "Epoch 131/1000\n",
            "2/2 [==============================] - 2s 896ms/step - loss: 0.0165 - mse: 0.0130 - val_loss: 0.1299 - val_mse: 0.0622 - lr: 5.0000e-04\n",
            "Epoch 132/1000\n",
            "2/2 [==============================] - 2s 896ms/step - loss: 0.0169 - mse: 0.0126 - val_loss: 0.1192 - val_mse: 0.0608 - lr: 5.0000e-04\n",
            "Epoch 133/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0174 - mse: 0.0137 - val_loss: 0.1270 - val_mse: 0.0625 - lr: 5.0000e-04\n",
            "Epoch 134/1000\n",
            "2/2 [==============================] - 2s 906ms/step - loss: 0.0159 - mse: 0.0127 - val_loss: 0.1275 - val_mse: 0.0616 - lr: 5.0000e-04\n",
            "Epoch 135/1000\n",
            "2/2 [==============================] - 2s 898ms/step - loss: 0.0155 - mse: 0.0118 - val_loss: 0.1196 - val_mse: 0.0601 - lr: 5.0000e-04\n",
            "Epoch 136/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0151 - mse: 0.0118 - val_loss: 0.1268 - val_mse: 0.0613 - lr: 5.0000e-04\n",
            "Epoch 137/1000\n",
            "2/2 [==============================] - 2s 906ms/step - loss: 0.0148 - mse: 0.0116 - val_loss: 0.1235 - val_mse: 0.0611 - lr: 5.0000e-04\n",
            "Epoch 138/1000\n",
            "2/2 [==============================] - 2s 897ms/step - loss: 0.0143 - mse: 0.0111 - val_loss: 0.1221 - val_mse: 0.0600 - lr: 5.0000e-04\n",
            "Epoch 139/1000\n",
            "2/2 [==============================] - 2s 903ms/step - loss: 0.0138 - mse: 0.0111 - val_loss: 0.1294 - val_mse: 0.0631 - lr: 5.0000e-04\n",
            "Epoch 140/1000\n",
            "2/2 [==============================] - 2s 906ms/step - loss: 0.0139 - mse: 0.0110 - val_loss: 0.1218 - val_mse: 0.0600 - lr: 5.0000e-04\n",
            "Epoch 141/1000\n",
            "2/2 [==============================] - 2s 893ms/step - loss: 0.0135 - mse: 0.0107 - val_loss: 0.1247 - val_mse: 0.0616 - lr: 5.0000e-04\n",
            "Epoch 142/1000\n",
            "2/2 [==============================] - 2s 895ms/step - loss: 0.0129 - mse: 0.0105 - val_loss: 0.1267 - val_mse: 0.0611 - lr: 5.0000e-04\n",
            "Epoch 143/1000\n",
            "2/2 [==============================] - 2s 895ms/step - loss: 0.0128 - mse: 0.0100 - val_loss: 0.1235 - val_mse: 0.0615 - lr: 5.0000e-04\n",
            "Epoch 144/1000\n",
            "2/2 [==============================] - 2s 895ms/step - loss: 0.0128 - mse: 0.0103 - val_loss: 0.1232 - val_mse: 0.0605 - lr: 5.0000e-04\n",
            "Epoch 145/1000\n",
            "2/2 [==============================] - 2s 895ms/step - loss: 0.0123 - mse: 0.0100 - val_loss: 0.1285 - val_mse: 0.0625 - lr: 5.0000e-04\n",
            "Epoch 146/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0124 - mse: 0.0100 - val_loss: 0.1232 - val_mse: 0.0602 - lr: 5.0000e-04\n",
            "Epoch 147/1000\n",
            "2/2 [==============================] - 2s 910ms/step - loss: 0.0120 - mse: 0.0097 - val_loss: 0.1237 - val_mse: 0.0615 - lr: 5.0000e-04\n",
            "Epoch 148/1000\n",
            "2/2 [==============================] - 2s 896ms/step - loss: 0.0118 - mse: 0.0096 - val_loss: 0.1251 - val_mse: 0.0607 - lr: 5.0000e-04\n",
            "Epoch 149/1000\n",
            "2/2 [==============================] - 2s 917ms/step - loss: 0.0117 - mse: 0.0095 - val_loss: 0.1283 - val_mse: 0.0625 - lr: 5.0000e-04\n",
            "Epoch 150/1000\n",
            "2/2 [==============================] - 2s 897ms/step - loss: 0.0115 - mse: 0.0093 - val_loss: 0.1231 - val_mse: 0.0607 - lr: 5.0000e-04\n",
            "Epoch 151/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0115 - mse: 0.0093 - val_loss: 0.1238 - val_mse: 0.0610 - lr: 5.0000e-04\n",
            "Epoch 152/1000\n",
            "2/2 [==============================] - 2s 910ms/step - loss: 0.0111 - mse: 0.0091 - val_loss: 0.1279 - val_mse: 0.0620 - lr: 5.0000e-04\n",
            "Epoch 153/1000\n",
            "2/2 [==============================] - 2s 901ms/step - loss: 0.0112 - mse: 0.0091 - val_loss: 0.1261 - val_mse: 0.0609 - lr: 5.0000e-04\n",
            "Epoch 154/1000\n",
            "2/2 [==============================] - 2s 907ms/step - loss: 0.0108 - mse: 0.0088 - val_loss: 0.1253 - val_mse: 0.0616 - lr: 5.0000e-04\n",
            "Epoch 155/1000\n",
            "2/2 [==============================] - 2s 902ms/step - loss: 0.0107 - mse: 0.0088 - val_loss: 0.1234 - val_mse: 0.0607 - lr: 5.0000e-04\n",
            "Epoch 156/1000\n",
            "2/2 [==============================] - 2s 899ms/step - loss: 0.0106 - mse: 0.0088 - val_loss: 0.1256 - val_mse: 0.0614 - lr: 5.0000e-04\n",
            "Epoch 157/1000\n",
            "2/2 [==============================] - 2s 898ms/step - loss: 0.0103 - mse: 0.0085 - val_loss: 0.1271 - val_mse: 0.0617 - lr: 5.0000e-04\n",
            "Epoch 158/1000\n",
            "2/2 [==============================] - 2s 900ms/step - loss: 0.0102 - mse: 0.0085 - val_loss: 0.1259 - val_mse: 0.0611 - lr: 5.0000e-04\n",
            "Epoch 159/1000\n",
            "2/2 [==============================] - 2s 901ms/step - loss: 0.0100 - mse: 0.0083 - val_loss: 0.1254 - val_mse: 0.0614 - lr: 5.0000e-04\n",
            "Epoch 160/1000\n",
            "2/2 [==============================] - 2s 904ms/step - loss: 0.0099 - mse: 0.0082 - val_loss: 0.1244 - val_mse: 0.0611 - lr: 5.0000e-04\n",
            "Epoch 161/1000\n",
            "2/2 [==============================] - 2s 903ms/step - loss: 0.0098 - mse: 0.0082 - val_loss: 0.1251 - val_mse: 0.0613 - lr: 5.0000e-04\n",
            "Epoch 162/1000\n",
            "2/2 [==============================] - 2s 902ms/step - loss: 0.0096 - mse: 0.0081 - val_loss: 0.1258 - val_mse: 0.0615 - lr: 5.0000e-04\n",
            "Epoch 163/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0095 - mse: 0.0079 - val_loss: 0.1270 - val_mse: 0.0617 - lr: 5.0000e-04\n",
            "Epoch 164/1000\n",
            "2/2 [==============================] - 2s 911ms/step - loss: 0.0094 - mse: 0.0079 - val_loss: 0.1264 - val_mse: 0.0612 - lr: 5.0000e-04\n",
            "Epoch 165/1000\n",
            "2/2 [==============================] - 2s 899ms/step - loss: 0.0093 - mse: 0.0078 - val_loss: 0.1275 - val_mse: 0.0620 - lr: 5.0000e-04\n",
            "Epoch 166/1000\n",
            "2/2 [==============================] - 2s 903ms/step - loss: 0.0092 - mse: 0.0077 - val_loss: 0.1268 - val_mse: 0.0617 - lr: 5.0000e-04\n",
            "Epoch 167/1000\n",
            "2/2 [==============================] - 2s 901ms/step - loss: 0.0091 - mse: 0.0076 - val_loss: 0.1262 - val_mse: 0.0616 - lr: 5.0000e-04\n",
            "Epoch 168/1000\n",
            "2/2 [==============================] - 2s 898ms/step - loss: 0.0089 - mse: 0.0075 - val_loss: 0.1257 - val_mse: 0.0613 - lr: 5.0000e-04\n",
            "Epoch 169/1000\n",
            "2/2 [==============================] - 2s 904ms/step - loss: 0.0089 - mse: 0.0075 - val_loss: 0.1251 - val_mse: 0.0615 - lr: 5.0000e-04\n",
            "Epoch 170/1000\n",
            "2/2 [==============================] - 2s 899ms/step - loss: 0.0091 - mse: 0.0075 - val_loss: 0.1240 - val_mse: 0.0615 - lr: 5.0000e-04\n",
            "Epoch 171/1000\n",
            "2/2 [==============================] - 2s 907ms/step - loss: 0.0099 - mse: 0.0079 - val_loss: 0.1215 - val_mse: 0.0616 - lr: 5.0000e-04\n",
            "Epoch 172/1000\n",
            "2/2 [==============================] - 2s 897ms/step - loss: 0.0126 - mse: 0.0097 - val_loss: 0.1195 - val_mse: 0.0606 - lr: 5.0000e-04\n",
            "Epoch 173/1000\n",
            "2/2 [==============================] - 2s 903ms/step - loss: 0.0163 - mse: 0.0116 - val_loss: 0.1196 - val_mse: 0.0592 - lr: 5.0000e-04\n",
            "Epoch 174/1000\n",
            "2/2 [==============================] - 2s 906ms/step - loss: 0.0126 - mse: 0.0102 - val_loss: 0.1416 - val_mse: 0.0667 - lr: 5.0000e-04\n",
            "Epoch 175/1000\n",
            "2/2 [==============================] - 2s 904ms/step - loss: 0.0156 - mse: 0.0112 - val_loss: 0.1221 - val_mse: 0.0608 - lr: 5.0000e-04\n",
            "Epoch 176/1000\n",
            "2/2 [==============================] - 2s 906ms/step - loss: 0.0135 - mse: 0.0102 - val_loss: 0.1200 - val_mse: 0.0600 - lr: 5.0000e-04\n",
            "Epoch 177/1000\n",
            "2/2 [==============================] - 2s 898ms/step - loss: 0.0145 - mse: 0.0119 - val_loss: 0.1226 - val_mse: 0.0604 - lr: 5.0000e-04\n",
            "Epoch 178/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0128 - mse: 0.0104 - val_loss: 0.1286 - val_mse: 0.0602 - lr: 5.0000e-04\n",
            "Epoch 179/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0123 - mse: 0.0090 - val_loss: 0.1216 - val_mse: 0.0620 - lr: 5.0000e-04\n",
            "Epoch 180/1000\n",
            "2/2 [==============================] - 2s 907ms/step - loss: 0.0136 - mse: 0.0105 - val_loss: 0.1209 - val_mse: 0.0585 - lr: 5.0000e-04\n",
            "Epoch 181/1000\n",
            "2/2 [==============================] - 2s 899ms/step - loss: 0.0119 - mse: 0.0097 - val_loss: 0.1332 - val_mse: 0.0640 - lr: 5.0000e-04\n",
            "Epoch 182/1000\n",
            "2/2 [==============================] - 2s 904ms/step - loss: 0.0118 - mse: 0.0091 - val_loss: 0.1202 - val_mse: 0.0600 - lr: 5.0000e-04\n",
            "Epoch 183/1000\n",
            "2/2 [==============================] - 2s 901ms/step - loss: 0.0118 - mse: 0.0094 - val_loss: 0.1216 - val_mse: 0.0594 - lr: 5.0000e-04\n",
            "Epoch 184/1000\n",
            "2/2 [==============================] - 2s 905ms/step - loss: 0.0101 - mse: 0.0084 - val_loss: 0.1306 - val_mse: 0.0628 - lr: 5.0000e-04\n",
            "Epoch 185/1000\n",
            "2/2 [==============================] - 2s 901ms/step - loss: 0.0103 - mse: 0.0082 - val_loss: 0.1213 - val_mse: 0.0605 - lr: 5.0000e-04\n",
            "Epoch 186/1000\n",
            "2/2 [==============================] - 2s 903ms/step - loss: 0.0106 - mse: 0.0083 - val_loss: 0.1224 - val_mse: 0.0597 - lr: 5.0000e-04\n",
            "Epoch 187/1000\n",
            "2/2 [==============================] - 2s 900ms/step - loss: 0.0092 - mse: 0.0077 - val_loss: 0.1294 - val_mse: 0.0621 - lr: 5.0000e-04\n",
            "Epoch 188/1000\n",
            "2/2 [==============================] - 2s 897ms/step - loss: 0.0096 - mse: 0.0078 - val_loss: 0.1223 - val_mse: 0.0599 - lr: 5.0000e-04\n",
            "Epoch 189/1000\n",
            "2/2 [==============================] - 2s 901ms/step - loss: 0.0091 - mse: 0.0076 - val_loss: 0.1231 - val_mse: 0.0601 - lr: 5.0000e-04\n",
            "Epoch 190/1000\n",
            "2/2 [==============================] - 2s 900ms/step - loss: 0.0085 - mse: 0.0072 - val_loss: 0.1278 - val_mse: 0.0615 - lr: 5.0000e-04\n",
            "Epoch 191/1000\n",
            "2/2 [==============================] - 2s 905ms/step - loss: 0.0086 - mse: 0.0072 - val_loss: 0.1241 - val_mse: 0.0604 - lr: 5.0000e-04\n",
            "Epoch 192/1000\n",
            "2/2 [==============================] - 2s 902ms/step - loss: 0.0083 - mse: 0.0069 - val_loss: 0.1229 - val_mse: 0.0603 - lr: 5.0000e-04\n",
            "Epoch 193/1000\n",
            "2/2 [==============================] - 2s 903ms/step - loss: 0.0081 - mse: 0.0069 - val_loss: 0.1266 - val_mse: 0.0610 - lr: 5.0000e-04\n",
            "Epoch 194/1000\n",
            "2/2 [==============================] - 2s 899ms/step - loss: 0.0080 - mse: 0.0068 - val_loss: 0.1247 - val_mse: 0.0608 - lr: 5.0000e-04\n",
            "Epoch 195/1000\n",
            "2/2 [==============================] - 2s 895ms/step - loss: 0.0078 - mse: 0.0067 - val_loss: 0.1237 - val_mse: 0.0603 - lr: 5.0000e-04\n",
            "Epoch 196/1000\n",
            "2/2 [==============================] - 2s 896ms/step - loss: 0.0078 - mse: 0.0066 - val_loss: 0.1252 - val_mse: 0.0611 - lr: 5.0000e-04\n",
            "Epoch 197/1000\n",
            "2/2 [==============================] - 2s 899ms/step - loss: 0.0076 - mse: 0.0066 - val_loss: 0.1255 - val_mse: 0.0604 - lr: 5.0000e-04\n",
            "Epoch 198/1000\n",
            "2/2 [==============================] - 2s 898ms/step - loss: 0.0076 - mse: 0.0065 - val_loss: 0.1261 - val_mse: 0.0614 - lr: 5.0000e-04\n",
            "Epoch 199/1000\n",
            "2/2 [==============================] - 2s 917ms/step - loss: 0.0075 - mse: 0.0064 - val_loss: 0.1237 - val_mse: 0.0601 - lr: 5.0000e-04\n",
            "Epoch 200/1000\n",
            "2/2 [==============================] - 2s 903ms/step - loss: 0.0074 - mse: 0.0064 - val_loss: 0.1260 - val_mse: 0.0613 - lr: 5.0000e-04\n",
            "Epoch 201/1000\n",
            "2/2 [==============================] - 2s 900ms/step - loss: 0.0073 - mse: 0.0063 - val_loss: 0.1254 - val_mse: 0.0606 - lr: 5.0000e-04\n",
            "Epoch 202/1000\n",
            "2/2 [==============================] - 2s 902ms/step - loss: 0.0072 - mse: 0.0063 - val_loss: 0.1253 - val_mse: 0.0609 - lr: 5.0000e-04\n",
            "Epoch 203/1000\n",
            "2/2 [==============================] - 2s 902ms/step - loss: 0.0072 - mse: 0.0062 - val_loss: 0.1252 - val_mse: 0.0609 - lr: 5.0000e-04\n",
            "Epoch 204/1000\n",
            "2/2 [==============================] - 2s 905ms/step - loss: 0.0071 - mse: 0.0062 - val_loss: 0.1251 - val_mse: 0.0607 - lr: 5.0000e-04\n",
            "Epoch 205/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0070 - mse: 0.0061 - val_loss: 0.1262 - val_mse: 0.0613 - lr: 5.0000e-04\n",
            "Epoch 206/1000\n",
            "2/2 [==============================] - 2s 911ms/step - loss: 0.0070 - mse: 0.0061 - val_loss: 0.1260 - val_mse: 0.0609 - lr: 5.0000e-04\n",
            "Epoch 207/1000\n",
            "2/2 [==============================] - 2s 890ms/step - loss: 0.0069 - mse: 0.0060 - val_loss: 0.1264 - val_mse: 0.0614 - lr: 5.0000e-04\n",
            "Epoch 208/1000\n",
            "2/2 [==============================] - 2s 909ms/step - loss: 0.0069 - mse: 0.0060 - val_loss: 0.1255 - val_mse: 0.0608 - lr: 5.0000e-04\n",
            "Epoch 209/1000\n",
            "2/2 [==============================] - 2s 903ms/step - loss: 0.0068 - mse: 0.0059 - val_loss: 0.1256 - val_mse: 0.0610 - lr: 5.0000e-04\n",
            "Epoch 210/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0067 - mse: 0.0059 - val_loss: 0.1258 - val_mse: 0.0612 - lr: 5.0000e-04\n",
            "Epoch 211/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0067 - mse: 0.0059 - val_loss: 0.1255 - val_mse: 0.0608 - lr: 5.0000e-04\n",
            "Epoch 212/1000\n",
            "2/2 [==============================] - 2s 908ms/step - loss: 0.0066 - mse: 0.0058 - val_loss: 0.1262 - val_mse: 0.0614 - lr: 5.0000e-04\n",
            "Epoch 213/1000\n",
            "2/2 [==============================] - 2s 908ms/step - loss: 0.0066 - mse: 0.0058 - val_loss: 0.1257 - val_mse: 0.0610 - lr: 5.0000e-04\n",
            "Epoch 214/1000\n",
            "2/2 [==============================] - 2s 901ms/step - loss: 0.0065 - mse: 0.0058 - val_loss: 0.1252 - val_mse: 0.0609 - lr: 5.0000e-04\n",
            "Epoch 215/1000\n",
            "2/2 [==============================] - 2s 904ms/step - loss: 0.0065 - mse: 0.0057 - val_loss: 0.1261 - val_mse: 0.0613 - lr: 5.0000e-04\n",
            "Epoch 216/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0065 - mse: 0.0057 - val_loss: 0.1265 - val_mse: 0.0612 - lr: 5.0000e-04\n",
            "Epoch 217/1000\n",
            "2/2 [==============================] - 2s 911ms/step - loss: 0.0064 - mse: 0.0057 - val_loss: 0.1268 - val_mse: 0.0613 - lr: 5.0000e-04\n",
            "Epoch 218/1000\n",
            "2/2 [==============================] - 2s 900ms/step - loss: 0.0064 - mse: 0.0056 - val_loss: 0.1263 - val_mse: 0.0615 - lr: 5.0000e-04\n",
            "Epoch 219/1000\n",
            "2/2 [==============================] - 2s 903ms/step - loss: 0.0063 - mse: 0.0056 - val_loss: 0.1253 - val_mse: 0.0609 - lr: 5.0000e-04\n",
            "Epoch 220/1000\n",
            "2/2 [==============================] - 2s 902ms/step - loss: 0.0064 - mse: 0.0056 - val_loss: 0.1250 - val_mse: 0.0610 - lr: 5.0000e-04\n",
            "Epoch 221/1000\n",
            "2/2 [==============================] - 2s 905ms/step - loss: 0.0064 - mse: 0.0056 - val_loss: 0.1247 - val_mse: 0.0612 - lr: 5.0000e-04\n",
            "Epoch 222/1000\n",
            "2/2 [==============================] - 2s 900ms/step - loss: 0.0065 - mse: 0.0056 - val_loss: 0.1241 - val_mse: 0.0610 - lr: 5.0000e-04\n",
            "Epoch 223/1000\n",
            "2/2 [==============================] - 2s 907ms/step - loss: 0.0067 - mse: 0.0058 - val_loss: 0.1234 - val_mse: 0.0606 - lr: 5.0000e-04\n",
            "Epoch 224/1000\n",
            "2/2 [==============================] - 2s 898ms/step - loss: 0.0069 - mse: 0.0060 - val_loss: 0.1237 - val_mse: 0.0603 - lr: 5.0000e-04\n",
            "Epoch 225/1000\n",
            "2/2 [==============================] - 2s 902ms/step - loss: 0.0064 - mse: 0.0056 - val_loss: 0.1289 - val_mse: 0.0621 - lr: 5.0000e-04\n",
            "Epoch 226/1000\n",
            "2/2 [==============================] - 2s 900ms/step - loss: 0.0073 - mse: 0.0062 - val_loss: 0.1345 - val_mse: 0.0638 - lr: 5.0000e-04\n",
            "Epoch 227/1000\n",
            "2/2 [==============================] - 2s 903ms/step - loss: 0.0104 - mse: 0.0082 - val_loss: 0.1352 - val_mse: 0.0640 - lr: 5.0000e-04\n",
            "Epoch 228/1000\n",
            "2/2 [==============================] - 2s 902ms/step - loss: 0.0095 - mse: 0.0075 - val_loss: 0.1264 - val_mse: 0.0618 - lr: 5.0000e-04\n",
            "Epoch 229/1000\n",
            "2/2 [==============================] - 2s 903ms/step - loss: 0.0073 - mse: 0.0060 - val_loss: 0.1208 - val_mse: 0.0597 - lr: 5.0000e-04\n",
            "Epoch 230/1000\n",
            "2/2 [==============================] - 2s 901ms/step - loss: 0.0093 - mse: 0.0078 - val_loss: 0.1225 - val_mse: 0.0601 - lr: 5.0000e-04\n",
            "Epoch 231/1000\n",
            "2/2 [==============================] - 2s 899ms/step - loss: 0.0073 - mse: 0.0063 - val_loss: 0.1319 - val_mse: 0.0625 - lr: 5.0000e-04\n",
            "Epoch 232/1000\n",
            "2/2 [==============================] - 2s 909ms/step - loss: 0.0086 - mse: 0.0068 - val_loss: 0.1258 - val_mse: 0.0600 - lr: 5.0000e-04\n",
            "Epoch 233/1000\n",
            "2/2 [==============================] - 2s 898ms/step - loss: 0.0071 - mse: 0.0058 - val_loss: 0.1240 - val_mse: 0.0619 - lr: 5.0000e-04\n",
            "Epoch 234/1000\n",
            "2/2 [==============================] - 2s 906ms/step - loss: 0.0079 - mse: 0.0065 - val_loss: 0.1222 - val_mse: 0.0592 - lr: 5.0000e-04\n",
            "Epoch 235/1000\n",
            "2/2 [==============================] - 2s 901ms/step - loss: 0.0071 - mse: 0.0061 - val_loss: 0.1317 - val_mse: 0.0640 - lr: 5.0000e-04\n",
            "Epoch 236/1000\n",
            "2/2 [==============================] - 2s 905ms/step - loss: 0.0084 - mse: 0.0071 - val_loss: 0.1288 - val_mse: 0.0606 - lr: 5.0000e-04\n",
            "Epoch 237/1000\n",
            "2/2 [==============================] - 2s 901ms/step - loss: 0.0076 - mse: 0.0060 - val_loss: 0.1233 - val_mse: 0.0615 - lr: 5.0000e-04\n",
            "Epoch 238/1000\n",
            "2/2 [==============================] - 2s 901ms/step - loss: 0.0083 - mse: 0.0064 - val_loss: 0.1214 - val_mse: 0.0600 - lr: 5.0000e-04\n",
            "Epoch 239/1000\n",
            "2/2 [==============================] - 2s 903ms/step - loss: 0.0071 - mse: 0.0062 - val_loss: 0.1288 - val_mse: 0.0618 - lr: 5.0000e-04\n",
            "Epoch 240/1000\n",
            "2/2 [==============================] - 2s 903ms/step - loss: 0.0081 - mse: 0.0069 - val_loss: 0.1327 - val_mse: 0.0633 - lr: 5.0000e-04\n",
            "Epoch 241/1000\n",
            "2/2 [==============================] - 2s 898ms/step - loss: 0.0080 - mse: 0.0064 - val_loss: 0.1243 - val_mse: 0.0607 - lr: 5.0000e-04\n",
            "Epoch 242/1000\n",
            "2/2 [==============================] - 2s 905ms/step - loss: 0.0071 - mse: 0.0059 - val_loss: 0.1207 - val_mse: 0.0600 - lr: 5.0000e-04\n",
            "Epoch 243/1000\n",
            "2/2 [==============================] - 2s 904ms/step - loss: 0.0076 - mse: 0.0064 - val_loss: 0.1251 - val_mse: 0.0603 - lr: 5.0000e-04\n",
            "Epoch 244/1000\n",
            "2/2 [==============================] - 2s 905ms/step - loss: 0.0069 - mse: 0.0059 - val_loss: 0.1327 - val_mse: 0.0637 - lr: 5.0000e-04\n",
            "Epoch 245/1000\n",
            "2/2 [==============================] - 2s 902ms/step - loss: 0.0074 - mse: 0.0062 - val_loss: 0.1218 - val_mse: 0.0593 - lr: 5.0000e-04\n",
            "Epoch 246/1000\n",
            "2/2 [==============================] - 2s 903ms/step - loss: 0.0070 - mse: 0.0059 - val_loss: 0.1241 - val_mse: 0.0614 - lr: 5.0000e-04\n",
            "Epoch 247/1000\n",
            "2/2 [==============================] - 2s 900ms/step - loss: 0.0065 - mse: 0.0056 - val_loss: 0.1263 - val_mse: 0.0602 - lr: 5.0000e-04\n",
            "Epoch 248/1000\n",
            "2/2 [==============================] - 2s 906ms/step - loss: 0.0065 - mse: 0.0056 - val_loss: 0.1290 - val_mse: 0.0625 - lr: 5.0000e-04\n",
            "Epoch 249/1000\n",
            "2/2 [==============================] - 2s 909ms/step - loss: 0.0061 - mse: 0.0053 - val_loss: 0.1232 - val_mse: 0.0601 - lr: 5.0000e-04\n",
            "Epoch 250/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0062 - mse: 0.0054 - val_loss: 0.1257 - val_mse: 0.0614 - lr: 5.0000e-04\n",
            "Epoch 251/1000\n",
            "2/2 [==============================] - 2s 908ms/step - loss: 0.0058 - mse: 0.0051 - val_loss: 0.1260 - val_mse: 0.0605 - lr: 5.0000e-04\n",
            "Epoch 252/1000\n",
            "2/2 [==============================] - 2s 904ms/step - loss: 0.0059 - mse: 0.0052 - val_loss: 0.1277 - val_mse: 0.0619 - lr: 5.0000e-04\n",
            "Epoch 253/1000\n",
            "2/2 [==============================] - 2s 903ms/step - loss: 0.0058 - mse: 0.0051 - val_loss: 0.1257 - val_mse: 0.0610 - lr: 5.0000e-04\n",
            "Epoch 254/1000\n",
            "2/2 [==============================] - 2s 901ms/step - loss: 0.0057 - mse: 0.0050 - val_loss: 0.1248 - val_mse: 0.0605 - lr: 5.0000e-04\n",
            "Epoch 255/1000\n",
            "2/2 [==============================] - 2s 904ms/step - loss: 0.0057 - mse: 0.0050 - val_loss: 0.1254 - val_mse: 0.0611 - lr: 5.0000e-04\n",
            "Epoch 256/1000\n",
            "2/2 [==============================] - 2s 907ms/step - loss: 0.0056 - mse: 0.0049 - val_loss: 0.1264 - val_mse: 0.0610 - lr: 5.0000e-04\n",
            "Epoch 257/1000\n",
            "2/2 [==============================] - 2s 902ms/step - loss: 0.0055 - mse: 0.0049 - val_loss: 0.1264 - val_mse: 0.0613 - lr: 5.0000e-04\n",
            "Epoch 258/1000\n",
            "2/2 [==============================] - 2s 905ms/step - loss: 0.0055 - mse: 0.0048 - val_loss: 0.1258 - val_mse: 0.0610 - lr: 5.0000e-04\n",
            "Epoch 259/1000\n",
            "2/2 [==============================] - 2s 902ms/step - loss: 0.0054 - mse: 0.0048 - val_loss: 0.1248 - val_mse: 0.0608 - lr: 5.0000e-04\n",
            "Epoch 260/1000\n",
            "2/2 [==============================] - 2s 900ms/step - loss: 0.0054 - mse: 0.0048 - val_loss: 0.1256 - val_mse: 0.0610 - lr: 5.0000e-04\n",
            "Epoch 261/1000\n",
            "2/2 [==============================] - 2s 902ms/step - loss: 0.0053 - mse: 0.0048 - val_loss: 0.1264 - val_mse: 0.0611 - lr: 5.0000e-04\n",
            "Epoch 262/1000\n",
            "2/2 [==============================] - 2s 903ms/step - loss: 0.0053 - mse: 0.0048 - val_loss: 0.1277 - val_mse: 0.0616 - lr: 5.0000e-04\n",
            "Epoch 263/1000\n",
            "2/2 [==============================] - 2s 899ms/step - loss: 0.0053 - mse: 0.0048 - val_loss: 0.1268 - val_mse: 0.0612 - lr: 5.0000e-04\n",
            "Epoch 264/1000\n",
            "2/2 [==============================] - 2s 901ms/step - loss: 0.0052 - mse: 0.0047 - val_loss: 0.1263 - val_mse: 0.0612 - lr: 5.0000e-04\n",
            "Epoch 265/1000\n",
            "2/2 [==============================] - 2s 902ms/step - loss: 0.0052 - mse: 0.0047 - val_loss: 0.1257 - val_mse: 0.0611 - lr: 5.0000e-04\n",
            "Epoch 266/1000\n",
            "2/2 [==============================] - 2s 901ms/step - loss: 0.0052 - mse: 0.0046 - val_loss: 0.1266 - val_mse: 0.0613 - lr: 5.0000e-04\n",
            "Epoch 267/1000\n",
            "2/2 [==============================] - 2s 907ms/step - loss: 0.0051 - mse: 0.0046 - val_loss: 0.1264 - val_mse: 0.0612 - lr: 5.0000e-04\n",
            "Epoch 268/1000\n",
            "2/2 [==============================] - 2s 898ms/step - loss: 0.0051 - mse: 0.0046 - val_loss: 0.1274 - val_mse: 0.0616 - lr: 5.0000e-04\n",
            "Epoch 269/1000\n",
            "2/2 [==============================] - 2s 906ms/step - loss: 0.0051 - mse: 0.0046 - val_loss: 0.1270 - val_mse: 0.0613 - lr: 5.0000e-04\n",
            "Epoch 270/1000\n",
            "2/2 [==============================] - 2s 913ms/step - loss: 0.0051 - mse: 0.0046 - val_loss: 0.1273 - val_mse: 0.0615 - lr: 5.0000e-04\n",
            "Epoch 271/1000\n",
            "2/2 [==============================] - 2s 904ms/step - loss: 0.0050 - mse: 0.0045 - val_loss: 0.1263 - val_mse: 0.0611 - lr: 5.0000e-04\n",
            "Epoch 272/1000\n",
            "2/2 [==============================] - 2s 903ms/step - loss: 0.0050 - mse: 0.0045 - val_loss: 0.1261 - val_mse: 0.0611 - lr: 5.0000e-04\n",
            "Epoch 273/1000\n",
            "2/2 [==============================] - 2s 907ms/step - loss: 0.0050 - mse: 0.0045 - val_loss: 0.1254 - val_mse: 0.0611 - lr: 5.0000e-04\n",
            "Epoch 274/1000\n",
            "2/2 [==============================] - 2s 905ms/step - loss: 0.0051 - mse: 0.0045 - val_loss: 0.1247 - val_mse: 0.0608 - lr: 5.0000e-04\n",
            "Epoch 275/1000\n",
            "2/2 [==============================] - 2s 904ms/step - loss: 0.0051 - mse: 0.0046 - val_loss: 0.1253 - val_mse: 0.0610 - lr: 5.0000e-04\n",
            "Epoch 276/1000\n",
            "2/2 [==============================] - 2s 905ms/step - loss: 0.0050 - mse: 0.0045 - val_loss: 0.1266 - val_mse: 0.0613 - lr: 5.0000e-04\n",
            "Epoch 277/1000\n",
            "2/2 [==============================] - 2s 902ms/step - loss: 0.0049 - mse: 0.0045 - val_loss: 0.1280 - val_mse: 0.0617 - lr: 5.0000e-04\n",
            "Epoch 278/1000\n",
            "2/2 [==============================] - 2s 912ms/step - loss: 0.0051 - mse: 0.0046 - val_loss: 0.1298 - val_mse: 0.0623 - lr: 5.0000e-04\n",
            "Epoch 279/1000\n",
            "2/2 [==============================] - 2s 900ms/step - loss: 0.0058 - mse: 0.0050 - val_loss: 0.1332 - val_mse: 0.0636 - lr: 5.0000e-04\n",
            "Epoch 280/1000\n",
            "2/2 [==============================] - 2s 904ms/step - loss: 0.0064 - mse: 0.0055 - val_loss: 0.1309 - val_mse: 0.0623 - lr: 5.0000e-04\n",
            "Epoch 281/1000\n",
            "2/2 [==============================] - 2s 903ms/step - loss: 0.0059 - mse: 0.0051 - val_loss: 0.1282 - val_mse: 0.0615 - lr: 5.0000e-04\n",
            "Epoch 282/1000\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.0051 - mse: 0.0045 - val_loss: 0.1246 - val_mse: 0.0611 - lr: 5.0000e-04\n",
            "Epoch 283/1000\n",
            "2/2 [==============================] - 2s 910ms/step - loss: 0.0056 - mse: 0.0048 - val_loss: 0.1235 - val_mse: 0.0608 - lr: 5.0000e-04\n",
            "Epoch 284/1000\n",
            "2/2 [==============================] - 2s 935ms/step - loss: 0.0062 - mse: 0.0054 - val_loss: 0.1228 - val_mse: 0.0603 - lr: 5.0000e-04\n"
          ]
        }
      ],
      "source": [
        "# Learning Rate Scheduler\n",
        "def scheduler(epoch, lr):\n",
        "  if epoch == 500:\n",
        "    return lr /5\n",
        "  else:\n",
        "    return lr\n",
        "\n",
        "scheduler_cb = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "# Early stopping criteria\n",
        "early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",min_delta=0.0005, patience=200, verbose=0, mode=\"auto\", baseline=None, restore_best_weights=True)\n",
        "\n",
        "# Training (Fit)\n",
        "history = model.fit(train_data, train_labels, epochs=1000, validation_data=(validation_data, validation_labels), callbacks=[early, scheduler_cb])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This next plot shows loss of the trianing and validation sets."
      ],
      "metadata": {
        "id": "xIGiYmh3fwP2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "UgCp0oNUAfzt",
        "outputId": "d4466992-2121-4c0d-c1bf-09bb7ae3a448",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'mse', 'val_loss', 'val_mse', 'lr'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "print(history.history.keys())\n",
        "# # summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the results\n",
        "\n",
        "After our training, we need to plot our results to verify if we are making a good prediction since the value of the loss can be heavily influenced by outliers. The following cell includes nine plots we use to evaluate performance on each of the points."
      ],
      "metadata": {
        "id": "Hb4C5FSDf-2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for the volume plot of hotspot\n",
        "\n",
        "def area_hotspot(datapoint):\n",
        "  tinc = 5\n",
        "  tnum = int(4500/tinc)\n",
        "\n",
        "  tinc = 5\n",
        "  tnum = int(4500/tinc)\n",
        "\n",
        "  bins=np.zeros((tnum,2))\n",
        "  bins[:,0] = [ tinc*(0.5 + x) for x in list(range(tnum))]\n",
        "\n",
        "  for bin_index, temp in np.ndenumerate(datapoint):\n",
        "    theta = temp * 1000\n",
        "    tind=math.floor(theta/tinc)\n",
        "    bins[:tind, 1] += 4 # ~ Roughly 2*2*1 nm^3 (volume value from Chunyu)\n",
        "  \n",
        "  return bins"
      ],
      "metadata": {
        "id": "cVbLrXkBNWDI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def datapoint_results_print(simulation_point, simulation_temperatures, prediction_tensor):\n",
        "\n",
        "  # Simulation point is the input train_data[<point order>,<dim 0>,<dim 1>,<dim 2>,<channel>]\n",
        "  # For example, simulation_point = train_data[i,:,:,:,:]\n",
        "\n",
        "\n",
        "\n",
        "  fig = make_subplots(rows=3, cols=3, specs=[[{\"type\": \"scatter3d\"},{\"type\": \"scatter3d\"},{\"type\": \"scatter3d\"}],\n",
        "                                             [{\"type\": \"scatter3d\"},{\"type\": \"scatter3d\"},{\"type\": \"scatter\"}],\n",
        "                                             [{\"type\": \"histogram\"},{\"type\": \"histogram\"},{\"type\": \"scatter\"}]],\n",
        "                      subplot_titles=[\"Input 1\",\"Input 2\",\"Input 3\",\n",
        "                                      \"Temp (Labels)\",\"Temp (Predictions)\",\"Parity Plot\",\n",
        "                                      \"Temp (Distributions)\", \"Residuals\", \"Hotspot volume\"], horizontal_spacing = 0.1, vertical_spacing = 0.1)\n",
        "  \n",
        "  fig.update_layout(autosize=False, width=800, height=800) \n",
        "\n",
        "  # FIRST PLOT --> INPUT 1\n",
        "\n",
        "  input_1 = simulation_point[:,:,:,0].squeeze()\n",
        "\n",
        "  X,Y,Z = np.mgrid[0:input_1.shape[0], 0:input_1.shape[1], 0:input_1.shape[2]]\n",
        "  #input_1_xz = np.swapaxes(input_1, 2, 0)\n",
        "\n",
        "  trace_1 = go.Scatter3d(x = X.flatten(), y = Y.flatten(), z=Z.flatten(),\n",
        "                          mode='markers', marker=dict(colorscale='Viridis', size=8, line=dict(width=0), symbol='square', color = input_1.flatten(), colorbar=dict(thickness=20, len=0.3, x=0.27, y=0.9)), showlegend=False)\n",
        "  fig.add_trace(trace_1, row=1, col=1)\n",
        "\n",
        "  # SECOND PLOT --> INPUT 2\n",
        "\n",
        "  input_2 = simulation_point[:,:,:,1].squeeze()\n",
        "\n",
        "  X,Y,Z = np.mgrid[0:input_2.shape[0], 0:input_2.shape[1], 0:input_2.shape[2]]\n",
        "  #input_2_xz = np.swapaxes(input_2, 2, 0)\n",
        "\n",
        "  trace_2 = go.Scatter3d(x = X.flatten(), y = Y.flatten(), z=Z.flatten(),\n",
        "                          mode='markers', marker=dict(colorscale='Viridis', size=8, line=dict(width=0), symbol='square', color = input_2.flatten(), colorbar=dict(thickness=20, len=0.3, x=0.62, y=0.9)), showlegend=False)\n",
        "  fig.add_trace(trace_2, row=1, col=2)\n",
        "\n",
        "\n",
        "  # THIRD PLOT --> INPUT 3\n",
        "\n",
        "  input_3 = simulation_point[:,:,:,2].squeeze()\n",
        "\n",
        "  X,Y,Z = np.mgrid[0:input_3.shape[0], 0:input_3.shape[1], 0:input_3.shape[2]]\n",
        "  #input_3_xz = np.swapaxes(input_3, 2, 0)\n",
        "\n",
        "  trace_3 = go.Scatter3d(x = X.flatten(), y = Y.flatten(), z=Z.flatten(),\n",
        "                          mode='markers', marker=dict(colorscale='Viridis', size=8, line=dict(width=0), symbol='square', color = input_3.flatten(), colorbar=dict(thickness=20, len=0.3, x=1, y=0.9)), showlegend=False)\n",
        "  fig.add_trace(trace_3, row=1, col=3)\n",
        "\n",
        "\n",
        "  # FOURTH PLOT --> TEMPS (LABELS)\n",
        "\n",
        "  maxval = max(np.max(prediction_tensor), np.max(simulation_temperatures))\n",
        "  \n",
        "\n",
        "  X,Y,Z = np.mgrid[0:simulation_temperatures.shape[0], 0:simulation_temperatures.shape[1], 0:simulation_temperatures.shape[2]]\n",
        "  #simulation_temperatures_xz = np.swapaxes(simulation_temperatures, 2, 0)\n",
        "\n",
        "  trace_4 = go.Scatter3d(x = X.flatten(), y = Y.flatten(), z=Z.flatten(),\n",
        "                          mode='markers', marker=dict(cmin=0, cmax=maxval, colorscale='Reds', size=8, line=dict(width=0), symbol='square', color = simulation_temperatures.flatten(), colorbar=dict(thickness=20,len=0.3, x=0.27, y=0.5)), showlegend=False)\n",
        "  fig.add_trace(trace_4, row=2, col=1)\n",
        "\n",
        "\n",
        "  # FIFTH PLOT --> TEMPS (PREDICTIONS)\n",
        "\n",
        "  X,Y,Z = np.mgrid[0:prediction_tensor.shape[0], 0:prediction_tensor.shape[1], 0:prediction_tensor.shape[2]]\n",
        "  #prediction_tensor_xz = np.swapaxes(prediction_tensor, 2, 0)\n",
        "\n",
        "  trace_5 = go.Scatter3d(x = X.flatten(), y = Y.flatten(), z=Z.flatten(),\n",
        "                          mode='markers', marker=dict(cmin=0, cmax=maxval, colorscale='Reds', size=8, line=dict(width=0), symbol='square', color = prediction_tensor.flatten(), colorbar=dict(thickness=20, len=0.3, x=0.62, y=0.5)), showlegend=False)\n",
        "  fig.add_trace(trace_5, row=2, col=2)\n",
        "\n",
        "  # SIXTH PLOT --> PARITY PLOT\n",
        "\n",
        "  trace_6 = go.Scatter(x=simulation_temperatures.flatten(), y = prediction_tensor.flatten(), mode='markers', showlegend=False)\n",
        "  fig.add_trace(trace_6, row=2, col=3)\n",
        "  fig.update_xaxes(title=\"Scaled Temperature (K) - Labels\", row=2, col=3)\n",
        "  fig.update_yaxes(title=\"Scaled Temperature (K) - Predictions\", row=2, col=3)\n",
        "\n",
        "\n",
        "  # SEVENTH PLOT --> TEMP (Distributions)\n",
        "\n",
        "  trace_7 = go.Histogram(x=prediction_tensor.flatten(), name='Predictions', marker=dict(color='red'), showlegend=True, legendgroup = '1')\n",
        "  trace_7b = go.Histogram(x=simulation_temperatures.flatten(), name='Truth', marker=dict(color='green'), showlegend=True, legendgroup = '1')\n",
        "  fig.update_xaxes(title=\"Temperature (K) - Labels\", row=3, col=1)\n",
        "  fig.add_trace(trace_7, row=3, col=1)\n",
        "  fig.add_trace(trace_7b, row=3, col=1) \n",
        "\n",
        "\n",
        "  # EIGHTH PLOT --> RESIDUALS\n",
        "\n",
        "  diff_xz = prediction_tensor - simulation_temperatures\n",
        "  flat_diff_xz = diff_xz.flatten()\n",
        "\n",
        "  trace_8 = go.Histogram(x=flat_diff_xz, showlegend=False)\n",
        "  trace_line = go.Scatter(x=[0,0], y = [0,700], mode='lines', showlegend=False)\n",
        "\n",
        "  fig.add_trace(trace_8, row=3, col=2)\n",
        "  fig.add_trace(trace_line, row=3, col=2)\n",
        "\n",
        "  # NINTH PLOT ---> VOLUME OF HOTSPOT\n",
        "  \n",
        "  bins_labels = area_hotspot(simulation_temperatures)\n",
        "  bins_predictions = area_hotspot(prediction_tensor)\n",
        "  trace_9 = go.Scatter(x=bins_predictions[:,1], y=bins_predictions[:,0], mode='lines',  name='Predictions', marker=dict(color='red'), showlegend=True, legendgroup = '2')\n",
        "  trace_9b = go.Scatter(x=bins_labels[:,1], y=bins_labels[:,0], mode='lines', name='Truth', marker=dict(color='green'), showlegend=True, legendgroup = '2')\n",
        "  \n",
        "  fig.add_trace(trace_9, row=3, col=3)\n",
        "  fig.add_trace(trace_9b, row=3, col=3) \n",
        "  fig.update_xaxes(type=\"log\", row=3, col=3)\n",
        "  fig.update_xaxes(title=\"Hotspot Volume (nm^3)\", row=3, col=3)\n",
        "  fig.update_yaxes(title=\"Temperature (K)\", row=3, col=3)  \n",
        "\n",
        "  #### \n",
        "\n",
        "  fig.update_layout(autosize=False, width=1400, height=1000, legend_tracegroupgap = 180, legend=dict(font=dict(size=16),orientation=\"h\"))   \n",
        "\n",
        "  return fig"
      ],
      "metadata": {
        "id": "p65_1oRxgTu1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since rendering multiple plots for each system is not ideal, we will save a numpy array with the model predictions and an HTML file with the interactive plots for exploration."
      ],
      "metadata": {
        "id": "0Jx7VbNCihTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p results/train\n",
        "!mkdir -p results/validation"
      ],
      "metadata": {
        "id": "zVpCWbXshU4h"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PREDICTIONS OVER TRAINING DATA\n",
        "\n",
        "for i, title in enumerate(paths):\n",
        "  print(i)\n",
        "  inppoint = train_data[i,:,:,:,:].squeeze()\n",
        "  inplabel = train_labels[i,:,:,:,:].squeeze()\n",
        "\n",
        "  prediction_point = model.predict(tf.expand_dims(inppoint, axis=0))\n",
        "  prediction_tensor = prediction_point.squeeze()\n",
        "  #print(prediction_tensor.shape)\n",
        "\n",
        "  inppoint = inppoint[:, 1:-1, 1:-1] # NON PERIODIC GETS PLOTTED\n",
        "\n",
        "  fig = datapoint_results_print(inppoint, inplabel, prediction_tensor)\n",
        "\n",
        "  os.mkdir('results/'+str(title))\n",
        "\n",
        "  ### SAVING NUMPY PREDICTIONS\n",
        "  np.save('results/'+str(title)+'/prediction.npy', prediction_tensor)\n",
        "  ### SAVING HTML IMAGES\n",
        "  fig.write_html('results/'+str(title)+'/visualization.html')"
      ],
      "metadata": {
        "id": "nTuoEr8Khjpw",
        "outputId": "a0292140-0061-4d74-ef3b-0876b313893a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "10\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "11\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "12\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "13\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "14\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "15\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "16\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "17\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "18\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "19\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "20\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "21\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "22\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "23\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "24\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "25\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "26\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "27\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "28\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "29\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "30\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "31\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "32\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "33\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "34\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "35\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "36\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "37\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "38\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "39\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "40\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "41\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "42\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "43\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "44\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "45\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "46\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "47\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "48\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "49\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "50\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "51\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "52\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "53\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "54\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "55\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "56\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "57\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "58\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "59\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "60\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "61\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "62\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "63\n",
            "1/1 [==============================] - 0s 20ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PREDICTIONS OVER VALIDATION DATA\n",
        "\n",
        "for i, title in enumerate(validation_paths):\n",
        "  print(i)\n",
        "  inppoint = validation_data[i,:,:,:,:].squeeze()\n",
        "  inplabel = validation_labels[i,:,:,:,:].squeeze()\n",
        "\n",
        "  prediction_point = model.predict(tf.expand_dims(inppoint, axis=0))\n",
        "  prediction_tensor = prediction_point.squeeze()\n",
        "\n",
        "  inppoint = inppoint[:, 1:-1, 1:-1] # NON PERIODIC GETS PLOTTED\n",
        "  fig = datapoint_results_print(inppoint, inplabel, prediction_tensor)\n",
        "  \n",
        "  os.mkdir('results/'+str(title))\n",
        "\n",
        "  ### SAVING NUMPY PREDICTIONS\n",
        "  np.save('results/'+str(title)+'/prediction.npy', prediction_tensor)\n",
        "  ### SAVING HTML IMAGES\n",
        "  fig.write_html('results/'+str(title)+'/visualization.html')"
      ],
      "metadata": {
        "id": "nYhrkn0_iK52",
        "outputId": "01eddf65-e1b5-4f1b-b6e8-f1addd4436c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "10\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "11\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "12\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "13\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "14\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "15\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "16\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "17\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "18\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "19\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "20\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "21\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "22\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "23\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "24\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "25\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "26\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "27\n",
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_hotspot(temp_grid):\n",
        "  x = []\n",
        "  y = []\n",
        "  z = []\n",
        "  temp = []\n",
        "  for i in range(16):\n",
        "    for j in range(32):\n",
        "      for k in range(32):\n",
        "        if temp_grid[i,j,k] >= 1.8: #1.52996:\n",
        "          x.append(i+1)\n",
        "          y.append(j+1)\n",
        "          z.append(k+1)\n",
        "          temp.append(temp_grid[i,j,k])\n",
        "  \n",
        "  df = pd.DataFrame(temp,columns=['Temperature'])\n",
        "  df['X'] = x\n",
        "  df['Y'] = y\n",
        "  df['Z'] = z\n",
        "\n",
        "  return df\n",
        "\n",
        "def agglo_cluster(dataframe):\n",
        "  pos = dataframe[['X','Y','Z']].values\n",
        "  agglo = AgglomerativeClustering(n_clusters=None, distance_threshold=1.8, linkage='single').fit(pos)\n",
        "  dataframe['Cluster ID'] = agglo.labels_\n",
        "  return dataframe\n",
        "\n",
        "def get_volume(dataframe):\n",
        "  vols = []\n",
        "  for i in range(dataframe['Cluster ID'].max()+1):\n",
        "    tmp = dataframe[dataframe['Cluster ID'] == i]\n",
        "    v = len(tmp)*4\n",
        "    vols.append(v)\n",
        "  return vols\n",
        "\n",
        "def get_temp_dist(dataframe):\n",
        "  mean_temps = []\n",
        "  std_temps = []\n",
        "  for i in range(dataframe['Cluster ID'].max()+1):\n",
        "    tmp = dataframe[dataframe['Cluster ID'] == i]\n",
        "    mean = np.mean(tmp['Temperature']*1000)\n",
        "    std = np.std(tmp['Temperature']*1000)\n",
        "    mean_temps.append(mean)\n",
        "    std_temps.append(std)\n",
        "  return mean_temps, std_temps\n",
        "\n",
        "def get_cm(dataframe):\n",
        "  cms = []\n",
        "  for i in range(dataframe['Cluster ID'].max()+1):\n",
        "    tmp = dataframe[dataframe['Cluster ID'] == i]\n",
        "    m = len(tmp)\n",
        "    cm_x = tmp['X'].sum()/m\n",
        "    cm_y = tmp['Y'].sum()/m\n",
        "    cm_z = tmp['Z'].sum()/m\n",
        "    cm = np.array([cm_x,cm_y,cm_z])\n",
        "    cms.append(cm)\n",
        "  return cms\n",
        "\n",
        "def get_mom_inertia(cms,dataframe):\n",
        "  inertias = []\n",
        "  for i in range(dataframe['Cluster ID'].max()+1):\n",
        "    tmp = dataframe[dataframe['Cluster ID'] == i]\n",
        "    r_i = tmp[['X','Y','Z']].values\n",
        "    r_cm = cms[i]\n",
        "    mom_int = 0\n",
        "    for j in range(len(tmp)):\n",
        "      mom_int += np.linalg.norm(r_i[j]-r_cm)**2\n",
        "    inertias.append(mom_int)\n",
        "  return inertias\n",
        "\n",
        "def plot_clusters(dataframe):\n",
        "  fig1 = go.Scatter3d(x = dataframe['X'], y = dataframe['Y'], z=dataframe['Z'], hovertemplate = 'Cluster ID: %{marker.color:.2f}<extra></extra>',\n",
        "                      mode='markers',  marker=dict(symbol='square', color = dataframe['Cluster ID']))\n",
        "  Fig = go.Figure(fig1)\n",
        "  return Fig"
      ],
      "metadata": {
        "id": "VaPQdkGzPaXa"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paths = [x[0] for x in os.walk('train/')][1:]\n",
        "md_temp = np.load(paths[1]+'/output.npy')/1000\n",
        "pred_temp = np.load('results/'+paths[1]+'/prediction.npy')"
      ],
      "metadata": {
        "id": "2kxZ0R89cO60"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "md_df = get_hotspot(md_temp)\n",
        "pred_df = get_hotspot(pred_temp)\n",
        "md_clust = agglo_cluster(md_df)\n",
        "pred_clust = agglo_cluster(pred_df)\n",
        "md_vols = get_volume(md_clust)\n",
        "pred_vols = get_volume(pred_clust)\n",
        "md_Tmean, md_Tstd = get_temp_dist(md_clust)\n",
        "pred_Tmean, pred_Tstd = get_temp_dist(pred_clust)\n",
        "md_cms = get_cm(md_clust)\n",
        "pred_cms = get_cm(pred_clust)\n",
        "md_mis = get_mom_inertia(md_cms,md_clust)\n",
        "pred_mis = get_mom_inertia(pred_cms,pred_clust) \n"
      ],
      "metadata": {
        "id": "EzOSEJbnjDg0"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "md_fig = plot_clusters(md_clust)\n",
        "md_fig.show()"
      ],
      "metadata": {
        "id": "UAB_vQW5kfbC",
        "outputId": "7220b9f3-828b-4cc7-f234-55c59f0dcbc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"1e33db00-38f0-4a47-9b09-4bd9b090932c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1e33db00-38f0-4a47-9b09-4bd9b090932c\")) {                    Plotly.newPlot(                        \"1e33db00-38f0-4a47-9b09-4bd9b090932c\",                        [{\"hovertemplate\":\"Cluster ID: %{marker.color:.2f}<extra></extra>\",\"marker\":{\"color\":[21,13,13,13,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,7,7,19,9,9,10,13,13,13,13,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,2,11,11,2,25,9,14,10,13,13,13,27,11,11,11,11,11,11,11,11,2,2,2,5,2,2,17,17,17,17,17,17,9,10,27,27,27,27,11,27,11,2,2,2,5,2,5,5,17,17,17,17,17,17,27,27,27,27,11,2,2,2,17,17,8,17,17,17,17,17,17,11,11,8,8,8,8,8,8,17,8,8,17,8,8,11,11,8,8,8,8,8,8,8,8,8,8,8,8,8,8,11,11,8,8,8,1,8,8,22,8,8,8,8,8,8,8,11,11,11,4,4,4,4,4,11,11,1,8,8,11,11,11,4,4,4,4,4,4,4,4,11,0,11,4,11,11,4,4,11,11,4,4,4,4,4,11,11,0,0,0,0,0,0,3,3,16,11,11,11,11,4,11,11,4,4,11,11,11,4,4,11,11,11,11,4,11,11,11,11,11,24,11,11,11,4,4,24,24,11,11,11,11,11,11,6,0,0,0,0,0,3,3,3,3,11,11,4,11,11,11,4,4,11,11,11,4,4,11,11,11,11,4,4,11,11,11,11,11,11,11,11,11,24,24,11,11,11,11,11,24,24,24,11,11,11,11,11,11,11,11,11,11,11,11,11,11,6,6,26,0,0,3,3,3,12,12,3,4,11,11,4,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,24,24,11,11,11,11,11,24,24,24,11,11,11,11,11,24,24,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,6,6,26,26,20,26,26,18,18,3,18,12,12,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,24,24,24,11,11,11,11,11,24,24,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,15,26,20,26,20,18,18,12,12,18,18,18,18,18,12,12,11,11,11,11,11,24,11,11,11,11,24,24,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,23,26,26,26,18,18,18,12,12,12],\"symbol\":\"square\"},\"mode\":\"markers\",\"x\":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16],\"y\":[3,4,4,5,6,7,8,8,8,8,9,9,9,9,9,9,10,10,10,10,10,10,11,11,11,11,11,12,12,12,12,12,13,13,13,14,16,17,24,32,32,2,3,4,4,5,9,9,9,9,10,10,10,10,10,10,11,11,11,11,11,12,12,12,12,13,13,13,14,30,32,32,2,4,4,4,10,10,10,11,11,11,12,12,12,13,13,13,13,14,14,25,25,26,26,27,27,32,2,9,9,10,10,10,11,11,13,13,13,13,14,14,14,25,25,26,26,26,27,9,10,10,10,10,13,13,14,24,24,25,25,25,25,26,26,26,10,11,23,23,24,24,25,25,25,26,26,26,27,28,11,12,22,23,23,24,24,25,25,25,26,26,27,27,28,29,3,11,22,23,23,23,24,24,24,25,26,26,27,27,28,29,3,3,4,7,7,8,8,8,10,10,24,27,28,4,5,5,6,7,7,8,8,8,8,8,10,27,3,4,4,4,5,5,5,5,6,7,7,8,8,9,10,25,26,26,26,27,27,31,31,32,1,1,2,2,3,3,3,4,4,4,4,4,5,5,5,5,5,5,6,6,6,6,6,6,7,7,7,7,8,8,8,8,8,9,10,10,11,11,18,26,26,27,27,27,31,31,31,32,1,1,2,2,2,2,3,3,3,3,3,4,4,4,4,4,4,5,5,5,5,5,5,6,6,6,6,6,7,7,7,7,7,7,7,8,8,8,8,8,8,9,9,9,9,10,10,10,11,11,11,12,17,18,24,26,26,30,31,31,32,32,32,2,2,2,3,3,3,3,4,4,4,5,5,5,5,6,6,6,6,6,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,10,10,10,10,11,11,11,11,12,12,12,12,13,17,18,24,24,25,25,25,31,31,31,32,32,32,3,3,4,4,5,5,5,6,6,6,6,7,7,7,7,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,10,10,10,10,10,11,11,11,11,11,12,12,12,12,13,13,13,21,24,25,25,26,31,31,31,31,32,32,32,32,32,32,32,3,4,5,6,6,7,7,7,7,7,8,8,8,8,8,8,9,9,9,9,9,9,10,10,10,10,10,10,11,11,11,11,11,12,12,12,12,12,13,13,13,14,14,16,24,25,25,31,32,32,32,32,32],\"z\":[30,14,15,14,30,30,29,30,31,32,27,28,29,30,31,32,27,28,29,30,31,32,27,28,29,30,31,27,28,29,30,31,27,28,29,27,26,26,13,9,10,7,14,14,15,14,27,28,31,32,27,28,29,30,31,32,27,28,29,30,31,27,28,29,30,8,27,28,10,17,9,13,7,13,14,15,19,27,28,27,28,29,27,28,29,8,9,10,18,10,11,29,30,28,29,28,29,9,7,18,19,18,19,27,19,27,9,10,11,19,11,18,19,29,30,28,29,30,29,19,18,19,20,27,10,11,12,29,30,1,28,29,30,28,29,30,27,26,2,3,2,3,1,2,29,1,2,29,1,1,26,25,3,2,3,2,3,1,2,3,1,2,1,2,1,1,31,26,3,2,3,23,2,3,25,2,1,2,1,2,1,1,30,31,30,6,7,7,9,10,26,27,23,1,1,30,30,31,6,6,7,6,7,8,9,10,27,20,29,5,29,30,5,6,30,31,6,6,7,7,11,27,27,21,20,21,22,19,21,27,28,10,28,29,27,28,5,28,29,5,6,28,29,30,5,6,29,30,31,32,6,28,29,30,31,32,23,28,29,30,11,12,23,24,28,28,27,28,27,28,9,21,22,19,20,21,27,28,29,28,28,29,5,27,28,29,5,6,27,28,29,5,6,27,28,29,30,5,6,28,29,30,31,28,29,30,31,32,23,24,28,29,30,31,32,22,23,24,28,29,30,26,27,28,29,27,28,29,27,28,29,28,9,9,13,21,22,28,28,29,10,11,29,6,28,29,6,28,29,30,28,29,30,28,29,30,31,28,29,30,31,32,23,24,28,29,30,31,32,22,23,24,28,29,30,31,32,23,24,27,28,29,30,31,27,28,29,30,27,28,29,30,27,28,29,30,28,9,9,13,14,10,12,13,5,6,29,4,10,11,29,30,29,30,29,30,31,29,30,31,32,29,30,31,32,22,23,24,28,29,30,31,32,23,24,27,28,29,30,31,32,27,28,29,30,31,27,28,29,30,31,27,28,29,30,27,28,29,31,14,10,13,10,5,6,10,11,1,2,3,4,5,10,11,30,30,30,30,31,22,29,30,31,32,22,23,29,30,31,32,27,28,29,30,31,32,27,28,29,30,31,32,27,28,29,30,31,27,28,29,30,31,27,28,29,27,28,1,14,13,14,6,1,2,10,11,12],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1e33db00-38f0-4a47-9b09-4bd9b090932c');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_fig = plot_clusters(pred_clust)\n",
        "pred_fig.show()"
      ],
      "metadata": {
        "id": "UePKih3V3s9v",
        "outputId": "c77d4754-6ccb-4aff-88dc-e9f7665e7635",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"2dad26ff-ead8-40f1-9cff-bd68236b5626\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2dad26ff-ead8-40f1-9cff-bd68236b5626\")) {                    Plotly.newPlot(                        \"2dad26ff-ead8-40f1-9cff-bd68236b5626\",                        [{\"hovertemplate\":\"Cluster ID: %{marker.color:.2f}<extra></extra>\",\"marker\":{\"color\":[14,25,25,25,26,26,16,26,26,26,16,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,15,15,9,9,15,15,9,9,15,15,15,2,4,4,4,4,4,4,4,4,4,14,14,14,14,25,25,25,25,25,26,26,26,26,26,26,26,26,26,26,26,26,19,26,26,26,26,26,19,26,26,26,13,19,26,15,15,2,2,3,3,4,4,4,4,4,4,14,14,14,14,14,25,25,25,25,25,26,26,26,26,19,26,26,13,19,26,13,13,13,13,19,13,13,0,0,0,0,0,4,14,14,19,26,19,19,26,19,19,26,13,13,13,13,13,19,13,13,19,19,19,0,0,0,0,0,0,0,0,19,19,19,19,26,13,13,13,13,6,6,6,0,6,6,0,0,0,0,0,0,6,0,6,6,6,6,6,0,6,6,6,6,6,6,6,6,6,12,12,12,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,12,12,20,20,20,12,12,12,12,12,6,6,6,6,6,6,6,6,6,6,6,6,12,12,12,20,20,20,20,20,20,12,12,11,6,11,12,12,12,20,12,12,20,20,20,20,20,20,20,12,12,12,18,18,11,11,11,11,12,20,20,12,12,20,20,12,12,20,20,12,12,20,12,12,12,12,18,11,11,11,11,11,11,11,11,7,5,5,12,12,12,12,20,20,12,12,12,20,20,12,12,12,20,20,12,12,12,12,20,20,12,12,12,12,23,12,12,23,12,12,12,12,12,12,12,12,12,12,12,8,8,11,11,11,11,11,11,11,5,5,5,5,7,7,5,5,5,5,5,5,20,12,12,20,20,12,12,20,20,12,12,12,12,20,20,12,12,12,12,20,20,12,12,12,12,12,12,12,12,12,12,23,23,23,12,12,12,12,12,23,23,23,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,8,8,17,11,11,11,11,5,5,5,5,7,7,5,5,7,5,5,20,12,12,20,12,12,20,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,23,23,23,12,12,12,12,12,23,23,23,12,12,12,12,12,23,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,24,24,8,8,21,17,17,10,10,17,22,22,22,22,22,22,7,7,22,22,22,22,22,7,7,5,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,23,23,23,12,12,12,12,12,23,23,23,12,12,12,12,12,23,23,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,1,1,24,24,24,1,1,24,24,21,10,10,17,17,10,10,17,10,10,22,22,22,22,22,22,22,22,22,7,7,7,22,22,22,22,7,7,12,12,12,12,12,12,12,12,12,12,12,23,23,12,12,12,12,12,23,23,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,24,24,1,1,24,24,24,24,1,1,24,24,24,17,10,10,17,22,22,7,7,7,7,7,7,7],\"symbol\":\"square\"},\"mode\":\"markers\",\"x\":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16],\"y\":[2,4,4,5,5,6,7,7,7,7,8,8,8,8,8,8,9,9,9,9,9,9,10,10,10,10,10,10,11,11,11,11,11,12,12,12,12,13,13,13,15,15,16,16,16,16,17,17,17,17,17,24,31,31,31,31,31,32,32,32,32,1,1,2,2,3,3,4,4,5,8,8,9,9,9,9,9,10,10,10,10,10,11,11,11,11,11,11,12,12,12,12,13,13,13,16,17,24,24,30,30,31,31,32,32,32,32,1,1,2,2,3,3,3,4,4,5,9,9,10,10,11,11,11,12,12,12,13,13,13,13,13,14,14,25,25,26,26,27,32,2,2,9,9,10,10,10,11,11,11,12,12,13,13,13,13,14,14,14,14,15,24,25,25,25,26,26,26,27,9,9,10,10,10,13,13,14,14,23,24,24,24,25,25,25,25,25,26,26,26,27,27,23,23,24,24,24,24,25,25,25,26,26,26,27,27,28,11,12,13,21,21,22,22,23,23,24,24,25,25,25,26,26,26,26,26,26,27,27,27,27,27,28,3,4,7,8,8,10,11,11,12,13,21,21,23,23,24,25,25,26,26,27,27,28,3,4,4,7,7,7,8,8,8,10,11,26,27,27,3,4,4,5,5,5,6,7,7,8,8,8,8,9,10,10,20,20,25,26,26,27,3,4,4,4,4,5,5,5,5,6,6,6,6,7,9,9,10,10,20,25,25,25,26,26,26,27,27,31,31,31,1,1,2,2,3,3,3,3,3,4,4,4,4,4,5,5,5,5,5,5,6,6,6,6,6,6,7,7,7,8,8,8,9,9,9,9,10,10,10,11,11,17,18,25,25,26,26,26,27,27,29,30,30,30,31,31,31,31,31,32,32,32,1,1,1,2,2,2,2,3,3,3,3,3,3,4,4,4,4,4,4,5,5,5,5,5,5,5,6,6,6,6,6,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,9,9,9,9,10,10,10,10,11,11,11,11,12,17,18,24,25,25,26,26,29,29,30,30,31,31,31,31,32,32,32,1,1,1,2,2,2,3,3,3,3,3,3,4,4,4,4,5,5,5,5,5,6,6,6,6,6,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,10,10,10,10,10,11,11,11,11,11,12,12,12,12,13,16,16,17,18,21,24,24,25,25,25,31,31,31,31,31,31,31,31,32,32,32,32,32,32,32,32,1,2,2,3,3,3,3,4,4,4,5,5,5,5,5,6,6,6,6,6,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,10,10,10,10,10,11,11,11,11,11,12,12,12,12,13,13,13,16,16,16,16,16,17,17,17,17,21,24,24,24,24,25,25,25,26,26,30,30,30,31,31,31,31,31,31,31,31,31,32,32,32,32,32,32,2,3,3,4,4,5,5,5,6,6,6,7,7,7,7,7,7,7,8,8,8,8,8,8,8,9,9,9,9,9,9,10,10,10,10,10,10,11,11,11,11,11,12,12,12,12,13,13,13,15,15,16,16,16,16,16,16,17,17,17,17,17,24,25,25,25,31,31,31,31,31,31,32,32,32],\"z\":[7,14,15,14,30,30,22,29,30,31,22,28,29,30,31,32,27,28,29,30,31,32,27,28,29,30,31,32,27,28,29,30,31,27,28,29,30,27,28,29,26,27,1,2,26,27,1,2,25,26,27,14,9,10,11,12,13,9,10,11,12,8,9,7,8,14,15,14,15,14,28,29,27,28,29,30,32,27,28,29,30,31,18,27,28,29,30,31,18,27,28,29,10,18,28,26,26,13,14,16,17,9,13,9,10,11,12,8,9,7,8,8,14,15,14,15,14,27,28,27,28,18,27,28,10,18,28,8,9,10,11,18,10,11,28,29,28,29,29,12,7,8,19,27,18,19,27,18,19,27,9,10,9,10,11,18,11,12,18,19,19,29,28,29,30,28,29,30,29,18,19,18,19,27,10,11,11,12,2,1,2,29,1,2,28,29,30,28,29,30,1,29,2,3,1,2,3,29,1,2,3,1,2,6,1,2,1,26,25,25,2,3,2,3,2,3,2,3,1,2,3,1,2,3,4,5,6,1,2,3,5,6,1,30,30,9,9,10,26,25,26,25,25,2,3,2,3,2,1,2,1,2,1,2,1,30,30,31,7,8,9,8,9,10,26,26,19,1,19,30,30,31,6,30,31,6,6,7,7,8,9,10,26,26,27,13,14,21,19,20,19,29,5,6,29,30,5,6,29,30,5,6,29,30,6,26,27,26,27,14,20,21,22,19,20,21,19,20,10,27,28,28,29,28,29,5,6,28,29,30,5,6,28,29,30,5,6,28,29,30,31,5,6,28,29,30,31,23,28,29,23,28,29,26,27,28,29,26,27,28,27,28,9,9,21,22,20,21,22,20,21,27,27,28,29,10,11,27,28,29,27,28,29,5,28,29,5,6,28,29,5,6,27,28,29,30,5,6,27,28,29,30,5,6,28,29,30,31,32,28,29,30,31,32,22,23,24,28,29,30,31,32,22,23,24,28,29,30,32,27,28,29,30,27,28,29,30,27,28,29,30,28,9,9,13,21,22,21,22,27,28,28,29,10,11,28,29,11,28,29,6,28,29,6,28,29,6,27,28,29,30,31,28,29,30,31,28,29,30,31,32,28,29,30,31,32,22,23,24,28,29,30,31,32,22,23,24,28,29,30,31,32,23,27,28,29,30,31,32,27,28,29,30,31,27,28,29,30,31,27,28,29,30,28,25,26,9,9,31,13,14,9,10,13,1,2,3,4,5,6,10,11,2,3,4,5,6,10,11,29,29,29,30,28,29,30,31,29,30,31,28,29,30,31,32,28,29,30,31,32,22,23,24,28,29,30,31,32,22,23,24,28,29,30,31,32,23,24,27,28,29,30,31,32,27,28,29,30,31,27,28,29,30,31,27,28,29,30,27,28,29,1,2,25,26,27,1,2,25,26,31,9,10,13,14,9,10,13,9,10,2,5,6,1,2,3,4,5,6,10,11,12,2,3,5,6,10,11,30,29,30,29,30,29,30,31,29,30,31,22,23,28,29,30,31,32,22,23,28,29,30,31,32,27,28,29,30,31,32,27,28,29,30,31,32,27,28,29,30,31,27,28,29,30,27,28,29,26,27,1,2,25,26,27,28,1,2,25,26,27,14,9,10,13,2,6,9,10,11,12,9,10,11],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('2dad26ff-ead8-40f1-9cff-bd68236b5626');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "md_fig = go.Scatter(x=md_vols,y=md_Tmean,error_y=dict(type='data', array=md_Tstd,visible=True),mode='markers',marker=dict(symbol='square',color='Blue',size=10),name='MD')\n",
        "pred_fig = go.Scatter(x=pred_vols,y=pred_Tmean,error_y=dict(type='data', array=pred_Tstd,visible=True),mode='markers',marker=dict(symbol='square',color='Red',size=10),name='CNN')\n",
        "t_Fig = go.Figure(md_fig)\n",
        "t_Fig.add_trace(pred_fig)\n",
        "t_Fig.show()"
      ],
      "metadata": {
        "id": "K_CyhLUgmHQe",
        "outputId": "735e5a87-ec43-46f9-e21f-85954c365883",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"7d3465b3-5731-4301-8602-849c67fc5575\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7d3465b3-5731-4301-8602-849c67fc5575\")) {                    Plotly.newPlot(                        \"7d3465b3-5731-4301-8602-849c67fc5575\",                        [{\"error_y\":{\"array\":[84.13416330298816,28.604999999999905,85.81043377939633,109.26596906948755,127.49521930204031,25.041814406108845,173.9632098347234,3.769999999999982,226.50169392454956,10.942035916592548,60.03065383618613,666.9314882943105,134.5083132458043,124.94784670413495,0.0,0.0,0.0,178.610511687668,130.5514996888428,0.0,20.968742345585586,0.0,0.0,0.0,239.41487609277323,0.0,136.4682332119824,121.82810203315162],\"type\":\"data\",\"visible\":true},\"marker\":{\"color\":\"Blue\",\"size\":10,\"symbol\":\"square\"},\"mode\":\"markers\",\"name\":\"MD\",\"x\":[56,8,56,44,152,16,20,8,156,16,12,1124,44,40,4,4,4,88,52,4,12,4,4,4,92,4,40,40],\"y\":[1939.2171428571432,1862.7649999999999,1886.9221428571432,1950.1418181818183,1972.1115789473681,1833.9625,2066.5879999999997,1834.02,2111.779230769231,1940.5200000000002,1883.5199999999998,2574.1470462633456,1987.7563636363639,1952.7679999999996,2071.0,1800.29,1981.5,2015.453181818182,1993.8753846153847,1871.49,1916.8633333333335,1882.22,1848.13,1814.87,2104.9152173913044,1860.46,1988.968,1908.655],\"type\":\"scatter\"},{\"error_y\":{\"array\":[233.2583770751953,107.54949188232422,82.79219055175781,10.80950927734375,71.16043853759766,112.46913146972656,221.75071716308594,121.16593933105469,123.36026763916016,62.01624298095703,121.798583984375,112.64647674560547,569.1188354492188,168.48422241210938,129.1612091064453,159.95822143554688,33.87567138671875,76.32498931884766,95.85001373291016,104.28535461425781,162.270751953125,15.77685546875,148.8726348876953,224.25958251953125,200.4918212890625,170.63760375976562,426.48883056640625],\"type\":\"data\",\"visible\":true},\"marker\":{\"color\":\"Red\",\"size\":10,\"symbol\":\"square\"},\"mode\":\"markers\",\"name\":\"CNN\",\"x\":[88,32,12,8,64,84,224,88,24,16,40,100,1044,76,48,36,8,36,12,76,176,8,104,108,64,52,264],\"y\":[2114.58740234375,2003.9451904296875,1934.72998046875,1826.050048828125,1935.982177734375,1976.960693359375,2094.41259765625,2034.2550048828125,1981.7872314453125,1924.4840087890625,2018.0697021484375,1996.9686279296875,2467.657958984375,2024.6141357421875,1957.4267578125,2007.2374267578125,1875.254150390625,1920.4791259765625,1951.9534912109375,1955.1031494140625,2035.6729736328125,1823.2823486328125,1999.205810546875,2070.638916015625,2046.2890625,2049.64208984375,2410.87451171875],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('7d3465b3-5731-4301-8602-849c67fc5575');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "overlap = []\n",
        "for i in range(md_clust['Cluster ID'].max()+1):\n",
        "  for j in range(pred_clust['Cluster ID'].max()+1):\n",
        "    md_tmp = md_clust[md_clust['Cluster ID'] == i]\n",
        "    pred_tmp = pred_clust[pred_clust['Cluster ID'] == j]\n",
        "    counts = 0\n",
        "    for k in range(len(md_tmp)):\n",
        "      for l in range(k,len(pred_tmp)):\n",
        "        if (md_tmp[['X','Y','Z']].values[k] == pred_tmp[['X','Y','Z']].values[l]).all():\n",
        "          counts += 1\n",
        "    if counts > 0:\n",
        "      overlap.append([i,j,counts/len(md_tmp)])"
      ],
      "metadata": {
        "id": "A1HSJfRUpyGK"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "over_array = np.array(overlap)"
      ],
      "metadata": {
        "id": "3ARQEyc83iC2"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "md_correct = md_clust[md_clust['Cluster ID'].isin(over_array[:,0].tolist())].reset_index(drop=True)\n",
        "pred_correct = pred_clust[pred_clust['Cluster ID'].isin(over_array[:,1].tolist())].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "xZjoYGJaz_Ir"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_id = []\n",
        "for i in range(len(pred_correct)):\n",
        "  for j in range(len(over_array)):\n",
        "    if pred_correct['Cluster ID'][i] == over_array[j,1]:\n",
        "      new_id.append(over_array[j,0])\n",
        "\n",
        "pred_correct['New ID'] = new_id\n",
        "pred_correct"
      ],
      "metadata": {
        "id": "Nc3qdYFgzaaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(new_id)"
      ],
      "metadata": {
        "id": "7rll7ER19PS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_correct"
      ],
      "metadata": {
        "id": "CkGYxckbBHF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mi = go.Scatter(x=md_mis, y=pred_mis,mode='markers',marker=dict(symbol='square',color='Blue',size=10))\n",
        "mi_fig = go.Figure(mi)\n",
        "mi_fig.show()"
      ],
      "metadata": {
        "id": "YYw6n0izpIAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploration GUI  (Under development)"
      ],
      "metadata": {
        "id": "8GgptMfOlBs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FUNCTIONS TO OBSERVE\n",
        "def populate_sliders(change):\n",
        "\n",
        "  with output_plot:\n",
        "    clear_output()\n",
        "  \n",
        "  example_label = np.load(main_dropdown.value + \"/output.npy\").squeeze() / 1000\n",
        "  example_pred = np.load('results/'+main_dropdown.value+\"/prediction.npy\").squeeze()\n",
        "\n",
        "  md_tmp_slider.min = np.min(example_label)\n",
        "  md_tmp_slider.max = np.max(example_label)\n",
        "  md_tmp_slider.value = [np.min(example_label), np.max(example_label)]\n",
        "\n",
        "  pred_tmp_slider.min = np.min(example_pred)\n",
        "  pred_tmp_slider.max = np.max(example_pred)\n",
        "  pred_tmp_slider.value = [np.min(example_pred), np.max(example_pred)]\n",
        "\n",
        "def display_fullplot(change):\n",
        "\n",
        "  with output_plot:\n",
        "    clear_output()\n",
        "\n",
        "  example_inp = np.load(main_dropdown.value + \"/input.npy\").squeeze()\n",
        "  example_inp = example_inp[:, 1:-1, 1:-1] # NON PERIODIC GETS PLOTTED\n",
        "  example_label = np.load(main_dropdown.value + \"/output.npy\").squeeze() / 1000\n",
        "  example_pred = np.load('results/'+main_dropdown.value+\"/prediction.npy\").squeeze()\n",
        "\n",
        "  example_fig = datapoint_results_print(example_inp, example_label, example_pred)\n",
        "  example_fig = go.FigureWidget(example_fig)\n",
        "\n",
        "  if toggle_button.value == \"MD\":\n",
        "\n",
        "    map = np.where(np.logical_and(example_label >=md_tmp_slider.value[0], example_label <=md_tmp_slider.value[1]), 8, 0)\n",
        "    with example_fig.batch_update():\n",
        "      example_fig.data[0].marker.size = map.flatten()\n",
        "      example_fig.data[1].marker.size = map.flatten()\n",
        "      example_fig.data[2].marker.size = map.flatten()\n",
        "      example_fig.data[3].marker.size = map.flatten()\n",
        "      example_fig.data[4].marker.size = map.flatten()\n",
        "\n",
        "  elif toggle_button.value == \"Pred\":\n",
        "\n",
        "    map = np.where(np.logical_and(example_pred>=pred_tmp_slider.value[0],example_pred<=pred_tmp_slider.value[1]), 8, 0)\n",
        "    with example_fig.batch_update():\n",
        "      example_fig.data[0].marker.size = map.flatten()\n",
        "      example_fig.data[1].marker.size = map.flatten()\n",
        "      example_fig.data[2].marker.size = map.flatten()\n",
        "      example_fig.data[3].marker.size = map.flatten()\n",
        "      example_fig.data[4].marker.size = map.flatten()\n",
        "\n",
        "  with output_plot:\n",
        "    example_fig.show()\n",
        "\n",
        "def slider_function(b):\n",
        "  md_tmp_slider.disabled = (toggle_button.value == 'Pred')\n",
        "  pred_tmp_slider.disabled = (toggle_button.value == 'MD')\n",
        "\n",
        "# GETTING LABELS FOR SYSTEMS\n",
        "systems = [x[0] for x in os.walk('results')]\n",
        "systems.remove('results')\n",
        "systems.remove('results/train')\n",
        "systems.remove('results/validation')\n",
        "systems = sorted(['/'.join(x.split('/')[1:]) for x in systems])\n",
        "\n",
        "# WIDGETS\n",
        "main_dropdown = widgets.Dropdown(options=systems, description = \"System: \", continuous_update=False)\n",
        "toggle_button = widgets.ToggleButtons(options=['MD', 'Pred'], description='Filter by:', button_style='')\n",
        "md_tmp_slider = widgets.FloatRangeSlider(value=[0, 1], min=0, max=1, description='MD Temp:', disabled=False, continuous_update=False)\n",
        "pred_tmp_slider = widgets.FloatRangeSlider(value=[0, 1], min=0, max=1, description='CNN Temp:', disabled=True, continuous_update=False)\n",
        "generate_button = widgets.Button(description='Generate', button_style='success', icon='fa-hand-pointer-o')\n",
        "\n",
        "output_plot = widgets.Output()\n",
        "\n",
        "# OBSERVERS\n",
        "main_dropdown.observe(populate_sliders, names='value')\n",
        "toggle_button.observe(slider_function)\n",
        "generate_button.on_click(display_fullplot)\n",
        "\n",
        "controls_box =widgets.VBox([main_dropdown, toggle_button, md_tmp_slider, pred_tmp_slider, generate_button], layout=widgets.Layout(width='100%', display='flex', flex_flow='column', align_items='flex-start'))\n",
        "frame_box = widgets.HBox([controls_box, output_plot])\n",
        "\n",
        "display(frame_box)"
      ],
      "metadata": {
        "id": "-sPms_uLlel7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ru-M1kbxIO5a"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "pbx-local",
      "language": "python",
      "name": "pbx-local"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "f806901b044f1f905f6f73d9d34ac86b2be2e087ac41c051b6f31285dd315984"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}