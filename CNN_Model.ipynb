{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jverduzc/CNN_PBX_Model/blob/master/CNN_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Networks (CNN) for prediction of hotspots on PBX\n",
        "\n",
        "In this notebook we create a CNN model with a U-Net architecture for the prediction of temperature for a plastically bonded explosive molecular dynamics simulation."
      ],
      "metadata": {
        "id": "4QfRMy9VFrcW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries\n",
        "\n",
        "First, we need to set up libraries that are not part of the default environment in Google Colab. In our case, this is only the rendering library ```kaleido```.\n",
        "\n",
        "You will need to restart the runtime to update the kernel.\n",
        "- Menu Runtime -> Restart Runtime"
      ],
      "metadata": {
        "id": "C2UgThuCGG3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaleido"
      ],
      "metadata": {
        "id": "M79B0dH7ftZW",
        "outputId": "0440ba7d-1ce4-48e4-82d3-e7031cb8b159",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaleido in /usr/local/lib/python3.7/dist-packages (0.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will then import the required libraries for our notebook to run. The following cells import:\n",
        "- Standard python libraries\n",
        "- Plotting libraries\n",
        "- Machine learning libraries (tensorflow / keras)"
      ],
      "metadata": {
        "id": "2ECMQghLGzUA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5Nd2jeT8r8uu"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import clear_output\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "qrgVqntVG6YP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "V08TFba6G_nw"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import initializers\n",
        "from keras.layers import Input, Dropout, BatchNormalization, Conv3DTranspose, concatenate, Dense, Conv3D, Flatten, MaxPooling3D\n",
        "from keras.models import Sequential\n",
        "import keras.backend as K\n",
        "tf.keras.utils.set_random_seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to verify that we are running an enviroment with a GPU in Colab. The next cell shows if you have a GPU front-end execution host allocated to the notebook. \n",
        "\n",
        "<font color='red'><b>Warning:</b></font> If you don't have one, you'll need to re-run the previous cells after going to:\n",
        "- Menu Runtime -> Change runtime type -> Hardware accelerator"
      ],
      "metadata": {
        "id": "Wh5PkIn3H9dD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KnH0b5QqG_ny",
        "outputId": "f5c89886-be34-4fbd-c9e3-7e649652449b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data\n",
        "\n",
        "After setting up the environment, we need the repository files to create the model and access the training/validation data. \n",
        "\n",
        "<font color='orange'><b>Attention:</b></font> This is not trivial in Colab, but to access a private repository on Github like this, you need to provide Colab with your Github Key. You can get that key here: https://github.com/settings/tokens\n",
        "\n",
        "After that, you need to execute a command with this syntax:\n",
        "```\n",
        "!git clone https://username:github_key@github.com/Jverduzc/CNN_PBX_Model.git\n",
        "```\n",
        "You can fill up the blanks in the following cell. We will also change the current working directory. You should see the a new directory in your directory tree (on your left) with the files on the repository.\n"
      ],
      "metadata": {
        "id": "hYseV3r9LkME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone XXXXXXX\n",
        "os.chdir(\"CNN_PBX_Model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cr1dF6TJHU2J",
        "outputId": "819583a6-5803-42d4-d0df-c7f62466fa22"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CNN_PBX_Model'...\n",
            "remote: Enumerating objects: 514, done.\u001b[K\n",
            "remote: Counting objects: 100% (514/514), done.\u001b[K\n",
            "remote: Compressing objects: 100% (328/328), done.\u001b[K\n",
            "remote: Total 514 (delta 230), reused 443 (delta 185), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (514/514), 23.85 MiB | 9.69 MiB/s, done.\n",
            "Resolving deltas: 100% (230/230), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and validation data\n",
        "\n",
        "This notebook was designed to read everything in the ```/train/``` folder as training data and everything in the ```/validation/``` folder as validation data. These directories contain individual labeled subdirectories that represent each of our simulation systems (data points).\n",
        "\n",
        "In each of the simulation systems subdirectories there are two files as numpy arrays: ```input.npy``` and ```output.npy```.\n",
        "\n",
        "\n",
        "```input.npy``` contains a (16 x 34 x 34 x 3) array with the input mappings from our simulations. The first three numbers represent the dimensions (in bins) of our system. The last number represents the number of mappings for our inputs. For each of our 3D structures, we generate the following:\n",
        "- Total density\n",
        "- HE density\n",
        "- GB interface parameter\n",
        "\n",
        "```output.npy``` contains a (16 x 32 x 32 x 1) array with the output mapping (temperature) from our simulations. The first three numbers represent the dimensions (in bins) of our system, but note that they are different from the inputs due to periodic boundary conditions. The last number represents the temperature mapping. \n",
        "- Temperature\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B2wbmJTjOpoe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please verify that after running the next cells you get the following results:\n",
        "\n",
        "<b>Training data:</b><br>\n",
        "\n",
        "(64, 16, 34, 34, 3) <br>\n",
        "(64, 16, 32, 32, 1) <br>\n",
        "\n",
        "<b>Validation data:</b><br>\n",
        "\n",
        "(28, 16, 34, 34, 3) <br>\n",
        "(28, 16, 32, 32, 1) <br>\n",
        "\n",
        "You can see that there is a new number in these arrays. It indicates the number of datapoints in each set. You can read this as having 64 points with (16 x 34 x 34 x 3) shape."
      ],
      "metadata": {
        "id": "ogxA0zxHRUIl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KZxqA1mmG_nz",
        "outputId": "3aa99001-e56f-4446-fe99-db610bcb72f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 16, 34, 34, 3)\n",
            "(64, 16, 32, 32, 1)\n"
          ]
        }
      ],
      "source": [
        "# TRAINING DATA\n",
        "\n",
        "paths = [x[0] for x in os.walk('train/')][1:]\n",
        "\n",
        "train_data = []\n",
        "train_labels = []\n",
        "\n",
        "for i in paths:\n",
        "  train_ex = np.load(i + \"/input.npy\")\n",
        "\n",
        "  if train_ex.shape != (16,34,34,3):\n",
        "\n",
        "    first_axis_pad = int(0.5 * (34 - train_ex.shape[1]))\n",
        "    second_axis_pad = int(0.5 * (34 - train_ex.shape[2]))\n",
        "\n",
        "    train_ex = np.pad(train_ex, ((0, 0), (first_axis_pad, first_axis_pad), (second_axis_pad, second_axis_pad), (0,0)), 'wrap')\n",
        "\n",
        "  train_lb = np.load(i + \"/output.npy\")\n",
        "  train_data.append(train_ex)\n",
        "  train_labels.append(train_lb)\n",
        "\n",
        "train_data = np.array(train_data)\n",
        "train_labels = np.array(train_labels) / 1000\n",
        "\n",
        "print(train_data.shape)\n",
        "print(train_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "02ORxH_vZNOC",
        "outputId": "43f3416d-88ff-443f-c017-099aaaa46635",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 16, 34, 34, 3)\n",
            "(28, 16, 32, 32, 1)\n"
          ]
        }
      ],
      "source": [
        "# VALIDATION DATA\n",
        "\n",
        "validation_paths = [x[0] for x in os.walk('validation/')][1:]\n",
        "\n",
        "validation_data = []\n",
        "validation_labels = []\n",
        "\n",
        "for i in validation_paths:\n",
        "  validation_ex= np.load(i + \"/input.npy\")\n",
        "\n",
        "  if validation_ex.shape != (16,34,34,1):\n",
        "\n",
        "    first_axis_pad = int(0.5 * (34 - validation_ex.shape[1]))\n",
        "    second_axis_pad = int(0.5 * (34 - validation_ex.shape[2]))\n",
        "\n",
        "    validation_ex = np.pad(validation_ex, ((0, 0), (first_axis_pad, first_axis_pad), (second_axis_pad, second_axis_pad), (0,0)), 'wrap')\n",
        "\n",
        "\n",
        "  validation_lb = np.load(i + \"/output.npy\")\n",
        "  validation_data.append(validation_ex)\n",
        "  validation_labels.append(validation_lb)\n",
        "\n",
        "validation_data = np.array(validation_data)\n",
        "validation_labels = np.array(validation_labels) / 1000\n",
        "\n",
        "print(validation_data.shape)\n",
        "print(validation_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "xQrUeLx5R1mp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWvLsqQXsWGy"
      },
      "outputs": [],
      "source": [
        "def periodic_padding_flexible(tensor, axis, padding=1):\n",
        "\n",
        "    if isinstance(axis,int):\n",
        "        axis = (axis,)\n",
        "    if isinstance(padding,int):\n",
        "        padding = (padding,)\n",
        "\n",
        "    ndim = len(tensor.shape)\n",
        "\n",
        "    for ax,p in zip(axis,padding):\n",
        "        # create a slice object that selects everything from all axes,\n",
        "        # except only 0:p for the specified for right, and -p: for left\n",
        "\n",
        "        ind_right = [slice(-p,None) if i == ax else slice(None) for i in range(ndim)]\n",
        "        ind_left = [slice(0, p) if i == ax else slice(None) for i in range(ndim)]\n",
        "        right = tensor[ind_right]\n",
        "        left = tensor[ind_left]\n",
        "        middle = tensor\n",
        "        tensor = tf.concat([right,middle,left], axis=ax)\n",
        "\n",
        "    return tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLhZ3NIocWJ9"
      },
      "outputs": [],
      "source": [
        "def DownConvBlock(inputs, n_filters=32, filter_size = 3, max_pooling=True, special_padding=False):\n",
        "\n",
        "  padding_size = int((filter_size-1)/2)\n",
        "  kernel_init =   tf.keras.initializers.GlorotUniform(seed=0)\n",
        "  bias_init = tf.keras.initializers.Zeros()\n",
        "\n",
        "\n",
        "  # PERIODIC PADDING\n",
        "\n",
        "  inputs = periodic_padding_flexible(inputs, axis=1,padding=padding_size)\n",
        "  if special_padding == False:\n",
        "    inputs = periodic_padding_flexible(inputs, axis=2,padding=padding_size)\n",
        "    inputs = periodic_padding_flexible(inputs, axis=3,padding=padding_size)\n",
        "  \n",
        "  conv = Conv3D(n_filters, filter_size, activation='relu', padding='valid', kernel_initializer=kernel_init, bias_initializer=bias_init)(inputs)\n",
        "  print(conv.shape)\n",
        "  conv = periodic_padding_flexible(conv, axis=(1,2,3),padding=(padding_size,padding_size,padding_size))\n",
        "  conv = Conv3D(n_filters, filter_size, activation='relu', padding='valid', kernel_initializer=kernel_init, bias_initializer=bias_init)(conv)\n",
        "  print(conv.shape)\n",
        "  conv = BatchNormalization()(conv, training=False)\n",
        "      \n",
        "  if max_pooling:\n",
        "    next_layer = tf.keras.layers.MaxPooling3D(pool_size = (2,2,2))(conv)\n",
        "  else:\n",
        "    next_layer = conv\n",
        "  \n",
        "  skip_connection = conv   \n",
        "\n",
        "  print(\"end_of_block\") \n",
        "  return next_layer, skip_connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvMNFlsHseOF"
      },
      "outputs": [],
      "source": [
        "def UpConvBlock(prev_layer_input, skip_layer_input, filter_size = 3, n_filters=32):\n",
        "\n",
        "    padding_size = int((filter_size-1)/2)\n",
        "    kernel_init = tf.keras.initializers.GlorotUniform(seed=0)\n",
        "    bias_init = tf.keras.initializers.Zeros()   \n",
        "\n",
        "    up = Conv3DTranspose(n_filters, (filter_size,filter_size,filter_size),\n",
        "                         strides=(filter_size-1,filter_size-1,filter_size-1),\n",
        "                         padding='same', kernel_initializer=kernel_init, bias_initializer=bias_init)(prev_layer_input)\n",
        "\n",
        "    merge = concatenate([up, skip_layer_input], axis=4)\n",
        "    merge = periodic_padding_flexible(merge, axis=(1,2,3),padding=(padding_size,padding_size,padding_size))\n",
        "    conv = Conv3D(n_filters, filter_size, activation='relu', padding='valid', kernel_initializer=kernel_init,  bias_initializer=bias_init)(merge)\n",
        "    print(conv.shape)\n",
        "    conv = periodic_padding_flexible(conv, axis=(1,2,3),padding=(padding_size,padding_size,padding_size))\n",
        "    conv = Conv3D(n_filters, filter_size, activation='relu',padding='valid', kernel_initializer=kernel_init,  bias_initializer=bias_init)(conv)\n",
        "    print(conv.shape)\n",
        "\n",
        "    print(\"end_of_block\")\n",
        "    return conv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fe-fUh99sgKg"
      },
      "outputs": [],
      "source": [
        "\n",
        "def UNet3DModel(input_size=(16, 34, 34, 3), n_filters=32, filter_size=3, n_classes=1):\n",
        "  kernel_init =  tf.keras.initializers.GlorotUniform(seed=0)\n",
        "  bias_init = tf.keras.initializers.Zeros()  \n",
        "  \n",
        "  inputs = Input(input_size)\n",
        "  print(\"Inputs\", inputs.shape)\n",
        "\n",
        "  cblock0 = DownConvBlock(inputs,     n_filters = n_filters    , filter_size = filter_size, max_pooling=False, special_padding=True)\n",
        "  print(\"CB0\", cblock0[0].shape)\n",
        "\n",
        "  cblock1 = DownConvBlock(inputs,     n_filters = n_filters    , filter_size = filter_size, max_pooling=True, special_padding=True)\n",
        "  print(\"CB1\", cblock1[0].shape)\n",
        "\n",
        "  cblock2 = DownConvBlock(cblock1[0], n_filters = n_filters*2  , filter_size = filter_size, max_pooling=True, special_padding=False)\n",
        "  print(\"CB2\", cblock2[0].shape)\n",
        "    \n",
        "  cblock3 = DownConvBlock(cblock2[0], n_filters = n_filters*4  , filter_size = filter_size, max_pooling=True, special_padding=False)\n",
        "  print(\"CB3\", cblock3[0].shape)\n",
        "  \n",
        "  cblock4 = DownConvBlock(cblock3[0], n_filters = n_filters*8  , filter_size = filter_size, max_pooling=False, special_padding=False)\n",
        "  print(\"CB4\", cblock4[0].shape)\n",
        "\n",
        "\n",
        "  print(\"------------------\")\n",
        "\n",
        "  ublock7 = UpConvBlock(cblock4[0]   , cblock3[1],  n_filters = n_filters * 4, filter_size = filter_size)\n",
        "  print(\"UB7\", ublock7.shape)\n",
        "  \n",
        "  ublock8 = UpConvBlock(ublock7   , cblock2[1],  n_filters = n_filters * 2, filter_size = filter_size)\n",
        "  print(\"UB8\", ublock8.shape)\n",
        "  \n",
        "  ublock9 = UpConvBlock(ublock8   , cblock1[1],  n_filters = n_filters, filter_size = filter_size)\n",
        "  print(\"UB9\", ublock9.shape)\n",
        "\n",
        "  ublock9 = periodic_padding_flexible(ublock9, axis=(1,2,3),padding=(1,1,1))\n",
        "  \n",
        "  conv9 = Conv3D(n_filters, 3, activation='relu', padding='valid', kernel_initializer=kernel_init,  bias_initializer=bias_init)(ublock9)\n",
        "  print(\"C9\", conv9.shape)\n",
        "  \n",
        "  conv10 = Conv3D(n_classes, 1, padding='same', kernel_initializer=kernel_init,  bias_initializer=bias_init)(conv9)\n",
        "  print(\"C10\", conv10.shape)\n",
        "\n",
        "  model = tf.keras.Model(inputs=inputs, outputs=conv10)  \n",
        "\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2a5FVUYPHTB"
      },
      "outputs": [],
      "source": [
        "\n",
        "def custom_mse(y_true,y_pred):\n",
        "    w_hot = 5.0\n",
        "    w_cold = 1.0\n",
        "    cutoff = 1.8\n",
        "    weightmat = tf.cast(tf.where(tf.greater(y_true, cutoff), w_hot, w_cold),float)\n",
        "    loss = tf.cast(K.square(y_pred - y_true),float)\n",
        "    loss = loss*weightmat\n",
        "    loss = K.mean(loss)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3SJtgKps6tc"
      },
      "outputs": [],
      "source": [
        "model = UNet3DModel(input_size=(16, 34, 34, 3), n_filters=32, filter_size = 3, n_classes=1)\n",
        "optimizer = tf.optimizers.Adam(learning_rate = 0.0005)\n",
        "model.compile(loss=custom_mse, optimizer=optimizer, metrics=['mse'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baIEkfpntuOW"
      },
      "outputs": [],
      "source": [
        "early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",min_delta=0.0005, patience=200, verbose=0, mode=\"auto\", baseline=None, restore_best_weights=True)\n",
        "\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "  if epoch == 500:\n",
        "    return lr /5\n",
        "  else:\n",
        "    return lr\n",
        "\n",
        "\n",
        "scheduler_cb = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "\n",
        "history = model.fit(train_data, train_labels, epochs=1000, validation_data=(validation_data, validation_labels), callbacks=[early, scheduler_cb])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgCp0oNUAfzt"
      },
      "outputs": [],
      "source": [
        "print(history.history.keys())\n",
        "# # summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "#plt.ylim([0,0.2])\n",
        "plt.legend(['train', 'valid'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def area_hotspot(datapoint):\n",
        "  tinc = 5\n",
        "  tnum = int(4500/tinc)\n",
        "\n",
        "  tinc = 5\n",
        "  tnum = int(4500/tinc)\n",
        "\n",
        "  bins=np.zeros((tnum,2))\n",
        "  bins[:,0] = [ tinc*(0.5 + x) for x in list(range(tnum))]\n",
        "\n",
        "  for bin_index, temp in np.ndenumerate(datapoint):\n",
        "    theta = temp * 1000\n",
        "    tind=math.floor(theta/tinc)\n",
        "    bins[:tind, 1] += 4 # ~ Roughly 2*2*1 nm^3 (volume value from Chunyu)\n",
        "  \n",
        "  return bins\n",
        "\n",
        "def datapoint_results_print(simulation_point, simulation_temperatures, prediction_tensor):\n",
        "\n",
        "  # Simulation point is the input train_data[<point order>,<dim 0>,<dim 1>,<dim 2>,<channel>]\n",
        "  # For example, simulation_point = train_data[i,:,:,:,:]\n",
        "\n",
        "\n",
        "\n",
        "  fig = make_subplots(rows=3, cols=3, specs=[[{\"type\": \"scatter3d\"},{\"type\": \"scatter3d\"},{\"type\": \"scatter3d\"}],\n",
        "                                             [{\"type\": \"scatter3d\"},{\"type\": \"scatter3d\"},{\"type\": \"scatter\"}],\n",
        "                                             [{\"type\": \"histogram\"},{\"type\": \"histogram\"},{\"type\": \"scatter\"}]],\n",
        "                      subplot_titles=[\"Input 1\",\"Input 2\",\"Input 3\",\n",
        "                                      \"Temp (Labels)\",\"Temp (Predictions)\",\"Parity Plot\",\n",
        "                                      \"Temp (Distributions)\", \"Residuals\", \"Hotspot volume\"], horizontal_spacing = 0.1, vertical_spacing = 0.1)\n",
        "  \n",
        "  fig.update_layout(autosize=False, width=800, height=800) \n",
        "\n",
        "  # FIRST PLOT --> INPUT 1\n",
        "\n",
        "  input_1 = simulation_point[:,:,:,0].squeeze()\n",
        "\n",
        "  X,Y,Z = np.mgrid[0:input_1.shape[0], 0:input_1.shape[1], 0:input_1.shape[2]]\n",
        "  #input_1_xz = np.swapaxes(input_1, 2, 0)\n",
        "\n",
        "  trace_1 = go.Scatter3d(x = X.flatten(), y = Y.flatten(), z=Z.flatten(),\n",
        "                          mode='markers', marker=dict(colorscale='Viridis', size=8, line=dict(width=0), symbol='square', color = input_1.flatten(), colorbar=dict(thickness=20, len=0.3, x=0.27, y=0.9)), showlegend=False)\n",
        "  fig.add_trace(trace_1, row=1, col=1)\n",
        "\n",
        "  # SECOND PLOT --> INPUT 2\n",
        "\n",
        "  input_2 = simulation_point[:,:,:,1].squeeze()\n",
        "\n",
        "  X,Y,Z = np.mgrid[0:input_2.shape[0], 0:input_2.shape[1], 0:input_2.shape[2]]\n",
        "  #input_2_xz = np.swapaxes(input_2, 2, 0)\n",
        "\n",
        "  trace_2 = go.Scatter3d(x = X.flatten(), y = Y.flatten(), z=Z.flatten(),\n",
        "                          mode='markers', marker=dict(colorscale='Viridis', size=8, line=dict(width=0), symbol='square', color = input_2.flatten(), colorbar=dict(thickness=20, len=0.3, x=0.62, y=0.9)), showlegend=False)\n",
        "  fig.add_trace(trace_2, row=1, col=2)\n",
        "\n",
        "\n",
        "  # THIRD PLOT --> INPUT 3\n",
        "\n",
        "  input_3 = simulation_point[:,:,:,2].squeeze()\n",
        "\n",
        "  X,Y,Z = np.mgrid[0:input_3.shape[0], 0:input_3.shape[1], 0:input_3.shape[2]]\n",
        "  #input_3_xz = np.swapaxes(input_3, 2, 0)\n",
        "\n",
        "  trace_3 = go.Scatter3d(x = X.flatten(), y = Y.flatten(), z=Z.flatten(),\n",
        "                          mode='markers', marker=dict(colorscale='Viridis', size=8, line=dict(width=0), symbol='square', color = input_3.flatten(), colorbar=dict(thickness=20, len=0.3, x=1, y=0.9)), showlegend=False)\n",
        "  fig.add_trace(trace_3, row=1, col=3)\n",
        "\n",
        "\n",
        "  # FOURTH PLOT --> TEMPS (LABELS)\n",
        "\n",
        "  maxval = max(np.max(prediction_tensor), np.max(simulation_temperatures))\n",
        "  \n",
        "\n",
        "  X,Y,Z = np.mgrid[0:simulation_temperatures.shape[0], 0:simulation_temperatures.shape[1], 0:simulation_temperatures.shape[2]]\n",
        "  #simulation_temperatures_xz = np.swapaxes(simulation_temperatures, 2, 0)\n",
        "\n",
        "  trace_4 = go.Scatter3d(x = X.flatten(), y = Y.flatten(), z=Z.flatten(),\n",
        "                          mode='markers', marker=dict(cmin=0, cmax=maxval, colorscale='Reds', size=8, line=dict(width=0), symbol='square', color = simulation_temperatures.flatten(), colorbar=dict(thickness=20,len=0.3, x=0.27, y=0.5)), showlegend=False)\n",
        "  fig.add_trace(trace_4, row=2, col=1)\n",
        "\n",
        "\n",
        "  # FIFTH PLOT --> TEMPS (PREDICTIONS)\n",
        "\n",
        "  X,Y,Z = np.mgrid[0:prediction_tensor.shape[0], 0:prediction_tensor.shape[1], 0:prediction_tensor.shape[2]]\n",
        "  #prediction_tensor_xz = np.swapaxes(prediction_tensor, 2, 0)\n",
        "\n",
        "  trace_5 = go.Scatter3d(x = X.flatten(), y = Y.flatten(), z=Z.flatten(),\n",
        "                          mode='markers', marker=dict(cmin=0, cmax=maxval, colorscale='Reds', size=8, line=dict(width=0), symbol='square', color = prediction_tensor.flatten(), colorbar=dict(thickness=20, len=0.3, x=0.62, y=0.5)), showlegend=False)\n",
        "  fig.add_trace(trace_5, row=2, col=2)\n",
        "\n",
        "  # SIXTH PLOT --> PARITY PLOT\n",
        "\n",
        "  trace_6 = go.Scatter(x=simulation_temperatures.flatten(), y = prediction_tensor.flatten(), mode='markers', showlegend=False)\n",
        "  fig.add_trace(trace_6, row=2, col=3)\n",
        "  fig.update_xaxes(title=\"Scaled Temperature (K) - Labels\", row=2, col=3)\n",
        "  fig.update_yaxes(title=\"Scaled Temperature (K) - Predictions\", row=2, col=3)\n",
        "\n",
        "\n",
        "  # SEVENTH PLOT --> TEMP (Distributions)\n",
        "\n",
        "  trace_7 = go.Histogram(x=prediction_tensor.flatten(), name='Predictions', marker=dict(color='red'), showlegend=True, legendgroup = '1')\n",
        "  trace_7b = go.Histogram(x=simulation_temperatures.flatten(), name='Truth', marker=dict(color='green'), showlegend=True, legendgroup = '1')\n",
        "  fig.update_xaxes(title=\"Temperature (K) - Labels\", row=3, col=1)\n",
        "  fig.add_trace(trace_7, row=3, col=1)\n",
        "  fig.add_trace(trace_7b, row=3, col=1) \n",
        "\n",
        "\n",
        "  # EIGHTH PLOT --> RESIDUALS\n",
        "\n",
        "  diff_xz = prediction_tensor - simulation_temperatures\n",
        "  flat_diff_xz = diff_xz.flatten()\n",
        "\n",
        "  trace_8 = go.Histogram(x=flat_diff_xz, showlegend=False)\n",
        "  trace_line = go.Scatter(x=[0,0], y = [0,700], mode='lines', showlegend=False)\n",
        "\n",
        "  fig.add_trace(trace_8, row=3, col=2)\n",
        "  fig.add_trace(trace_line, row=3, col=2)\n",
        "\n",
        "  # NINTH PLOT ---> VOLUME OF HOTSPOT\n",
        "  \n",
        "  bins_labels = area_hotspot(simulation_temperatures)\n",
        "  bins_predictions = area_hotspot(prediction_tensor)\n",
        "  trace_9 = go.Scatter(x=bins_predictions[:,1], y=bins_predictions[:,0], mode='lines',  name='Predictions', marker=dict(color='red'), showlegend=True, legendgroup = '2')\n",
        "  trace_9b = go.Scatter(x=bins_labels[:,1], y=bins_labels[:,0], mode='lines', name='Truth', marker=dict(color='green'), showlegend=True, legendgroup = '2')\n",
        "  \n",
        "  fig.add_trace(trace_9, row=3, col=3)\n",
        "  fig.add_trace(trace_9b, row=3, col=3) \n",
        "  fig.update_xaxes(type=\"log\", row=3, col=3)\n",
        "  fig.update_xaxes(title=\"Hotspot Volume (nm^3)\", row=3, col=3)\n",
        "  fig.update_yaxes(title=\"Temperature (K)\", row=3, col=3)  \n",
        "\n",
        "  #### \n",
        "\n",
        "  fig.update_layout(autosize=False, width=1400, height=1000, legend_tracegroupgap = 180, legend=dict(font=dict(size=16),orientation=\"h\"))   \n",
        "\n",
        "  return fig\n",
        "\n"
      ],
      "metadata": {
        "id": "cVbLrXkBNWDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GUI(inplabel, prediction, fig):\n",
        "  #########\n",
        "\n",
        "  fig = go.FigureWidget(fig)\n",
        "\n",
        "  toggle_button = widgets.ToggleButtons(options=['MD', 'Pred'], description='Filter by:', button_style='')\n",
        "  md_tmp_slider = widgets.FloatRangeSlider(value=[0, np.max(inplabel)], min=0, max=np.max(inplabel), description='MD Temp:', disabled=False, continuous_update=False)\n",
        "  pred_tmp_slider = widgets.FloatRangeSlider(value=[0, np.max(prediction)], min=0, max=np.max(prediction), description='CNN Temp:', disabled=True, continuous_update=False)\n",
        "\n",
        "  slider_box =widgets.VBox([md_tmp_slider, pred_tmp_slider])\n",
        "  controls_box = widgets.HBox([slider_box, toggle_button])\n",
        "  endbox = widgets.VBox([controls_box, fig], layout=widgets.Layout(width='100%'))\n",
        "  \n",
        "  display(endbox)  \n",
        "\n",
        "  # OBSERVERS\n",
        "\n",
        "  def response_MD(change):\n",
        "\n",
        "    map = np.where(np.logical_and(inplabel>=md_tmp_slider.value[0], inplabel<=md_tmp_slider.value[1]), 8, 0)\n",
        "    with fig.batch_update():\n",
        "      fig.data[0].marker.size = map.flatten()\n",
        "      fig.data[1].marker.size = map.flatten()\n",
        "      fig.data[2].marker.size = map.flatten()\n",
        "      fig.data[3].marker.size = map.flatten()\n",
        "      fig.data[4].marker.size = map.flatten()\n",
        "\n",
        "\n",
        "  def response_Pred(change):\n",
        "\n",
        "    map = np.where(np.logical_and(prediction>=pred_tmp_slider.value[0], prediction<=pred_tmp_slider.value[1]), 8, 0)\n",
        "    with fig.batch_update():\n",
        "      fig.data[0].marker.size = map.flatten()\n",
        "      fig.data[1].marker.size = map.flatten()\n",
        "      fig.data[2].marker.size = map.flatten()\n",
        "      fig.data[3].marker.size = map.flatten()\n",
        "      fig.data[4].marker.size = map.flatten()\n",
        "\n",
        "  def slider_function(b):\n",
        "    md_tmp_slider.value = [0, np.max(inplabel)]\n",
        "    md_tmp_slider.disabled = (toggle_button.value == 'Pred')\n",
        "\n",
        "    pred_tmp_slider.value = [0, np.max(prediction)]\n",
        "    pred_tmp_slider.disabled = (toggle_button.value == 'MD')\n",
        "\n",
        "  toggle_button.observe(slider_function)\n",
        "  md_tmp_slider.observe(response_MD)\n",
        "  pred_tmp_slider.observe(response_Pred)\n",
        "\n",
        "  return fig\n",
        "\n",
        "\n",
        "  #fig.write_html('results/'+str(title)+'.html')"
      ],
      "metadata": {
        "id": "vUEMAz7qfj_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [0]:\n",
        "  print(i)\n",
        "  print(paths[i])\n",
        "  inppoint = train_data[i,:,:,:,:].squeeze()\n",
        "  inplabel = train_labels[i,:,:,:,:].squeeze()\n",
        "\n",
        "  prediction_point = model.predict(tf.expand_dims(inppoint, axis=0))\n",
        "  prediction_tensor = prediction_point.squeeze()\n",
        "\n",
        "  inppoint = inppoint[:, 1:-1, 1:-1] # NON PERIODIC GETS PLOTTED\n",
        "  fig = datapoint_results_print(inppoint, inplabel, prediction_tensor)\n",
        "\n",
        "  # GUI\n",
        "\n",
        "  updated_fig = GUI(inplabel, prediction_tensor, fig)\n",
        "\n",
        "  # ### SAVING NUMPY PREDICTIONS\n",
        "  \n",
        "  # np.save('results/'+str(title)+'.npy', prediction_tensor)"
      ],
      "metadata": {
        "id": "-PCvavvNP6kj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "updated_fig.show()\n",
        "# updated_fig.write_html('test4.html')"
      ],
      "metadata": {
        "id": "MA8uxuCQ3Hj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i, title in enumerate(validation_paths):\n",
        "#   print(i)\n",
        "#   inppoint = validation_data[i,:,:,:,:].squeeze()\n",
        "#   inplabel = validation_labels[i,:,:,:,:].squeeze()\n",
        "#   fig, prediction =  datapoint_results_print(inppoint, inplabel)\n",
        "#   ### SAVING NUMPY PREDICTIONS\n",
        "#   np.save('results/'+str(title)+'.npy', prediction)\n",
        "#   #fig.write_image('results/'+str(title)+'.pdf')\n",
        "#   fig.write_html('results/'+str(title)+'.html')"
      ],
      "metadata": {
        "id": "ClEFHwOOjvd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [0]:\n",
        "  print(i)\n",
        "  print(validation_paths[i])\n",
        "  inppoint = validation_data[i,:,:,:,:].squeeze()\n",
        "  inplabel = validation_labels[i,:,:,:,:].squeeze()\n",
        "\n",
        "  prediction_point = model.predict(tf.expand_dims(inppoint, axis=0))\n",
        "  prediction_tensor = prediction_point.squeeze()\n",
        "\n",
        "  inppoint = inppoint[:, 1:-1, 1:-1] # NON PERIODIC GETS PLOTTED\n",
        "  fig = datapoint_results_print(inppoint, inplabel, prediction_tensor)\n",
        "\n",
        "  # GUI\n",
        "\n",
        "  updated_fig = GUI(inplabel, prediction_tensor, fig)\n",
        "\n",
        "  # ### SAVING NUMPY PREDICTIONS\n",
        "  \n",
        "  # np.save('results/'+str(title)+'.npy', prediction_tensor)"
      ],
      "metadata": {
        "id": "c52fdGLIA_W3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "updated_fig.show()"
      ],
      "metadata": {
        "id": "aAAv5I7aIfdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OvGM6Bn8ImGo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "pbx-local",
      "language": "python",
      "name": "pbx-local"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "f806901b044f1f905f6f73d9d34ac86b2be2e087ac41c051b6f31285dd315984"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}